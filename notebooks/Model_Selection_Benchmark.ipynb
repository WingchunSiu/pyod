{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Utilizing PyOD for Deep Learning Model Selection with GPT Few-Shot Learning\n",
    "\n",
    "### Project Overview\n",
    "This project leverages the Python Outlier Detection (PyOD) library, which encompasses a wide range of deep learning models designed for identifying outliers in multivariate data. Our goal is to use this extensive toolkit in conjunction with a language model (GPT) to intelligently select the most appropriate model for a specific dataset through a few-shot learning approach.\n",
    "\n",
    "### Objectives\n",
    "1. **Summarize Dataset and Model Information**: Compile and format detailed information about our dataset and the available models within the PyOD library into a structured form that can be easily processed by GPT.\n",
    "2. **Model Selection with Language Model (LLM)**: Utilize the capabilities of GPT, trained in a few-shot learning manner, to determine the most suitable outlier detection model from the PyOD library for our dataset based on the summarized information.\n",
    "\n",
    "### Dataset Description\n",
    "The dataset involved in this project is characterized by its diversity in features and instances, providing a challenging environment to test the efficacy of various outlier detection models. Here’s a brief overview of the dataset:\n",
    "\n",
    "| Dataset    | Domain            | Data Type    | Instances | Attributes | Missing Values | Area                    |\n",
    "|------------|-------------------|--------------|-----------|------------|----------------|-------------------------|\n",
    "| Arrhythmia | Medical           | Multivariate | 452       | 279        | Yes            | Cardiology              |\n",
    "| Glass      | Forensic Science  | Multivariate | 214       | 9          | No             | Material Identification |\n",
    "| Ionosphere | Astronomy         | Multivariate | 351       | 34         | No             | Space                   |\n",
    "| Lympho     | Medical           | Multivariate | 148       | 18         | No             | Oncology                |\n",
    "\n",
    "\n",
    "### PyOD Models Overview\n",
    "The PyOD library includes several deep learning-based models, each with unique capabilities and configurations. The following table summarizes some of the models available for selection:\n",
    "\n",
    "| Model      | Description                                                                                           |\n",
    "|------------|-------------------------------------------------------------------------------------------------------|\n",
    "| MO_GAAL    | Multiple-Objective Generative Adversarial Active Learning, suitable for complex multi-objective setups. |\n",
    "| SO_GAAL    | Single-Objective Generative Adversarial Active Learning, optimized for simpler, single-objective tasks.  |\n",
    "| AutoEncoder| Utilizes neural networks to learn compressed data representations, detecting anomalies based on the reconstruction errors. |\n",
    "| AnoGAN     | Anomaly Detection with Generative Adversarial Networks, employs a discriminator to identify data inconsistencies. |\n",
    "| DeepSVDD   | Deep Support Vector Data Description, a deep learning adaptation of the traditional SVDD method.     |\n",
    "| ALAD       | Adversarially Learned Anomaly Detection, differentiates normal from abnormal data in latent space using adversarial training. |\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import os\n",
    "import sys\n",
    "from time import time\n",
    "\n",
    "# temporary solution for relative imports in case pyod is not installed\n",
    "# if pyod is installed, no need to use the following line\n",
    "sys.path.append(\n",
    "    os.path.abspath(os.path.join(os.path.dirname(\"__file__\"), '..')))\n",
    "# supress warnings for clean output\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from scipy.io import loadmat\n",
    "\n",
    "\n",
    "from pyod.models.mo_gaal import MO_GAAL\n",
    "from pyod.models.so_gaal import SO_GAAL\n",
    "from pyod.models.auto_encoder import AutoEncoder\n",
    "from pyod.models.vae import VAE\n",
    "from pyod.models.anogan import AnoGAN\n",
    "from pyod.models.deep_svdd import DeepSVDD\n",
    "from pyod.models.alad import ALAD\n",
    "from pyod.models.ae1svm import AE1SVM\n",
    "from pyod.models.devnet import DevNet\n",
    "from pyod.models.rgraph import RGraph\n",
    "from pyod.models.lunar import LUNAR\n",
    "\n",
    "#AE1SVM\n",
    "#DevNet\n",
    "#R-Graph\n",
    "#LUNAR\n",
    "\n",
    "\n",
    "from pyod.utils.utility import standardizer\n",
    "from pyod.utils.utility import precision_n_scores\n",
    "from sklearn.metrics import roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "... Processing arrhythmia.mat ...\n",
      "Epoch 1 of 60\n",
      "Epoch 2 of 60\n",
      "Epoch 3 of 60\n",
      "Epoch 4 of 60\n",
      "Epoch 5 of 60\n",
      "Epoch 6 of 60\n",
      "Epoch 7 of 60\n",
      "Epoch 8 of 60\n",
      "Epoch 9 of 60\n",
      "Epoch 10 of 60\n",
      "Epoch 11 of 60\n",
      "Epoch 12 of 60\n",
      "Epoch 13 of 60\n",
      "Epoch 14 of 60\n",
      "Epoch 15 of 60\n",
      "Epoch 16 of 60\n",
      "Epoch 17 of 60\n",
      "Epoch 18 of 60\n",
      "Epoch 19 of 60\n",
      "Epoch 20 of 60\n",
      "Epoch 21 of 60\n",
      "Epoch 22 of 60\n",
      "Epoch 23 of 60\n",
      "Epoch 24 of 60\n",
      "Epoch 25 of 60\n",
      "Epoch 26 of 60\n",
      "Epoch 27 of 60\n",
      "Epoch 28 of 60\n",
      "Epoch 29 of 60\n",
      "Epoch 30 of 60\n",
      "Epoch 31 of 60\n",
      "Epoch 32 of 60\n",
      "Epoch 33 of 60\n",
      "Epoch 34 of 60\n",
      "Epoch 35 of 60\n",
      "Epoch 36 of 60\n",
      "Epoch 37 of 60\n",
      "Epoch 38 of 60\n",
      "Epoch 39 of 60\n",
      "Epoch 40 of 60\n",
      "Epoch 41 of 60\n",
      "Epoch 42 of 60\n",
      "Epoch 43 of 60\n",
      "Epoch 44 of 60\n",
      "Epoch 45 of 60\n",
      "Epoch 46 of 60\n",
      "Epoch 47 of 60\n",
      "Epoch 48 of 60\n",
      "Epoch 49 of 60\n",
      "Epoch 50 of 60\n",
      "Epoch 51 of 60\n",
      "Epoch 52 of 60\n",
      "Epoch 53 of 60\n",
      "Epoch 54 of 60\n",
      "Epoch 55 of 60\n",
      "Epoch 56 of 60\n",
      "Epoch 57 of 60\n",
      "Epoch 58 of 60\n",
      "Epoch 59 of 60\n",
      "Epoch 60 of 60\n",
      "MO_GAAL ROC: 0.6153, precision @ rank n: 0.3214, execution time: 2.2194s\n",
      "Epoch 1 of 60\n",
      "Epoch 2 of 60\n",
      "Epoch 3 of 60\n",
      "Epoch 4 of 60\n",
      "Epoch 5 of 60\n",
      "Epoch 6 of 60\n",
      "Epoch 7 of 60\n",
      "Epoch 8 of 60\n",
      "Epoch 9 of 60\n",
      "Epoch 10 of 60\n",
      "Epoch 11 of 60\n",
      "Epoch 12 of 60\n",
      "Epoch 13 of 60\n",
      "Epoch 14 of 60\n",
      "Epoch 15 of 60\n",
      "Epoch 16 of 60\n",
      "Epoch 17 of 60\n",
      "Epoch 18 of 60\n",
      "Epoch 19 of 60\n",
      "Epoch 20 of 60\n",
      "Epoch 21 of 60\n",
      "Epoch 22 of 60\n",
      "Epoch 23 of 60\n",
      "Epoch 24 of 60\n",
      "Epoch 25 of 60\n",
      "Epoch 26 of 60\n",
      "Epoch 27 of 60\n",
      "Epoch 28 of 60\n",
      "Epoch 29 of 60\n",
      "Epoch 30 of 60\n",
      "Epoch 31 of 60\n",
      "Epoch 32 of 60\n",
      "Epoch 33 of 60\n",
      "Epoch 34 of 60\n",
      "Epoch 35 of 60\n",
      "Epoch 36 of 60\n",
      "Epoch 37 of 60\n",
      "Epoch 38 of 60\n",
      "Epoch 39 of 60\n",
      "Epoch 40 of 60\n",
      "Epoch 41 of 60\n",
      "Epoch 42 of 60\n",
      "Epoch 43 of 60\n",
      "Epoch 44 of 60\n",
      "Epoch 45 of 60\n",
      "Epoch 46 of 60\n",
      "Epoch 47 of 60\n",
      "Epoch 48 of 60\n",
      "Epoch 49 of 60\n",
      "Epoch 50 of 60\n",
      "Epoch 51 of 60\n",
      "Epoch 52 of 60\n",
      "Epoch 53 of 60\n",
      "Epoch 54 of 60\n",
      "Epoch 55 of 60\n",
      "Epoch 56 of 60\n",
      "Epoch 57 of 60\n",
      "Epoch 58 of 60\n",
      "Epoch 59 of 60\n",
      "Epoch 60 of 60\n",
      "SO_GAAL ROC: 0.6179, precision @ rank n: 0.3571, execution time: 0.7724s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 10/10 [00:00<00:00, 18.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AutoEncoder ROC: 0.8096, precision @ rank n: 0.3929, execution time: 3.1156s\n",
      "AnoGAN ROC: 0.7726, precision @ rank n: 0.4286, execution time: 52.4219s\n",
      "Epoch 1/100, Loss: 5.825584053993225\n",
      "Epoch 2/100, Loss: 5.766186058521271\n",
      "Epoch 3/100, Loss: 5.762155622243881\n",
      "Epoch 4/100, Loss: 5.853882700204849\n",
      "Epoch 5/100, Loss: 5.786322772502899\n",
      "Epoch 6/100, Loss: 5.646298587322235\n",
      "Epoch 7/100, Loss: 5.793177425861359\n",
      "Epoch 8/100, Loss: 5.740046471357346\n",
      "Epoch 9/100, Loss: 5.9401843547821045\n",
      "Epoch 10/100, Loss: 5.7085913717746735\n",
      "Epoch 11/100, Loss: 5.576205193996429\n",
      "Epoch 12/100, Loss: 5.7851404547691345\n",
      "Epoch 13/100, Loss: 5.77113077044487\n",
      "Epoch 14/100, Loss: 5.7520412504673\n",
      "Epoch 15/100, Loss: 5.915862739086151\n",
      "Epoch 16/100, Loss: 5.660930097103119\n",
      "Epoch 17/100, Loss: 5.639804899692535\n",
      "Epoch 18/100, Loss: 5.746669828891754\n",
      "Epoch 19/100, Loss: 5.6973293125629425\n",
      "Epoch 20/100, Loss: 5.6578125059604645\n",
      "Epoch 21/100, Loss: 5.895969212055206\n",
      "Epoch 22/100, Loss: 6.077497363090515\n",
      "Epoch 23/100, Loss: 5.841287732124329\n",
      "Epoch 24/100, Loss: 5.576956689357758\n",
      "Epoch 25/100, Loss: 5.922933101654053\n",
      "Epoch 26/100, Loss: 5.764268547296524\n",
      "Epoch 27/100, Loss: 5.981364130973816\n",
      "Epoch 28/100, Loss: 5.7167651653289795\n",
      "Epoch 29/100, Loss: 5.7342604994773865\n",
      "Epoch 30/100, Loss: 5.98813259601593\n",
      "Epoch 31/100, Loss: 5.767529606819153\n",
      "Epoch 32/100, Loss: 5.671326398849487\n",
      "Epoch 33/100, Loss: 5.8973928689956665\n",
      "Epoch 34/100, Loss: 6.053325176239014\n",
      "Epoch 35/100, Loss: 6.02507284283638\n",
      "Epoch 36/100, Loss: 5.76396781206131\n",
      "Epoch 37/100, Loss: 5.780953079462051\n",
      "Epoch 38/100, Loss: 5.770173817873001\n",
      "Epoch 39/100, Loss: 5.725734502077103\n",
      "Epoch 40/100, Loss: 5.6643082201480865\n",
      "Epoch 41/100, Loss: 5.6523992121219635\n",
      "Epoch 42/100, Loss: 5.713056564331055\n",
      "Epoch 43/100, Loss: 5.765583395957947\n",
      "Epoch 44/100, Loss: 5.829516887664795\n",
      "Epoch 45/100, Loss: 6.154963105916977\n",
      "Epoch 46/100, Loss: 5.6028774082660675\n",
      "Epoch 47/100, Loss: 5.654470890760422\n",
      "Epoch 48/100, Loss: 5.721946656703949\n",
      "Epoch 49/100, Loss: 5.688358336687088\n",
      "Epoch 50/100, Loss: 5.785615622997284\n",
      "Epoch 51/100, Loss: 5.887760281562805\n",
      "Epoch 52/100, Loss: 5.674372881650925\n",
      "Epoch 53/100, Loss: 5.621196150779724\n",
      "Epoch 54/100, Loss: 5.774117648601532\n",
      "Epoch 55/100, Loss: 5.8160781264305115\n",
      "Epoch 56/100, Loss: 5.5785708129405975\n",
      "Epoch 57/100, Loss: 5.704960078001022\n",
      "Epoch 58/100, Loss: 5.920604020357132\n",
      "Epoch 59/100, Loss: 5.948373854160309\n",
      "Epoch 60/100, Loss: 5.709269940853119\n",
      "Epoch 61/100, Loss: 5.820351600646973\n",
      "Epoch 62/100, Loss: 5.681069374084473\n",
      "Epoch 63/100, Loss: 5.902109980583191\n",
      "Epoch 64/100, Loss: 5.661280304193497\n",
      "Epoch 65/100, Loss: 5.905064076185226\n",
      "Epoch 66/100, Loss: 6.0464257299900055\n",
      "Epoch 67/100, Loss: 5.656590014696121\n",
      "Epoch 68/100, Loss: 6.277182459831238\n",
      "Epoch 69/100, Loss: 5.714087575674057\n",
      "Epoch 70/100, Loss: 5.67311155796051\n",
      "Epoch 71/100, Loss: 5.745434761047363\n",
      "Epoch 72/100, Loss: 5.669977813959122\n",
      "Epoch 73/100, Loss: 5.761296659708023\n",
      "Epoch 74/100, Loss: 5.705011397600174\n",
      "Epoch 75/100, Loss: 5.8858682513237\n",
      "Epoch 76/100, Loss: 5.815396726131439\n",
      "Epoch 77/100, Loss: 5.706779420375824\n",
      "Epoch 78/100, Loss: 5.717624843120575\n",
      "Epoch 79/100, Loss: 5.84048718214035\n",
      "Epoch 80/100, Loss: 5.804624557495117\n",
      "Epoch 81/100, Loss: 5.692366302013397\n",
      "Epoch 82/100, Loss: 5.640580385923386\n",
      "Epoch 83/100, Loss: 5.833495944738388\n",
      "Epoch 84/100, Loss: 5.773498117923737\n",
      "Epoch 85/100, Loss: 6.030056476593018\n",
      "Epoch 86/100, Loss: 5.599182814359665\n",
      "Epoch 87/100, Loss: 5.671288788318634\n",
      "Epoch 88/100, Loss: 5.603378802537918\n",
      "Epoch 89/100, Loss: 5.730778783559799\n",
      "Epoch 90/100, Loss: 5.754105269908905\n",
      "Epoch 91/100, Loss: 5.971511960029602\n",
      "Epoch 92/100, Loss: 5.650279998779297\n",
      "Epoch 93/100, Loss: 6.0050338208675385\n",
      "Epoch 94/100, Loss: 5.686640202999115\n",
      "Epoch 95/100, Loss: 5.60435077548027\n",
      "Epoch 96/100, Loss: 6.167220652103424\n",
      "Epoch 97/100, Loss: 5.6702050268650055\n",
      "Epoch 98/100, Loss: 5.613074958324432\n",
      "Epoch 99/100, Loss: 5.713058590888977\n",
      "Epoch 100/100, Loss: 5.748966872692108\n",
      "DeepSVDD ROC: 0.7915, precision @ rank n: 0.4286, execution time: 0.6767s\n",
      "ALAD ROC: 0.5257, precision @ rank n: 0.0714, execution time: 3.3174s\n",
      "Epoch 10/50, Loss: 6.8404696517520485\n",
      "Epoch 20/50, Loss: 6.509733385509914\n",
      "Epoch 30/50, Loss: 4.83187280760871\n",
      "Epoch 40/50, Loss: 3.8174199793073864\n",
      "Epoch 50/50, Loss: 5.224082734849718\n",
      "AE1SVM ROC: 0.818, precision @ rank n: 0.3929, execution time: 4.6475s\n",
      "Original training size: 271, No. outliers: 413\n",
      "181 413 26990 4614\n",
      "Epoch 1, Loss: -3674.260498046875\n",
      "Epoch 2, Loss: -8558.15234375\n",
      "Epoch 3, Loss: -14331.146484375\n",
      "Epoch 4, Loss: -18750.998046875\n",
      "Epoch 5, Loss: -27549.05859375\n",
      "Epoch 6, Loss: -36912.0390625\n",
      "Epoch 7, Loss: -41425.12109375\n",
      "Epoch 8, Loss: -50201.07421875\n",
      "Epoch 9, Loss: -60115.71875\n",
      "Epoch 10, Loss: -71028.34375\n",
      "Epoch 11, Loss: -84501.96875\n",
      "Epoch 12, Loss: -87905.0546875\n",
      "Epoch 13, Loss: -107739.421875\n",
      "Epoch 14, Loss: -120581.2734375\n",
      "Epoch 15, Loss: -130769.375\n",
      "Epoch 16, Loss: -143315.09375\n",
      "Epoch 17, Loss: -153585.671875\n",
      "Epoch 18, Loss: -166293.84375\n",
      "Epoch 19, Loss: -191116.609375\n",
      "Epoch 20, Loss: -207622.34375\n",
      "Epoch 21, Loss: -223428.953125\n",
      "Epoch 22, Loss: -235438.53125\n",
      "Epoch 23, Loss: -257456.4375\n",
      "Epoch 24, Loss: -282460.375\n",
      "Epoch 25, Loss: -296839.5\n",
      "Epoch 26, Loss: -312384.46875\n",
      "Epoch 27, Loss: -341267.5\n",
      "Epoch 28, Loss: -381047.25\n",
      "Epoch 29, Loss: -390501.34375\n",
      "Epoch 30, Loss: -403553.25\n",
      "Epoch 31, Loss: -409644.46875\n",
      "Epoch 32, Loss: -457655.90625\n",
      "Epoch 33, Loss: -472350.9375\n",
      "Epoch 34, Loss: -480540.0\n",
      "Epoch 35, Loss: -502001.6875\n",
      "Epoch 36, Loss: -570639.5625\n",
      "Epoch 37, Loss: -587192.25\n",
      "Epoch 38, Loss: -627809.375\n",
      "Epoch 39, Loss: -630048.5\n",
      "Epoch 40, Loss: -638484.375\n",
      "Epoch 41, Loss: -748929.25\n",
      "Epoch 42, Loss: -729901.625\n",
      "Epoch 43, Loss: -738101.25\n",
      "Epoch 44, Loss: -757893.25\n",
      "Epoch 45, Loss: -804751.5\n",
      "Epoch 46, Loss: -846349.0625\n",
      "Epoch 47, Loss: -881991.875\n",
      "Epoch 48, Loss: -919090.375\n",
      "Epoch 49, Loss: -943357.8125\n",
      "Epoch 50, Loss: -970783.4375\n",
      "DevNet ROC: 0.4288, precision @ rank n: 0.2143, execution time: 52.4647s\n",
      "0/271\n",
      "25/271\n",
      "50/271\n",
      "75/271\n",
      "100/271\n",
      "125/271\n",
      "150/271\n",
      "175/271\n",
      "200/271\n",
      "225/271\n",
      "250/271\n",
      "Test block 0/19\n",
      "0/281\n",
      "25/281\n",
      "50/281\n",
      "75/281\n",
      "100/281\n",
      "125/281\n",
      "150/281\n",
      "175/281\n",
      "200/281\n",
      "225/281\n",
      "250/281\n",
      "275/281\n",
      "Test block 1/19\n",
      "0/281\n",
      "25/281\n",
      "50/281\n",
      "75/281\n",
      "100/281\n",
      "125/281\n",
      "150/281\n",
      "175/281\n",
      "200/281\n",
      "225/281\n",
      "250/281\n",
      "275/281\n",
      "Test block 2/19\n",
      "0/281\n",
      "25/281\n",
      "50/281\n",
      "75/281\n",
      "100/281\n",
      "125/281\n",
      "150/281\n",
      "175/281\n",
      "200/281\n",
      "225/281\n",
      "250/281\n",
      "275/281\n",
      "Test block 3/19\n",
      "0/281\n",
      "25/281\n",
      "50/281\n",
      "75/281\n",
      "100/281\n",
      "125/281\n",
      "150/281\n",
      "175/281\n",
      "200/281\n",
      "225/281\n",
      "250/281\n",
      "275/281\n",
      "Test block 4/19\n",
      "0/281\n",
      "25/281\n",
      "50/281\n",
      "75/281\n",
      "100/281\n",
      "125/281\n",
      "150/281\n",
      "175/281\n",
      "200/281\n",
      "225/281\n",
      "250/281\n",
      "275/281\n",
      "Test block 5/19\n",
      "0/281\n",
      "25/281\n",
      "50/281\n",
      "75/281\n",
      "100/281\n",
      "125/281\n",
      "150/281\n",
      "175/281\n",
      "200/281\n",
      "225/281\n",
      "250/281\n",
      "275/281\n",
      "Test block 6/19\n",
      "0/281\n",
      "25/281\n",
      "50/281\n",
      "75/281\n",
      "100/281\n",
      "125/281\n",
      "150/281\n",
      "175/281\n",
      "200/281\n",
      "225/281\n",
      "250/281\n",
      "275/281\n",
      "Test block 7/19\n",
      "0/281\n",
      "25/281\n",
      "50/281\n",
      "75/281\n",
      "100/281\n",
      "125/281\n",
      "150/281\n",
      "175/281\n",
      "200/281\n",
      "225/281\n",
      "250/281\n",
      "275/281\n",
      "Test block 8/19\n",
      "0/281\n",
      "25/281\n",
      "50/281\n",
      "75/281\n",
      "100/281\n",
      "125/281\n",
      "150/281\n",
      "175/281\n",
      "200/281\n",
      "225/281\n",
      "250/281\n",
      "275/281\n",
      "Test block 9/19\n",
      "0/281\n",
      "25/281\n",
      "50/281\n",
      "75/281\n",
      "100/281\n",
      "125/281\n",
      "150/281\n",
      "175/281\n",
      "200/281\n",
      "225/281\n",
      "250/281\n",
      "275/281\n",
      "Test block 10/19\n",
      "0/281\n",
      "25/281\n",
      "50/281\n",
      "75/281\n",
      "100/281\n",
      "125/281\n",
      "150/281\n",
      "175/281\n",
      "200/281\n",
      "225/281\n",
      "250/281\n",
      "275/281\n",
      "Test block 11/19\n",
      "0/281\n",
      "25/281\n",
      "50/281\n",
      "75/281\n",
      "100/281\n",
      "125/281\n",
      "150/281\n",
      "175/281\n",
      "200/281\n",
      "225/281\n",
      "250/281\n",
      "275/281\n",
      "Test block 12/19\n",
      "0/281\n",
      "25/281\n",
      "50/281\n",
      "75/281\n",
      "100/281\n",
      "125/281\n",
      "150/281\n",
      "175/281\n",
      "200/281\n",
      "225/281\n",
      "250/281\n",
      "275/281\n",
      "Test block 13/19\n",
      "0/281\n",
      "25/281\n",
      "50/281\n",
      "75/281\n",
      "100/281\n",
      "125/281\n",
      "150/281\n",
      "175/281\n",
      "200/281\n",
      "225/281\n",
      "250/281\n",
      "275/281\n",
      "Test block 14/19\n",
      "0/281\n",
      "25/281\n",
      "50/281\n",
      "75/281\n",
      "100/281\n",
      "125/281\n",
      "150/281\n",
      "175/281\n",
      "200/281\n",
      "225/281\n",
      "250/281\n",
      "275/281\n",
      "Test block 15/19\n",
      "0/281\n",
      "25/281\n",
      "50/281\n",
      "75/281\n",
      "100/281\n",
      "125/281\n",
      "150/281\n",
      "175/281\n",
      "200/281\n",
      "225/281\n",
      "250/281\n",
      "275/281\n",
      "Test block 16/19\n",
      "0/281\n",
      "25/281\n",
      "50/281\n",
      "75/281\n",
      "100/281\n",
      "125/281\n",
      "150/281\n",
      "175/281\n",
      "200/281\n",
      "225/281\n",
      "250/281\n",
      "275/281\n",
      "Test block 17/19\n",
      "0/281\n",
      "25/281\n",
      "50/281\n",
      "75/281\n",
      "100/281\n",
      "125/281\n",
      "150/281\n",
      "175/281\n",
      "200/281\n",
      "225/281\n",
      "250/281\n",
      "275/281\n",
      "Test block 18/19\n",
      "0/272\n",
      "25/272\n",
      "50/272\n",
      "75/272\n",
      "100/272\n",
      "125/272\n",
      "150/272\n",
      "175/272\n",
      "200/272\n",
      "225/272\n",
      "250/272\n",
      "RGraph ROC: 0.7241, precision @ rank n: 0.3571, execution time: 386.0246s\n",
      "LUNAR ROC: 0.8284, precision @ rank n: 0.4643, execution time: 4.632s\n",
      "\n",
      "... Processing glass.mat ...\n",
      "Epoch 1 of 60\n",
      "Epoch 2 of 60\n",
      "Epoch 3 of 60\n",
      "Epoch 4 of 60\n",
      "Epoch 5 of 60\n",
      "Epoch 6 of 60\n",
      "Epoch 7 of 60\n",
      "Epoch 8 of 60\n",
      "Epoch 9 of 60\n",
      "Epoch 10 of 60\n",
      "Epoch 11 of 60\n",
      "Epoch 12 of 60\n",
      "Epoch 13 of 60\n",
      "Epoch 14 of 60\n",
      "Epoch 15 of 60\n",
      "Epoch 16 of 60\n",
      "Epoch 17 of 60\n",
      "Epoch 18 of 60\n",
      "Epoch 19 of 60\n",
      "Epoch 20 of 60\n",
      "Epoch 21 of 60\n",
      "Epoch 22 of 60\n",
      "Epoch 23 of 60\n",
      "Epoch 24 of 60\n",
      "Epoch 25 of 60\n",
      "Epoch 26 of 60\n",
      "Epoch 27 of 60\n",
      "Epoch 28 of 60\n",
      "Epoch 29 of 60\n",
      "Epoch 30 of 60\n",
      "Epoch 31 of 60\n",
      "Epoch 32 of 60\n",
      "Epoch 33 of 60\n",
      "Epoch 34 of 60\n",
      "Epoch 35 of 60\n",
      "Epoch 36 of 60\n",
      "Epoch 37 of 60\n",
      "Epoch 38 of 60\n",
      "Epoch 39 of 60\n",
      "Epoch 40 of 60\n",
      "Epoch 41 of 60\n",
      "Epoch 42 of 60\n",
      "Epoch 43 of 60\n",
      "Epoch 44 of 60\n",
      "Epoch 45 of 60\n",
      "Epoch 46 of 60\n",
      "Epoch 47 of 60\n",
      "Epoch 48 of 60\n",
      "Epoch 49 of 60\n",
      "Epoch 50 of 60\n",
      "Epoch 51 of 60\n",
      "Epoch 52 of 60\n",
      "Epoch 53 of 60\n",
      "Epoch 54 of 60\n",
      "Epoch 55 of 60\n",
      "Epoch 56 of 60\n",
      "Epoch 57 of 60\n",
      "Epoch 58 of 60\n",
      "Epoch 59 of 60\n",
      "Epoch 60 of 60\n",
      "MO_GAAL ROC: 0.686, precision @ rank n: 0.25, execution time: 0.5026s\n",
      "Epoch 1 of 60\n",
      "Epoch 2 of 60\n",
      "Epoch 3 of 60\n",
      "Epoch 4 of 60\n",
      "Epoch 5 of 60\n",
      "Epoch 6 of 60\n",
      "Epoch 7 of 60\n",
      "Epoch 8 of 60\n",
      "Epoch 9 of 60\n",
      "Epoch 10 of 60\n",
      "Epoch 11 of 60\n",
      "Epoch 12 of 60\n",
      "Epoch 13 of 60\n",
      "Epoch 14 of 60\n",
      "Epoch 15 of 60\n",
      "Epoch 16 of 60\n",
      "Epoch 17 of 60\n",
      "Epoch 18 of 60\n",
      "Epoch 19 of 60\n",
      "Epoch 20 of 60\n",
      "Epoch 21 of 60\n",
      "Epoch 22 of 60\n",
      "Epoch 23 of 60\n",
      "Epoch 24 of 60\n",
      "Epoch 25 of 60\n",
      "Epoch 26 of 60\n",
      "Epoch 27 of 60\n",
      "Epoch 28 of 60\n",
      "Epoch 29 of 60\n",
      "Epoch 30 of 60\n",
      "Epoch 31 of 60\n",
      "Epoch 32 of 60\n",
      "Epoch 33 of 60\n",
      "Epoch 34 of 60\n",
      "Epoch 35 of 60\n",
      "Epoch 36 of 60\n",
      "Epoch 37 of 60\n",
      "Epoch 38 of 60\n",
      "Epoch 39 of 60\n",
      "Epoch 40 of 60\n",
      "Epoch 41 of 60\n",
      "Epoch 42 of 60\n",
      "Epoch 43 of 60\n",
      "Epoch 44 of 60\n",
      "Epoch 45 of 60\n",
      "Epoch 46 of 60\n",
      "Epoch 47 of 60\n",
      "Epoch 48 of 60\n",
      "Epoch 49 of 60\n",
      "Epoch 50 of 60\n",
      "Epoch 51 of 60\n",
      "Epoch 52 of 60\n",
      "Epoch 53 of 60\n",
      "Epoch 54 of 60\n",
      "Epoch 55 of 60\n",
      "Epoch 56 of 60\n",
      "Epoch 57 of 60\n",
      "Epoch 58 of 60\n",
      "Epoch 59 of 60\n",
      "Epoch 60 of 60\n",
      "SO_GAAL ROC: 0.4756, precision @ rank n: 0.0, execution time: 0.137s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 10/10 [00:00<00:00, 51.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AutoEncoder ROC: 0.561, precision @ rank n: 0.0, execution time: 0.2098s\n",
      "AnoGAN ROC: 0.628, precision @ rank n: 0.0, execution time: 13.7568s\n",
      "Epoch 1/100, Loss: 3.2010475993156433\n",
      "Epoch 2/100, Loss: 3.2010475397109985\n",
      "Epoch 3/100, Loss: 3.2010475993156433\n",
      "Epoch 4/100, Loss: 3.2010475993156433\n",
      "Epoch 5/100, Loss: 3.2010475993156433\n",
      "Epoch 6/100, Loss: 3.201047658920288\n",
      "Epoch 7/100, Loss: 3.2010475397109985\n",
      "Epoch 8/100, Loss: 3.201047658920288\n",
      "Epoch 9/100, Loss: 3.2010475993156433\n",
      "Epoch 10/100, Loss: 3.201047658920288\n",
      "Epoch 11/100, Loss: 3.2010475993156433\n",
      "Epoch 12/100, Loss: 3.2010474801063538\n",
      "Epoch 13/100, Loss: 3.2010475993156433\n",
      "Epoch 14/100, Loss: 3.201047658920288\n",
      "Epoch 15/100, Loss: 3.2010475993156433\n",
      "Epoch 16/100, Loss: 3.2010475397109985\n",
      "Epoch 17/100, Loss: 3.201047658920288\n",
      "Epoch 18/100, Loss: 3.2010475397109985\n",
      "Epoch 19/100, Loss: 3.201047658920288\n",
      "Epoch 20/100, Loss: 3.201047658920288\n",
      "Epoch 21/100, Loss: 3.2010475397109985\n",
      "Epoch 22/100, Loss: 3.2010474801063538\n",
      "Epoch 23/100, Loss: 3.2010475993156433\n",
      "Epoch 24/100, Loss: 3.2010475993156433\n",
      "Epoch 25/100, Loss: 3.201047718524933\n",
      "Epoch 26/100, Loss: 3.201047420501709\n",
      "Epoch 27/100, Loss: 3.2010475993156433\n",
      "Epoch 28/100, Loss: 3.201047420501709\n",
      "Epoch 29/100, Loss: 3.201047658920288\n",
      "Epoch 30/100, Loss: 3.2010475397109985\n",
      "Epoch 31/100, Loss: 3.2010474801063538\n",
      "Epoch 32/100, Loss: 3.2010475993156433\n",
      "Epoch 33/100, Loss: 3.201047718524933\n",
      "Epoch 34/100, Loss: 3.2010475397109985\n",
      "Epoch 35/100, Loss: 3.2010474801063538\n",
      "Epoch 36/100, Loss: 3.2010474503040314\n",
      "Epoch 37/100, Loss: 3.2010477781295776\n",
      "Epoch 38/100, Loss: 3.2010478377342224\n",
      "Epoch 39/100, Loss: 3.2010475993156433\n",
      "Epoch 40/100, Loss: 3.201047718524933\n",
      "Epoch 41/100, Loss: 3.2010475397109985\n",
      "Epoch 42/100, Loss: 3.2010475397109985\n",
      "Epoch 43/100, Loss: 3.2010475993156433\n",
      "Epoch 44/100, Loss: 3.2010475993156433\n",
      "Epoch 45/100, Loss: 3.201047420501709\n",
      "Epoch 46/100, Loss: 3.2010475993156433\n",
      "Epoch 47/100, Loss: 3.2010475397109985\n",
      "Epoch 48/100, Loss: 3.2010475993156433\n",
      "Epoch 49/100, Loss: 3.201047718524933\n",
      "Epoch 50/100, Loss: 3.201047658920288\n",
      "Epoch 51/100, Loss: 3.201047658920288\n",
      "Epoch 52/100, Loss: 3.201047658920288\n",
      "Epoch 53/100, Loss: 3.201047658920288\n",
      "Epoch 54/100, Loss: 3.2010475993156433\n",
      "Epoch 55/100, Loss: 3.2010475993156433\n",
      "Epoch 56/100, Loss: 3.201047658920288\n",
      "Epoch 57/100, Loss: 3.201047658920288\n",
      "Epoch 58/100, Loss: 3.2010475993156433\n",
      "Epoch 59/100, Loss: 3.201047658920288\n",
      "Epoch 60/100, Loss: 3.201047658920288\n",
      "Epoch 61/100, Loss: 3.2010475993156433\n",
      "Epoch 62/100, Loss: 3.201047658920288\n",
      "Epoch 63/100, Loss: 3.201047360897064\n",
      "Epoch 64/100, Loss: 3.2010475993156433\n",
      "Epoch 65/100, Loss: 3.2010475993156433\n",
      "Epoch 66/100, Loss: 3.2010475993156433\n",
      "Epoch 67/100, Loss: 3.201047718524933\n",
      "Epoch 68/100, Loss: 3.2010475397109985\n",
      "Epoch 69/100, Loss: 3.201047718524933\n",
      "Epoch 70/100, Loss: 3.2010475397109985\n",
      "Epoch 71/100, Loss: 3.201047420501709\n",
      "Epoch 72/100, Loss: 3.2010475397109985\n",
      "Epoch 73/100, Loss: 3.201047658920288\n",
      "Epoch 74/100, Loss: 3.201047658920288\n",
      "Epoch 75/100, Loss: 3.2010475993156433\n",
      "Epoch 76/100, Loss: 3.201047658920288\n",
      "Epoch 77/100, Loss: 3.2010475993156433\n",
      "Epoch 78/100, Loss: 3.2010475397109985\n",
      "Epoch 79/100, Loss: 3.2010474801063538\n",
      "Epoch 80/100, Loss: 3.2010475993156433\n",
      "Epoch 81/100, Loss: 3.201047718524933\n",
      "Epoch 82/100, Loss: 3.2010475397109985\n",
      "Epoch 83/100, Loss: 3.201047658920288\n",
      "Epoch 84/100, Loss: 3.201047420501709\n",
      "Epoch 85/100, Loss: 3.2010476887226105\n",
      "Epoch 86/100, Loss: 3.2010474801063538\n",
      "Epoch 87/100, Loss: 3.2010475993156433\n",
      "Epoch 88/100, Loss: 3.2010475397109985\n",
      "Epoch 89/100, Loss: 3.2010475993156433\n",
      "Epoch 90/100, Loss: 3.201047658920288\n",
      "Epoch 91/100, Loss: 3.2010476291179657\n",
      "Epoch 92/100, Loss: 3.201047569513321\n",
      "Epoch 93/100, Loss: 3.201047420501709\n",
      "Epoch 94/100, Loss: 3.2010475397109985\n",
      "Epoch 95/100, Loss: 3.201047658920288\n",
      "Epoch 96/100, Loss: 3.201047658920288\n",
      "Epoch 97/100, Loss: 3.2010475993156433\n",
      "Epoch 98/100, Loss: 3.2010475993156433\n",
      "Epoch 99/100, Loss: 3.201047420501709\n",
      "Epoch 100/100, Loss: 3.2010475993156433\n",
      "DeepSVDD ROC: 0.4573, precision @ rank n: 0.0, execution time: 0.1831s\n",
      "ALAD ROC: 0.5305, precision @ rank n: 0.0, execution time: 1.9788s\n",
      "Epoch 10/50, Loss: 6.217249035835266\n",
      "Epoch 20/50, Loss: 6.065092086791992\n",
      "Epoch 30/50, Loss: 5.506428956985474\n",
      "Epoch 40/50, Loss: 4.243503749370575\n",
      "Epoch 50/50, Loss: 6.087799310684204\n",
      "AE1SVM ROC: 0.6189, precision @ rank n: 0.0, execution time: 1.8763s\n",
      "Original training size: 128, No. outliers: 2\n",
      "86 2 153 6\n",
      "Epoch 1, Loss: -1.3000997304916382\n",
      "Epoch 2, Loss: -14.24895191192627\n",
      "Epoch 3, Loss: -23.98811912536621\n",
      "Epoch 4, Loss: -32.85137939453125\n",
      "Epoch 5, Loss: -41.41780090332031\n",
      "Epoch 6, Loss: -49.51348114013672\n",
      "Epoch 7, Loss: -57.96425247192383\n",
      "Epoch 8, Loss: -66.23150634765625\n",
      "Epoch 9, Loss: -73.95845794677734\n",
      "Epoch 10, Loss: -82.83539581298828\n",
      "Epoch 11, Loss: -90.67761993408203\n",
      "Epoch 12, Loss: -99.70281982421875\n",
      "Epoch 13, Loss: -107.78092956542969\n",
      "Epoch 14, Loss: -115.9013442993164\n",
      "Epoch 15, Loss: -124.4553451538086\n",
      "Epoch 16, Loss: -133.31015014648438\n",
      "Epoch 17, Loss: -142.9747314453125\n",
      "Epoch 18, Loss: -151.87356567382812\n",
      "Epoch 19, Loss: -160.80064392089844\n",
      "Epoch 20, Loss: -169.56166076660156\n",
      "Epoch 21, Loss: -178.58570861816406\n",
      "Epoch 22, Loss: -187.94618225097656\n",
      "Epoch 23, Loss: -196.36045837402344\n",
      "Epoch 24, Loss: -206.26585388183594\n",
      "Epoch 25, Loss: -213.17442321777344\n",
      "Epoch 26, Loss: -223.2875518798828\n",
      "Epoch 27, Loss: -233.98089599609375\n",
      "Epoch 28, Loss: -243.33633422851562\n",
      "Epoch 29, Loss: -252.75775146484375\n",
      "Epoch 30, Loss: -262.1838684082031\n",
      "Epoch 31, Loss: -270.5535888671875\n",
      "Epoch 32, Loss: -280.8930969238281\n",
      "Epoch 33, Loss: -290.7140808105469\n",
      "Epoch 34, Loss: -300.28466796875\n",
      "Epoch 35, Loss: -308.993408203125\n",
      "Epoch 36, Loss: -316.7098693847656\n",
      "Epoch 37, Loss: -329.1123352050781\n",
      "Epoch 38, Loss: -337.8136901855469\n",
      "Epoch 39, Loss: -348.568359375\n",
      "Epoch 40, Loss: -357.1852111816406\n",
      "Epoch 41, Loss: -368.1474304199219\n",
      "Epoch 42, Loss: -377.1379699707031\n",
      "Epoch 43, Loss: -385.42718505859375\n",
      "Epoch 44, Loss: -397.7402648925781\n",
      "Epoch 45, Loss: -407.651123046875\n",
      "Epoch 46, Loss: -417.6387634277344\n",
      "Epoch 47, Loss: -427.6148681640625\n",
      "Epoch 48, Loss: -434.5616760253906\n",
      "Epoch 49, Loss: -444.1414489746094\n",
      "Epoch 50, Loss: -457.6091003417969\n",
      "DevNet ROC: 0.5335, precision @ rank n: 0.0, execution time: 0.2086s\n",
      "0/128\n",
      "25/128\n",
      "50/128\n",
      "75/128\n",
      "100/128\n",
      "125/128\n",
      "Test block 0/9\n",
      "0/138\n",
      "25/138\n",
      "50/138\n",
      "75/138\n",
      "100/138\n",
      "125/138\n",
      "Test block 1/9\n",
      "0/138\n",
      "25/138\n",
      "50/138\n",
      "75/138\n",
      "100/138\n",
      "125/138\n",
      "Test block 2/9\n",
      "0/138\n",
      "25/138\n",
      "50/138\n",
      "75/138\n",
      "100/138\n",
      "125/138\n",
      "Test block 3/9\n",
      "0/138\n",
      "25/138\n",
      "50/138\n",
      "75/138\n",
      "100/138\n",
      "125/138\n",
      "Test block 4/9\n",
      "0/138\n",
      "25/138\n",
      "50/138\n",
      "75/138\n",
      "100/138\n",
      "125/138\n",
      "Test block 5/9\n",
      "0/138\n",
      "25/138\n",
      "50/138\n",
      "75/138\n",
      "100/138\n",
      "125/138\n",
      "Test block 6/9\n",
      "0/138\n",
      "25/138\n",
      "50/138\n",
      "75/138\n",
      "100/138\n",
      "125/138\n",
      "Test block 7/9\n",
      "0/138\n",
      "25/138\n",
      "50/138\n",
      "75/138\n",
      "100/138\n",
      "125/138\n",
      "Test block 8/9\n",
      "0/134\n",
      "25/134\n",
      "50/134\n",
      "75/134\n",
      "100/134\n",
      "125/134\n",
      "RGraph ROC: 0.5274, precision @ rank n: 0.0, execution time: 4.1631s\n",
      "LUNAR ROC: 0.6707, precision @ rank n: 0.0, execution time: 3.702s\n",
      "\n",
      "... Processing ionosphere.mat ...\n",
      "Epoch 1 of 60\n",
      "Epoch 2 of 60\n",
      "Epoch 3 of 60\n",
      "Epoch 4 of 60\n",
      "Epoch 5 of 60\n",
      "Epoch 6 of 60\n",
      "Epoch 7 of 60\n",
      "Epoch 8 of 60\n",
      "Epoch 9 of 60\n",
      "Epoch 10 of 60\n",
      "Epoch 11 of 60\n",
      "Epoch 12 of 60\n",
      "Epoch 13 of 60\n",
      "Epoch 14 of 60\n",
      "Epoch 15 of 60\n",
      "Epoch 16 of 60\n",
      "Epoch 17 of 60\n",
      "Epoch 18 of 60\n",
      "Epoch 19 of 60\n",
      "Epoch 20 of 60\n",
      "Epoch 21 of 60\n",
      "Epoch 22 of 60\n",
      "Epoch 23 of 60\n",
      "Epoch 24 of 60\n",
      "Epoch 25 of 60\n",
      "Epoch 26 of 60\n",
      "Epoch 27 of 60\n",
      "Epoch 28 of 60\n",
      "Epoch 29 of 60\n",
      "Epoch 30 of 60\n",
      "Epoch 31 of 60\n",
      "Epoch 32 of 60\n",
      "Epoch 33 of 60\n",
      "Epoch 34 of 60\n",
      "Epoch 35 of 60\n",
      "Epoch 36 of 60\n",
      "Epoch 37 of 60\n",
      "Epoch 38 of 60\n",
      "Epoch 39 of 60\n",
      "Epoch 40 of 60\n",
      "Epoch 41 of 60\n",
      "Epoch 42 of 60\n",
      "Epoch 43 of 60\n",
      "Epoch 44 of 60\n",
      "Epoch 45 of 60\n",
      "Epoch 46 of 60\n",
      "Epoch 47 of 60\n",
      "Epoch 48 of 60\n",
      "Epoch 49 of 60\n",
      "Epoch 50 of 60\n",
      "Epoch 51 of 60\n",
      "Epoch 52 of 60\n",
      "Epoch 53 of 60\n",
      "Epoch 54 of 60\n",
      "Epoch 55 of 60\n",
      "Epoch 56 of 60\n",
      "Epoch 57 of 60\n",
      "Epoch 58 of 60\n",
      "Epoch 59 of 60\n",
      "Epoch 60 of 60\n",
      "MO_GAAL ROC: 0.7789, precision @ rank n: 0.6739, execution time: 0.5761s\n",
      "Epoch 1 of 60\n",
      "Epoch 2 of 60\n",
      "Epoch 3 of 60\n",
      "Epoch 4 of 60\n",
      "Epoch 5 of 60\n",
      "Epoch 6 of 60\n",
      "Epoch 7 of 60\n",
      "Epoch 8 of 60\n",
      "Epoch 9 of 60\n",
      "Epoch 10 of 60\n",
      "Epoch 11 of 60\n",
      "Epoch 12 of 60\n",
      "Epoch 13 of 60\n",
      "Epoch 14 of 60\n",
      "Epoch 15 of 60\n",
      "Epoch 16 of 60\n",
      "Epoch 17 of 60\n",
      "Epoch 18 of 60\n",
      "Epoch 19 of 60\n",
      "Epoch 20 of 60\n",
      "Epoch 21 of 60\n",
      "Epoch 22 of 60\n",
      "Epoch 23 of 60\n",
      "Epoch 24 of 60\n",
      "Epoch 25 of 60\n",
      "Epoch 26 of 60\n",
      "Epoch 27 of 60\n",
      "Epoch 28 of 60\n",
      "Epoch 29 of 60\n",
      "Epoch 30 of 60\n",
      "Epoch 31 of 60\n",
      "Epoch 32 of 60\n",
      "Epoch 33 of 60\n",
      "Epoch 34 of 60\n",
      "Epoch 35 of 60\n",
      "Epoch 36 of 60\n",
      "Epoch 37 of 60\n",
      "Epoch 38 of 60\n",
      "Epoch 39 of 60\n",
      "Epoch 40 of 60\n",
      "Epoch 41 of 60\n",
      "Epoch 42 of 60\n",
      "Epoch 43 of 60\n",
      "Epoch 44 of 60\n",
      "Epoch 45 of 60\n",
      "Epoch 46 of 60\n",
      "Epoch 47 of 60\n",
      "Epoch 48 of 60\n",
      "Epoch 49 of 60\n",
      "Epoch 50 of 60\n",
      "Epoch 51 of 60\n",
      "Epoch 52 of 60\n",
      "Epoch 53 of 60\n",
      "Epoch 54 of 60\n",
      "Epoch 55 of 60\n",
      "Epoch 56 of 60\n",
      "Epoch 57 of 60\n",
      "Epoch 58 of 60\n",
      "Epoch 59 of 60\n",
      "Epoch 60 of 60\n",
      "SO_GAAL ROC: 0.4838, precision @ rank n: 0.3261, execution time: 0.2449s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 10/10 [00:00<00:00, 35.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AutoEncoder ROC: 0.8435, precision @ rank n: 0.6522, execution time: 0.3043s\n",
      "AnoGAN ROC: 0.7895, precision @ rank n: 0.5652, execution time: 24.3891s\n",
      "Epoch 1/100, Loss: 7.921357691287994\n",
      "Epoch 2/100, Loss: 8.030775845050812\n",
      "Epoch 3/100, Loss: 8.10765814781189\n",
      "Epoch 4/100, Loss: 7.986689925193787\n",
      "Epoch 5/100, Loss: 7.972405552864075\n",
      "Epoch 6/100, Loss: 8.013543665409088\n",
      "Epoch 7/100, Loss: 8.173039436340332\n",
      "Epoch 8/100, Loss: 8.132040560245514\n",
      "Epoch 9/100, Loss: 8.053748488426208\n",
      "Epoch 10/100, Loss: 8.158176898956299\n",
      "Epoch 11/100, Loss: 8.000537633895874\n",
      "Epoch 12/100, Loss: 7.931086182594299\n",
      "Epoch 13/100, Loss: 8.042643427848816\n",
      "Epoch 14/100, Loss: 8.279706358909607\n",
      "Epoch 15/100, Loss: 7.955238521099091\n",
      "Epoch 16/100, Loss: 8.147838830947876\n",
      "Epoch 17/100, Loss: 8.23161506652832\n",
      "Epoch 18/100, Loss: 8.068905115127563\n",
      "Epoch 19/100, Loss: 8.19365644454956\n",
      "Epoch 20/100, Loss: 7.965809404850006\n",
      "Epoch 21/100, Loss: 7.936765968799591\n",
      "Epoch 22/100, Loss: 8.340260207653046\n",
      "Epoch 23/100, Loss: 8.094170272350311\n",
      "Epoch 24/100, Loss: 8.131231963634491\n",
      "Epoch 25/100, Loss: 7.9376025795936584\n",
      "Epoch 26/100, Loss: 7.872631013393402\n",
      "Epoch 27/100, Loss: 8.10527229309082\n",
      "Epoch 28/100, Loss: 8.135935425758362\n",
      "Epoch 29/100, Loss: 7.842932164669037\n",
      "Epoch 30/100, Loss: 8.188008785247803\n",
      "Epoch 31/100, Loss: 8.497725188732147\n",
      "Epoch 32/100, Loss: 8.100618124008179\n",
      "Epoch 33/100, Loss: 8.136941492557526\n",
      "Epoch 34/100, Loss: 8.260895371437073\n",
      "Epoch 35/100, Loss: 8.13731038570404\n",
      "Epoch 36/100, Loss: 7.920191407203674\n",
      "Epoch 37/100, Loss: 8.091071903705597\n",
      "Epoch 38/100, Loss: 8.264930963516235\n",
      "Epoch 39/100, Loss: 8.06171065568924\n",
      "Epoch 40/100, Loss: 8.03029078245163\n",
      "Epoch 41/100, Loss: 8.138296484947205\n",
      "Epoch 42/100, Loss: 8.038348495960236\n",
      "Epoch 43/100, Loss: 7.995338320732117\n",
      "Epoch 44/100, Loss: 8.037069439888\n",
      "Epoch 45/100, Loss: 8.163298606872559\n",
      "Epoch 46/100, Loss: 8.279587030410767\n",
      "Epoch 47/100, Loss: 7.990108370780945\n",
      "Epoch 48/100, Loss: 8.164315700531006\n",
      "Epoch 49/100, Loss: 8.055322647094727\n",
      "Epoch 50/100, Loss: 8.095026433467865\n",
      "Epoch 51/100, Loss: 7.914349913597107\n",
      "Epoch 52/100, Loss: 8.165332555770874\n",
      "Epoch 53/100, Loss: 7.857083022594452\n",
      "Epoch 54/100, Loss: 8.081693291664124\n",
      "Epoch 55/100, Loss: 8.06811273097992\n",
      "Epoch 56/100, Loss: 8.076023817062378\n",
      "Epoch 57/100, Loss: 7.969784259796143\n",
      "Epoch 58/100, Loss: 7.94008332490921\n",
      "Epoch 59/100, Loss: 7.952554643154144\n",
      "Epoch 60/100, Loss: 8.155449628829956\n",
      "Epoch 61/100, Loss: 8.207586646080017\n",
      "Epoch 62/100, Loss: 8.02039086818695\n",
      "Epoch 63/100, Loss: 7.997717320919037\n",
      "Epoch 64/100, Loss: 7.942947804927826\n",
      "Epoch 65/100, Loss: 8.145970940589905\n",
      "Epoch 66/100, Loss: 7.9350669384002686\n",
      "Epoch 67/100, Loss: 7.954392075538635\n",
      "Epoch 68/100, Loss: 7.937044560909271\n",
      "Epoch 69/100, Loss: 8.106382548809052\n",
      "Epoch 70/100, Loss: 8.03827166557312\n",
      "Epoch 71/100, Loss: 7.901196539402008\n",
      "Epoch 72/100, Loss: 7.959064185619354\n",
      "Epoch 73/100, Loss: 7.939586818218231\n",
      "Epoch 74/100, Loss: 7.935831129550934\n",
      "Epoch 75/100, Loss: 8.175571203231812\n",
      "Epoch 76/100, Loss: 8.065319776535034\n",
      "Epoch 77/100, Loss: 7.915957689285278\n",
      "Epoch 78/100, Loss: 8.1536363363266\n",
      "Epoch 79/100, Loss: 8.141571700572968\n",
      "Epoch 80/100, Loss: 8.072506308555603\n",
      "Epoch 81/100, Loss: 7.9671149253845215\n",
      "Epoch 82/100, Loss: 8.054691910743713\n",
      "Epoch 83/100, Loss: 8.055369794368744\n",
      "Epoch 84/100, Loss: 8.110094785690308\n",
      "Epoch 85/100, Loss: 8.13823652267456\n",
      "Epoch 86/100, Loss: 8.017236948013306\n",
      "Epoch 87/100, Loss: 7.996225833892822\n",
      "Epoch 88/100, Loss: 8.070310235023499\n",
      "Epoch 89/100, Loss: 8.022866368293762\n",
      "Epoch 90/100, Loss: 8.014356076717377\n",
      "Epoch 91/100, Loss: 7.883635997772217\n",
      "Epoch 92/100, Loss: 7.95615690946579\n",
      "Epoch 93/100, Loss: 7.996944427490234\n",
      "Epoch 94/100, Loss: 8.132649183273315\n",
      "Epoch 95/100, Loss: 8.058581829071045\n",
      "Epoch 96/100, Loss: 7.937285304069519\n",
      "Epoch 97/100, Loss: 8.127813398838043\n",
      "Epoch 98/100, Loss: 8.276620507240295\n",
      "Epoch 99/100, Loss: 8.029248178005219\n",
      "Epoch 100/100, Loss: 8.075631439685822\n",
      "DeepSVDD ROC: 0.832, precision @ rank n: 0.6304, execution time: 0.2843s\n",
      "ALAD ROC: 0.4579, precision @ rank n: 0.2609, execution time: 2.0203s\n",
      "Epoch 10/50, Loss: 8.07661315373012\n",
      "Epoch 20/50, Loss: 6.010691438402448\n",
      "Epoch 30/50, Loss: 6.072680473327637\n",
      "Epoch 40/50, Loss: 5.753279447555542\n",
      "Epoch 50/50, Loss: 6.341530118669782\n",
      "AE1SVM ROC: 0.8872, precision @ rank n: 0.6304, execution time: 3.1278s\n",
      "Original training size: 210, No. outliers: 717\n",
      "141 717 392 219\n",
      "Epoch 1, Loss: -20.838294982910156\n",
      "Epoch 2, Loss: -49.402015686035156\n",
      "Epoch 3, Loss: -87.9237060546875\n",
      "Epoch 4, Loss: -116.77406311035156\n",
      "Epoch 5, Loss: -178.27418518066406\n",
      "Epoch 6, Loss: -228.76890563964844\n",
      "Epoch 7, Loss: -275.0686950683594\n",
      "Epoch 8, Loss: -351.5153503417969\n",
      "Epoch 9, Loss: -374.7181701660156\n",
      "Epoch 10, Loss: -415.013427734375\n",
      "Epoch 11, Loss: -492.1528625488281\n",
      "Epoch 12, Loss: -550.2713623046875\n",
      "Epoch 13, Loss: -648.5963745117188\n",
      "Epoch 14, Loss: -668.30517578125\n",
      "Epoch 15, Loss: -721.3875732421875\n",
      "Epoch 16, Loss: -833.7562866210938\n",
      "Epoch 17, Loss: -950.2777099609375\n",
      "Epoch 18, Loss: -938.3923950195312\n",
      "Epoch 19, Loss: -937.92431640625\n",
      "Epoch 20, Loss: -1031.6649169921875\n",
      "Epoch 21, Loss: -1218.1578369140625\n",
      "Epoch 22, Loss: -1198.6953125\n",
      "Epoch 23, Loss: -1244.9830322265625\n",
      "Epoch 24, Loss: -1269.194091796875\n",
      "Epoch 25, Loss: -1413.4608154296875\n",
      "Epoch 26, Loss: -1536.7691650390625\n",
      "Epoch 27, Loss: -1663.91455078125\n",
      "Epoch 28, Loss: -1775.2271728515625\n",
      "Epoch 29, Loss: -1681.9765625\n",
      "Epoch 30, Loss: -1833.8641357421875\n",
      "Epoch 31, Loss: -1811.43115234375\n",
      "Epoch 32, Loss: -2072.778564453125\n",
      "Epoch 33, Loss: -2174.871826171875\n",
      "Epoch 34, Loss: -2112.699462890625\n",
      "Epoch 35, Loss: -2003.9720458984375\n",
      "Epoch 36, Loss: -2370.2197265625\n",
      "Epoch 37, Loss: -2247.74072265625\n",
      "Epoch 38, Loss: -2494.650634765625\n",
      "Epoch 39, Loss: -2475.923095703125\n",
      "Epoch 40, Loss: -2835.972900390625\n",
      "Epoch 41, Loss: -2726.62109375\n",
      "Epoch 42, Loss: -2880.641845703125\n",
      "Epoch 43, Loss: -2833.515869140625\n",
      "Epoch 44, Loss: -2664.75634765625\n",
      "Epoch 45, Loss: -3128.55859375\n",
      "Epoch 46, Loss: -2961.82763671875\n",
      "Epoch 47, Loss: -2924.359619140625\n",
      "Epoch 48, Loss: -3304.339111328125\n",
      "Epoch 49, Loss: -3010.52734375\n",
      "Epoch 50, Loss: -3295.794677734375\n",
      "DevNet ROC: 0.7227, precision @ rank n: 0.5435, execution time: 1.6063s\n",
      "0/210\n",
      "25/210\n",
      "50/210\n",
      "75/210\n",
      "100/210\n",
      "125/210\n",
      "150/210\n",
      "175/210\n",
      "200/210\n",
      "Test block 0/15\n",
      "0/220\n",
      "25/220\n",
      "50/220\n",
      "75/220\n",
      "100/220\n",
      "125/220\n",
      "150/220\n",
      "175/220\n",
      "200/220\n",
      "Test block 1/15\n",
      "0/220\n",
      "25/220\n",
      "50/220\n",
      "75/220\n",
      "100/220\n",
      "125/220\n",
      "150/220\n",
      "175/220\n",
      "200/220\n",
      "Test block 2/15\n",
      "0/220\n",
      "25/220\n",
      "50/220\n",
      "75/220\n",
      "100/220\n",
      "125/220\n",
      "150/220\n",
      "175/220\n",
      "200/220\n",
      "Test block 3/15\n",
      "0/220\n",
      "25/220\n",
      "50/220\n",
      "75/220\n",
      "100/220\n",
      "125/220\n",
      "150/220\n",
      "175/220\n",
      "200/220\n",
      "Test block 4/15\n",
      "0/220\n",
      "25/220\n",
      "50/220\n",
      "75/220\n",
      "100/220\n",
      "125/220\n",
      "150/220\n",
      "175/220\n",
      "200/220\n",
      "Test block 5/15\n",
      "0/220\n",
      "25/220\n",
      "50/220\n",
      "75/220\n",
      "100/220\n",
      "125/220\n",
      "150/220\n",
      "175/220\n",
      "200/220\n",
      "Test block 6/15\n",
      "0/220\n",
      "25/220\n",
      "50/220\n",
      "75/220\n",
      "100/220\n",
      "125/220\n",
      "150/220\n",
      "175/220\n",
      "200/220\n",
      "Test block 7/15\n",
      "0/220\n",
      "25/220\n",
      "50/220\n",
      "75/220\n",
      "100/220\n",
      "125/220\n",
      "150/220\n",
      "175/220\n",
      "200/220\n",
      "Test block 8/15\n",
      "0/220\n",
      "25/220\n",
      "50/220\n",
      "75/220\n",
      "100/220\n",
      "125/220\n",
      "150/220\n",
      "175/220\n",
      "200/220\n",
      "Test block 9/15\n",
      "0/220\n",
      "25/220\n",
      "50/220\n",
      "75/220\n",
      "100/220\n",
      "125/220\n",
      "150/220\n",
      "175/220\n",
      "200/220\n",
      "Test block 10/15\n",
      "0/220\n",
      "25/220\n",
      "50/220\n",
      "75/220\n",
      "100/220\n",
      "125/220\n",
      "150/220\n",
      "175/220\n",
      "200/220\n",
      "Test block 11/15\n",
      "0/220\n",
      "25/220\n",
      "50/220\n",
      "75/220\n",
      "100/220\n",
      "125/220\n",
      "150/220\n",
      "175/220\n",
      "200/220\n",
      "Test block 12/15\n",
      "0/220\n",
      "25/220\n",
      "50/220\n",
      "75/220\n",
      "100/220\n",
      "125/220\n",
      "150/220\n",
      "175/220\n",
      "200/220\n",
      "Test block 13/15\n",
      "0/220\n",
      "25/220\n",
      "50/220\n",
      "75/220\n",
      "100/220\n",
      "125/220\n",
      "150/220\n",
      "175/220\n",
      "200/220\n",
      "Test block 14/15\n",
      "0/211\n",
      "25/211\n",
      "50/211\n",
      "75/211\n",
      "100/211\n",
      "125/211\n",
      "150/211\n",
      "175/211\n",
      "200/211\n",
      "RGraph ROC: 0.2331, precision @ rank n: 0.0, execution time: 49.7426s\n",
      "LUNAR ROC: 0.9172, precision @ rank n: 0.8696, execution time: 3.5511s\n",
      "\n",
      "... Processing lympho.mat ...\n",
      "Epoch 1 of 60\n",
      "Epoch 2 of 60\n",
      "Epoch 3 of 60\n",
      "Epoch 4 of 60\n",
      "Epoch 5 of 60\n",
      "Epoch 6 of 60\n",
      "Epoch 7 of 60\n",
      "Epoch 8 of 60\n",
      "Epoch 9 of 60\n",
      "Epoch 10 of 60\n",
      "Epoch 11 of 60\n",
      "Epoch 12 of 60\n",
      "Epoch 13 of 60\n",
      "Epoch 14 of 60\n",
      "Epoch 15 of 60\n",
      "Epoch 16 of 60\n",
      "Epoch 17 of 60\n",
      "Epoch 18 of 60\n",
      "Epoch 19 of 60\n",
      "Epoch 20 of 60\n",
      "Epoch 21 of 60\n",
      "Epoch 22 of 60\n",
      "Epoch 23 of 60\n",
      "Epoch 24 of 60\n",
      "Epoch 25 of 60\n",
      "Epoch 26 of 60\n",
      "Epoch 27 of 60\n",
      "Epoch 28 of 60\n",
      "Epoch 29 of 60\n",
      "Epoch 30 of 60\n",
      "Epoch 31 of 60\n",
      "Epoch 32 of 60\n",
      "Epoch 33 of 60\n",
      "Epoch 34 of 60\n",
      "Epoch 35 of 60\n",
      "Epoch 36 of 60\n",
      "Epoch 37 of 60\n",
      "Epoch 38 of 60\n",
      "Epoch 39 of 60\n",
      "Epoch 40 of 60\n",
      "Epoch 41 of 60\n",
      "Epoch 42 of 60\n",
      "Epoch 43 of 60\n",
      "Epoch 44 of 60\n",
      "Epoch 45 of 60\n",
      "Epoch 46 of 60\n",
      "Epoch 47 of 60\n",
      "Epoch 48 of 60\n",
      "Epoch 49 of 60\n",
      "Epoch 50 of 60\n",
      "Epoch 51 of 60\n",
      "Epoch 52 of 60\n",
      "Epoch 53 of 60\n",
      "Epoch 54 of 60\n",
      "Epoch 55 of 60\n",
      "Epoch 56 of 60\n",
      "Epoch 57 of 60\n",
      "Epoch 58 of 60\n",
      "Epoch 59 of 60\n",
      "Epoch 60 of 60\n",
      "MO_GAAL ROC: 0.4971, precision @ rank n: 0.3333, execution time: 0.4787s\n",
      "Epoch 1 of 60\n",
      "Epoch 2 of 60\n",
      "Epoch 3 of 60\n",
      "Epoch 4 of 60\n",
      "Epoch 5 of 60\n",
      "Epoch 6 of 60\n",
      "Epoch 7 of 60\n",
      "Epoch 8 of 60\n",
      "Epoch 9 of 60\n",
      "Epoch 10 of 60\n",
      "Epoch 11 of 60\n",
      "Epoch 12 of 60\n",
      "Epoch 13 of 60\n",
      "Epoch 14 of 60\n",
      "Epoch 15 of 60\n",
      "Epoch 16 of 60\n",
      "Epoch 17 of 60\n",
      "Epoch 18 of 60\n",
      "Epoch 19 of 60\n",
      "Epoch 20 of 60\n",
      "Epoch 21 of 60\n",
      "Epoch 22 of 60\n",
      "Epoch 23 of 60\n",
      "Epoch 24 of 60\n",
      "Epoch 25 of 60\n",
      "Epoch 26 of 60\n",
      "Epoch 27 of 60\n",
      "Epoch 28 of 60\n",
      "Epoch 29 of 60\n",
      "Epoch 30 of 60\n",
      "Epoch 31 of 60\n",
      "Epoch 32 of 60\n",
      "Epoch 33 of 60\n",
      "Epoch 34 of 60\n",
      "Epoch 35 of 60\n",
      "Epoch 36 of 60\n",
      "Epoch 37 of 60\n",
      "Epoch 38 of 60\n",
      "Epoch 39 of 60\n",
      "Epoch 40 of 60\n",
      "Epoch 41 of 60\n",
      "Epoch 42 of 60\n",
      "Epoch 43 of 60\n",
      "Epoch 44 of 60\n",
      "Epoch 45 of 60\n",
      "Epoch 46 of 60\n",
      "Epoch 47 of 60\n",
      "Epoch 48 of 60\n",
      "Epoch 49 of 60\n",
      "Epoch 50 of 60\n",
      "Epoch 51 of 60\n",
      "Epoch 52 of 60\n",
      "Epoch 53 of 60\n",
      "Epoch 54 of 60\n",
      "Epoch 55 of 60\n",
      "Epoch 56 of 60\n",
      "Epoch 57 of 60\n",
      "Epoch 58 of 60\n",
      "Epoch 59 of 60\n",
      "Epoch 60 of 60\n",
      "SO_GAAL ROC: 0.3977, precision @ rank n: 0.3333, execution time: 0.0963s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 10/10 [00:00<00:00, 102.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AutoEncoder ROC: 1.0, precision @ rank n: 1.0, execution time: 0.112s\n",
      "AnoGAN ROC: 1.0, precision @ rank n: 1.0, execution time: 9.4266s\n",
      "Epoch 1/100, Loss: 2.2078898549079895\n",
      "Epoch 2/100, Loss: 2.213684618473053\n",
      "Epoch 3/100, Loss: 2.185956060886383\n",
      "Epoch 4/100, Loss: 2.2086670994758606\n",
      "Epoch 5/100, Loss: 2.2030729055404663\n",
      "Epoch 6/100, Loss: 2.221741259098053\n",
      "Epoch 7/100, Loss: 2.2205770015716553\n",
      "Epoch 8/100, Loss: 2.1961257457733154\n",
      "Epoch 9/100, Loss: 2.237293064594269\n",
      "Epoch 10/100, Loss: 2.1748898029327393\n",
      "Epoch 11/100, Loss: 2.2146159410476685\n",
      "Epoch 12/100, Loss: 2.201032519340515\n",
      "Epoch 13/100, Loss: 2.210383653640747\n",
      "Epoch 14/100, Loss: 2.2095858454704285\n",
      "Epoch 15/100, Loss: 2.182273507118225\n",
      "Epoch 16/100, Loss: 2.215256690979004\n",
      "Epoch 17/100, Loss: 2.218577742576599\n",
      "Epoch 18/100, Loss: 2.2309000492095947\n",
      "Epoch 19/100, Loss: 2.182823419570923\n",
      "Epoch 20/100, Loss: 2.2528615593910217\n",
      "Epoch 21/100, Loss: 2.169226288795471\n",
      "Epoch 22/100, Loss: 2.197996437549591\n",
      "Epoch 23/100, Loss: 2.2163959741592407\n",
      "Epoch 24/100, Loss: 2.236602246761322\n",
      "Epoch 25/100, Loss: 2.1868902444839478\n",
      "Epoch 26/100, Loss: 2.1876478791236877\n",
      "Epoch 27/100, Loss: 2.186587631702423\n",
      "Epoch 28/100, Loss: 2.1833885312080383\n",
      "Epoch 29/100, Loss: 2.1936169862747192\n",
      "Epoch 30/100, Loss: 2.1905298829078674\n",
      "Epoch 31/100, Loss: 2.1907098293304443\n",
      "Epoch 32/100, Loss: 2.220941185951233\n",
      "Epoch 33/100, Loss: 2.1930745244026184\n",
      "Epoch 34/100, Loss: 2.176065504550934\n",
      "Epoch 35/100, Loss: 2.160846710205078\n",
      "Epoch 36/100, Loss: 2.1800946593284607\n",
      "Epoch 37/100, Loss: 2.2145922780036926\n",
      "Epoch 38/100, Loss: 2.2003252506256104\n",
      "Epoch 39/100, Loss: 2.194559156894684\n",
      "Epoch 40/100, Loss: 2.171207070350647\n",
      "Epoch 41/100, Loss: 2.180631399154663\n",
      "Epoch 42/100, Loss: 2.2047407031059265\n",
      "Epoch 43/100, Loss: 2.2014260292053223\n",
      "Epoch 44/100, Loss: 2.2044700384140015\n",
      "Epoch 45/100, Loss: 2.2074636816978455\n",
      "Epoch 46/100, Loss: 2.223456859588623\n",
      "Epoch 47/100, Loss: 2.174995243549347\n",
      "Epoch 48/100, Loss: 2.1886295676231384\n",
      "Epoch 49/100, Loss: 2.220359981060028\n",
      "Epoch 50/100, Loss: 2.1824678778648376\n",
      "Epoch 51/100, Loss: 2.2007614374160767\n",
      "Epoch 52/100, Loss: 2.2018187642097473\n",
      "Epoch 53/100, Loss: 2.254359245300293\n",
      "Epoch 54/100, Loss: 2.188879430294037\n",
      "Epoch 55/100, Loss: 2.2020033597946167\n",
      "Epoch 56/100, Loss: 2.2228273153305054\n",
      "Epoch 57/100, Loss: 2.2227829098701477\n",
      "Epoch 58/100, Loss: 2.193140923976898\n",
      "Epoch 59/100, Loss: 2.1629638075828552\n",
      "Epoch 60/100, Loss: 2.176304578781128\n",
      "Epoch 61/100, Loss: 2.2426480054855347\n",
      "Epoch 62/100, Loss: 2.2065147161483765\n",
      "Epoch 63/100, Loss: 2.2195974588394165\n",
      "Epoch 64/100, Loss: 2.2178980708122253\n",
      "Epoch 65/100, Loss: 2.181669294834137\n",
      "Epoch 66/100, Loss: 2.2027750611305237\n",
      "Epoch 67/100, Loss: 2.237743556499481\n",
      "Epoch 68/100, Loss: 2.228065073490143\n",
      "Epoch 69/100, Loss: 2.2169647812843323\n",
      "Epoch 70/100, Loss: 2.201646566390991\n",
      "Epoch 71/100, Loss: 2.157926082611084\n",
      "Epoch 72/100, Loss: 2.2121938467025757\n",
      "Epoch 73/100, Loss: 2.2114094495773315\n",
      "Epoch 74/100, Loss: 2.200919985771179\n",
      "Epoch 75/100, Loss: 2.2283830642700195\n",
      "Epoch 76/100, Loss: 2.220145583152771\n",
      "Epoch 77/100, Loss: 2.18315851688385\n",
      "Epoch 78/100, Loss: 2.1529011130332947\n",
      "Epoch 79/100, Loss: 2.208178997039795\n",
      "Epoch 80/100, Loss: 2.2175066471099854\n",
      "Epoch 81/100, Loss: 2.1838901042938232\n",
      "Epoch 82/100, Loss: 2.166662812232971\n",
      "Epoch 83/100, Loss: 2.23123562335968\n",
      "Epoch 84/100, Loss: 2.1918063163757324\n",
      "Epoch 85/100, Loss: 2.2157869935035706\n",
      "Epoch 86/100, Loss: 2.1952080130577087\n",
      "Epoch 87/100, Loss: 2.228883922100067\n",
      "Epoch 88/100, Loss: 2.1932377219200134\n",
      "Epoch 89/100, Loss: 2.1821780800819397\n",
      "Epoch 90/100, Loss: 2.203913390636444\n",
      "Epoch 91/100, Loss: 2.2328116297721863\n",
      "Epoch 92/100, Loss: 2.173583507537842\n",
      "Epoch 93/100, Loss: 2.235518455505371\n",
      "Epoch 94/100, Loss: 2.190483868122101\n",
      "Epoch 95/100, Loss: 2.2515255212783813\n",
      "Epoch 96/100, Loss: 2.1834883093833923\n",
      "Epoch 97/100, Loss: 2.241326093673706\n",
      "Epoch 98/100, Loss: 2.1872023940086365\n",
      "Epoch 99/100, Loss: 2.163875699043274\n",
      "Epoch 100/100, Loss: 2.1835883259773254\n",
      "DeepSVDD ROC: 0.9766, precision @ rank n: 0.6667, execution time: 0.1654s\n",
      "ALAD ROC: 0.4503, precision @ rank n: 0.0, execution time: 2.153s\n",
      "Epoch 10/50, Loss: 8.113729000091553\n",
      "Epoch 20/50, Loss: 8.051623503367106\n",
      "Epoch 30/50, Loss: 8.047197182973227\n",
      "Epoch 40/50, Loss: 7.801077524820964\n",
      "Epoch 50/50, Loss: 8.31837828954061\n",
      "AE1SVM ROC: 1.0, precision @ rank n: 1.0, execution time: 1.5269s\n",
      "Original training size: 88, No. outliers: 443\n",
      "60 443 0 0\n",
      "Epoch 1, Loss: 0.6002205610275269\n",
      "Epoch 2, Loss: -7.507327556610107\n",
      "Epoch 3, Loss: -13.94773006439209\n",
      "Epoch 4, Loss: -19.479312896728516\n",
      "Epoch 5, Loss: -25.662437438964844\n",
      "Epoch 6, Loss: -31.093185424804688\n",
      "Epoch 7, Loss: -37.348514556884766\n",
      "Epoch 8, Loss: -42.5166130065918\n",
      "Epoch 9, Loss: -50.144195556640625\n",
      "Epoch 10, Loss: -54.01803970336914\n",
      "Epoch 11, Loss: -61.14984893798828\n",
      "Epoch 12, Loss: -67.97328186035156\n",
      "Epoch 13, Loss: -74.82940673828125\n",
      "Epoch 14, Loss: -83.00231170654297\n",
      "Epoch 15, Loss: -90.45433044433594\n",
      "Epoch 16, Loss: -94.8077392578125\n",
      "Epoch 17, Loss: -102.23504638671875\n",
      "Epoch 18, Loss: -109.89665985107422\n",
      "Epoch 19, Loss: -116.96563720703125\n",
      "Epoch 20, Loss: -124.20997619628906\n",
      "Epoch 21, Loss: -133.96926879882812\n",
      "Epoch 22, Loss: -136.90573120117188\n",
      "Epoch 23, Loss: -145.8280487060547\n",
      "Epoch 24, Loss: -156.15516662597656\n",
      "Epoch 25, Loss: -163.4238739013672\n",
      "Epoch 26, Loss: -172.64593505859375\n",
      "Epoch 27, Loss: -177.8197021484375\n",
      "Epoch 28, Loss: -182.5486602783203\n",
      "Epoch 29, Loss: -192.97604370117188\n",
      "Epoch 30, Loss: -201.42613220214844\n",
      "Epoch 31, Loss: -211.59262084960938\n",
      "Epoch 32, Loss: -215.13394165039062\n",
      "Epoch 33, Loss: -221.07310485839844\n",
      "Epoch 34, Loss: -232.54946899414062\n",
      "Epoch 35, Loss: -238.620849609375\n",
      "Epoch 36, Loss: -246.28173828125\n",
      "Epoch 37, Loss: -252.0323486328125\n",
      "Epoch 38, Loss: -266.23712158203125\n",
      "Epoch 39, Loss: -268.6694641113281\n",
      "Epoch 40, Loss: -279.045654296875\n",
      "Epoch 41, Loss: -293.2638244628906\n",
      "Epoch 42, Loss: -301.44549560546875\n",
      "Epoch 43, Loss: -310.694091796875\n",
      "Epoch 44, Loss: -322.9856262207031\n",
      "Epoch 45, Loss: -316.1067810058594\n",
      "Epoch 46, Loss: -329.8016052246094\n",
      "Epoch 47, Loss: -342.3417663574219\n",
      "Epoch 48, Loss: -350.6997375488281\n",
      "Epoch 49, Loss: -364.9230651855469\n",
      "Epoch 50, Loss: -370.3005065917969\n",
      "DevNet ROC: 0.0058, precision @ rank n: 0.0, execution time: 0.6124s\n",
      "0/88\n",
      "25/88\n",
      "50/88\n",
      "75/88\n",
      "Test block 0/7\n",
      "0/98\n",
      "25/98\n",
      "50/98\n",
      "75/98\n",
      "Test block 1/7\n",
      "0/98\n",
      "25/98\n",
      "50/98\n",
      "75/98\n",
      "Test block 2/7\n",
      "0/98\n",
      "25/98\n",
      "50/98\n",
      "75/98\n",
      "Test block 3/7\n",
      "0/98\n",
      "25/98\n",
      "50/98\n",
      "75/98\n",
      "Test block 4/7\n",
      "0/98\n",
      "25/98\n",
      "50/98\n",
      "75/98\n",
      "Test block 5/7\n",
      "0/98\n",
      "25/98\n",
      "50/98\n",
      "75/98\n",
      "Test block 6/7\n",
      "RGraph ROC: 0.6316, precision @ rank n: 0.0, execution time: 3.0226s\n",
      "LUNAR ROC: 0.9708, precision @ rank n: 0.6667, execution time: 3.2403s\n"
     ]
    }
   ],
   "source": [
    "# Define data file and read X and y\n",
    "mat_file_list = ['arrhythmia.mat',\n",
    "                 # 'cardio.mat',\n",
    "                 'glass.mat',\n",
    "                 'ionosphere.mat',\n",
    "                 # 'letter.mat',\n",
    "                 'lympho.mat',\n",
    "                 # 'mnist.mat',\n",
    "                 # 'musk.mat',\n",
    "                 # 'optdigits.mat',\n",
    "                 # 'pendigits.mat',\n",
    "                 # 'pima.mat',\n",
    "                 # 'satellite.mat',\n",
    "                 # 'satimage-2.mat',\n",
    "                 # 'shuttle.mat',\n",
    "                 # 'vertebral.mat',\n",
    "                 # 'vowels.mat',\n",
    "                 # 'wbc.mat'\n",
    "                 ]\n",
    "\n",
    "# Define outlier detection tools to be compared\n",
    "random_state = np.random.RandomState(42)\n",
    "\n",
    "#待添加：VAE\n",
    "df_columns = ['Data', '#Samples', '# Dimensions', 'Outlier Perc',\n",
    "              'MO_GAAL', 'SO_GAAL', 'AutoEncoder', 'AnoGAN', 'DeepSVDD', \n",
    "              'ALAD', 'AE1SVM', 'DevNet', 'RGraph', 'LUNAR']\n",
    "roc_df = pd.DataFrame(columns=df_columns)\n",
    "prn_df = pd.DataFrame(columns=df_columns)\n",
    "time_df = pd.DataFrame(columns=df_columns)\n",
    "\n",
    "for mat_file in mat_file_list:\n",
    "    print(\"\\n... Processing\", mat_file, '...')\n",
    "    mat = loadmat(os.path.join('data', mat_file))\n",
    "\n",
    "    X = mat['X']\n",
    "    y = mat['y'].ravel()\n",
    "    outliers_fraction = np.count_nonzero(y) / len(y)\n",
    "    outliers_percentage = round(outliers_fraction * 100, ndigits=4)\n",
    "    n_features = X.shape[1]\n",
    "\n",
    "    col_means = np.nanmean(X, axis=0)\n",
    "    inds = np.where(np.isnan(X))\n",
    "    X[inds] = np.take(col_means, inds[1])\n",
    "\n",
    "    if np.isnan(X).any():\n",
    "        raise ValueError(\"NaN values remain after attempting to replace with column means.\")\n",
    "\n",
    "    # Construct containers for saving results\n",
    "    roc_list = [mat_file[:-4], X.shape[0], X.shape[1], outliers_percentage]\n",
    "    prn_list = [mat_file[:-4], X.shape[0], X.shape[1], outliers_percentage]\n",
    "    time_list = [mat_file[:-4], X.shape[0], X.shape[1], outliers_percentage]\n",
    "\n",
    "    # 60% data for training and 40% for testing\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.4, random_state=random_state)\n",
    "\n",
    "    # Standardizing data for processing\n",
    "    X_train_norm, X_test_norm = standardizer(X_train, X_test)\n",
    "\n",
    "    classifiers = {\n",
    "        'MO_GAAL': MO_GAAL(contamination=outliers_fraction),\n",
    "        'SO_GAAL': SO_GAAL(contamination=outliers_fraction),\n",
    "        'AutoEncoder': AutoEncoder(contamination=outliers_fraction),\n",
    "        #'VAE': VAE(contamination=outliers_fraction),\n",
    "        'AnoGAN': AnoGAN(contamination=outliers_fraction),\n",
    "        'DeepSVDD': DeepSVDD(contamination=outliers_fraction, n_features=n_features),\n",
    "        'ALAD': ALAD(contamination=outliers_fraction),\n",
    "        'AE1SVM': AE1SVM(contamination=outliers_fraction),\n",
    "        'DevNet': DevNet(contamination=outliers_fraction),\n",
    "        'RGraph': RGraph(contamination=outliers_fraction),\n",
    "        'LUNAR': LUNAR(contamination=outliers_fraction)\n",
    "    }\n",
    "\n",
    "    for clf_name, clf in classifiers.items():\n",
    "        t0 = time()\n",
    "        if clf_name == 'DevNet':\n",
    "            clf.fit(X_train_norm, X_test)\n",
    "        else:\n",
    "            clf.fit(X_train_norm)\n",
    "        test_scores = clf.decision_function(X_test_norm)\n",
    "        t1 = time()\n",
    "        duration = round(t1 - t0, ndigits=4)\n",
    "        time_list.append(duration)\n",
    "\n",
    "        roc = round(roc_auc_score(y_test, test_scores), ndigits=4)\n",
    "        prn = round(precision_n_scores(y_test, test_scores), ndigits=4)\n",
    "\n",
    "        print(f'{clf_name} ROC: {roc}, precision @ rank n: {prn}, execution time: {duration}s')\n",
    "\n",
    "        roc_list.append(roc)\n",
    "        prn_list.append(prn)\n",
    "\n",
    "    temp_df = pd.DataFrame(time_list).transpose()\n",
    "    temp_df.columns = df_columns\n",
    "    time_df = pd.concat([time_df, temp_df], axis=0)\n",
    "\n",
    "    temp_df = pd.DataFrame(roc_list).transpose()\n",
    "    temp_df.columns = df_columns\n",
    "    roc_df = pd.concat([roc_df, temp_df], axis=0)\n",
    "\n",
    "    temp_df = pd.DataFrame(prn_list).transpose()\n",
    "    temp_df.columns = df_columns\n",
    "    prn_df = pd.concat([prn_df, temp_df], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time complexity\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Data</th>\n",
       "      <th>#Samples</th>\n",
       "      <th># Dimensions</th>\n",
       "      <th>Outlier Perc</th>\n",
       "      <th>MO_GAAL</th>\n",
       "      <th>SO_GAAL</th>\n",
       "      <th>AutoEncoder</th>\n",
       "      <th>AnoGAN</th>\n",
       "      <th>DeepSVDD</th>\n",
       "      <th>ALAD</th>\n",
       "      <th>AE1SVM</th>\n",
       "      <th>DevNet</th>\n",
       "      <th>RGraph</th>\n",
       "      <th>LUNAR</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>arrhythmia</td>\n",
       "      <td>452</td>\n",
       "      <td>274</td>\n",
       "      <td>14.6018</td>\n",
       "      <td>2.2194</td>\n",
       "      <td>0.7724</td>\n",
       "      <td>3.1156</td>\n",
       "      <td>52.4219</td>\n",
       "      <td>0.6767</td>\n",
       "      <td>3.3174</td>\n",
       "      <td>4.6475</td>\n",
       "      <td>52.4647</td>\n",
       "      <td>386.0246</td>\n",
       "      <td>4.632</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>glass</td>\n",
       "      <td>214</td>\n",
       "      <td>9</td>\n",
       "      <td>4.2056</td>\n",
       "      <td>0.5026</td>\n",
       "      <td>0.137</td>\n",
       "      <td>0.2098</td>\n",
       "      <td>13.7568</td>\n",
       "      <td>0.1831</td>\n",
       "      <td>1.9788</td>\n",
       "      <td>1.8763</td>\n",
       "      <td>0.2086</td>\n",
       "      <td>4.1631</td>\n",
       "      <td>3.702</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ionosphere</td>\n",
       "      <td>351</td>\n",
       "      <td>33</td>\n",
       "      <td>35.8974</td>\n",
       "      <td>0.5761</td>\n",
       "      <td>0.2449</td>\n",
       "      <td>0.3043</td>\n",
       "      <td>24.3891</td>\n",
       "      <td>0.2843</td>\n",
       "      <td>2.0203</td>\n",
       "      <td>3.1278</td>\n",
       "      <td>1.6063</td>\n",
       "      <td>49.7426</td>\n",
       "      <td>3.5511</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>lympho</td>\n",
       "      <td>148</td>\n",
       "      <td>18</td>\n",
       "      <td>4.0541</td>\n",
       "      <td>0.4787</td>\n",
       "      <td>0.0963</td>\n",
       "      <td>0.112</td>\n",
       "      <td>9.4266</td>\n",
       "      <td>0.1654</td>\n",
       "      <td>2.153</td>\n",
       "      <td>1.5269</td>\n",
       "      <td>0.6124</td>\n",
       "      <td>3.0226</td>\n",
       "      <td>3.2403</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Data #Samples # Dimensions Outlier Perc MO_GAAL SO_GAAL AutoEncoder  \\\n",
       "0  arrhythmia      452          274      14.6018  2.2194  0.7724      3.1156   \n",
       "0       glass      214            9       4.2056  0.5026   0.137      0.2098   \n",
       "0  ionosphere      351           33      35.8974  0.5761  0.2449      0.3043   \n",
       "0      lympho      148           18       4.0541  0.4787  0.0963       0.112   \n",
       "\n",
       "    AnoGAN DeepSVDD    ALAD  AE1SVM   DevNet    RGraph   LUNAR  \n",
       "0  52.4219   0.6767  3.3174  4.6475  52.4647  386.0246   4.632  \n",
       "0  13.7568   0.1831  1.9788  1.8763   0.2086    4.1631   3.702  \n",
       "0  24.3891   0.2843  2.0203  3.1278   1.6063   49.7426  3.5511  \n",
       "0   9.4266   0.1654   2.153  1.5269   0.6124    3.0226  3.2403  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('Time complexity')\n",
    "time_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Analyze the performance of ROC and Precision @ n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC Performance\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Data</th>\n",
       "      <th>#Samples</th>\n",
       "      <th># Dimensions</th>\n",
       "      <th>Outlier Perc</th>\n",
       "      <th>MO_GAAL</th>\n",
       "      <th>SO_GAAL</th>\n",
       "      <th>AutoEncoder</th>\n",
       "      <th>AnoGAN</th>\n",
       "      <th>DeepSVDD</th>\n",
       "      <th>ALAD</th>\n",
       "      <th>AE1SVM</th>\n",
       "      <th>DevNet</th>\n",
       "      <th>RGraph</th>\n",
       "      <th>LUNAR</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>arrhythmia</td>\n",
       "      <td>452</td>\n",
       "      <td>274</td>\n",
       "      <td>14.6018</td>\n",
       "      <td>0.6153</td>\n",
       "      <td>0.6179</td>\n",
       "      <td>0.8096</td>\n",
       "      <td>0.7726</td>\n",
       "      <td>0.7915</td>\n",
       "      <td>0.5257</td>\n",
       "      <td>0.818</td>\n",
       "      <td>0.4288</td>\n",
       "      <td>0.7241</td>\n",
       "      <td>0.8284</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>glass</td>\n",
       "      <td>214</td>\n",
       "      <td>9</td>\n",
       "      <td>4.2056</td>\n",
       "      <td>0.686</td>\n",
       "      <td>0.4756</td>\n",
       "      <td>0.561</td>\n",
       "      <td>0.628</td>\n",
       "      <td>0.4573</td>\n",
       "      <td>0.5305</td>\n",
       "      <td>0.6189</td>\n",
       "      <td>0.5335</td>\n",
       "      <td>0.5274</td>\n",
       "      <td>0.6707</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ionosphere</td>\n",
       "      <td>351</td>\n",
       "      <td>33</td>\n",
       "      <td>35.8974</td>\n",
       "      <td>0.7789</td>\n",
       "      <td>0.4838</td>\n",
       "      <td>0.8435</td>\n",
       "      <td>0.7895</td>\n",
       "      <td>0.832</td>\n",
       "      <td>0.4579</td>\n",
       "      <td>0.8872</td>\n",
       "      <td>0.7227</td>\n",
       "      <td>0.2331</td>\n",
       "      <td>0.9172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>lympho</td>\n",
       "      <td>148</td>\n",
       "      <td>18</td>\n",
       "      <td>4.0541</td>\n",
       "      <td>0.4971</td>\n",
       "      <td>0.3977</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.9766</td>\n",
       "      <td>0.4503</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0058</td>\n",
       "      <td>0.6316</td>\n",
       "      <td>0.9708</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Data #Samples # Dimensions Outlier Perc MO_GAAL SO_GAAL AutoEncoder  \\\n",
       "0  arrhythmia      452          274      14.6018  0.6153  0.6179      0.8096   \n",
       "0       glass      214            9       4.2056   0.686  0.4756       0.561   \n",
       "0  ionosphere      351           33      35.8974  0.7789  0.4838      0.8435   \n",
       "0      lympho      148           18       4.0541  0.4971  0.3977         1.0   \n",
       "\n",
       "   AnoGAN DeepSVDD    ALAD  AE1SVM  DevNet  RGraph   LUNAR  \n",
       "0  0.7726   0.7915  0.5257   0.818  0.4288  0.7241  0.8284  \n",
       "0   0.628   0.4573  0.5305  0.6189  0.5335  0.5274  0.6707  \n",
       "0  0.7895    0.832  0.4579  0.8872  0.7227  0.2331  0.9172  \n",
       "0     1.0   0.9766  0.4503     1.0  0.0058  0.6316  0.9708  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('ROC Performance')\n",
    "roc_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "roc_df.to_csv('roc_df.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "''' \n",
    "answer from llm:\n",
    "- arrhythmia: AutoEncoder/vae\n",
    "- glass: mogaal/sogaal\n",
    "- ionosphere: auto/vae\n",
    "- lympho: mogaal/sogaal\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision @ n Performance\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Data</th>\n",
       "      <th>#Samples</th>\n",
       "      <th># Dimensions</th>\n",
       "      <th>Outlier Perc</th>\n",
       "      <th>MO_GAAL</th>\n",
       "      <th>SO_GAAL</th>\n",
       "      <th>AutoEncoder</th>\n",
       "      <th>AnoGAN</th>\n",
       "      <th>DeepSVDD</th>\n",
       "      <th>ALAD</th>\n",
       "      <th>AE1SVM</th>\n",
       "      <th>DevNet</th>\n",
       "      <th>RGraph</th>\n",
       "      <th>LUNAR</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>arrhythmia</td>\n",
       "      <td>452</td>\n",
       "      <td>274</td>\n",
       "      <td>14.6018</td>\n",
       "      <td>0.3214</td>\n",
       "      <td>0.3571</td>\n",
       "      <td>0.3929</td>\n",
       "      <td>0.4286</td>\n",
       "      <td>0.4286</td>\n",
       "      <td>0.0714</td>\n",
       "      <td>0.3929</td>\n",
       "      <td>0.2143</td>\n",
       "      <td>0.3571</td>\n",
       "      <td>0.4643</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>glass</td>\n",
       "      <td>214</td>\n",
       "      <td>9</td>\n",
       "      <td>4.2056</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ionosphere</td>\n",
       "      <td>351</td>\n",
       "      <td>33</td>\n",
       "      <td>35.8974</td>\n",
       "      <td>0.6739</td>\n",
       "      <td>0.3261</td>\n",
       "      <td>0.6522</td>\n",
       "      <td>0.5652</td>\n",
       "      <td>0.6304</td>\n",
       "      <td>0.2609</td>\n",
       "      <td>0.6304</td>\n",
       "      <td>0.5435</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.8696</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>lympho</td>\n",
       "      <td>148</td>\n",
       "      <td>18</td>\n",
       "      <td>4.0541</td>\n",
       "      <td>0.3333</td>\n",
       "      <td>0.3333</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.6667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.6667</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Data #Samples # Dimensions Outlier Perc MO_GAAL SO_GAAL AutoEncoder  \\\n",
       "0  arrhythmia      452          274      14.6018  0.3214  0.3571      0.3929   \n",
       "0       glass      214            9       4.2056    0.25     0.0         0.0   \n",
       "0  ionosphere      351           33      35.8974  0.6739  0.3261      0.6522   \n",
       "0      lympho      148           18       4.0541  0.3333  0.3333         1.0   \n",
       "\n",
       "   AnoGAN DeepSVDD    ALAD  AE1SVM  DevNet  RGraph   LUNAR  \n",
       "0  0.4286   0.4286  0.0714  0.3929  0.2143  0.3571  0.4643  \n",
       "0     0.0      0.0     0.0     0.0     0.0     0.0     0.0  \n",
       "0  0.5652   0.6304  0.2609  0.6304  0.5435     0.0  0.8696  \n",
       "0     1.0   0.6667     0.0     1.0     0.0     0.0  0.6667  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('Precision @ n Performance')\n",
    "prn_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summarize model/dataset features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 数据集信息\n",
    "data_info = {\n",
    "    \"Dataset\": [\"arrhythmia\", \"glass\", \"ionosphere\", \"lympho\"],\n",
    "    \"Domain\": [\"Medical\", \"Forensic Science\", \"Astronomy\", \"Medical\"],\n",
    "    \"Data Type\": [\"Multivariate\", \"Multivariate\", \"Multivariate\", \"Multivariate\"],\n",
    "    \"Number of Instances\": [452, 214, 351, 148],\n",
    "    \"Number of Attributes\": [279, 9, 34, 18],\n",
    "    \"Missing Values\": [\"Yes\", \"No\", \"No\", \"No\"],\n",
    "    \"Area\": [\"Cardiology\", \"Material Identification\", \"Space\", \"Oncology\"]\n",
    "}\n",
    "\n",
    "# 创建 DataFrame\n",
    "df = pd.DataFrame(data_info)\n",
    "\n",
    "# 将 DataFrame 保存为 CSV 文件\n",
    "csv_file_path = 'dataset_hyperparam.csv'\n",
    "df.to_csv(csv_file_path, index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.io import loadmat\n",
    "import os\n",
    "\n",
    "def calculate_descriptive_statistics(data_path, dataset_names):\n",
    "    stats = []\n",
    "    for dataset in dataset_names:\n",
    "        mat = loadmat(os.path.join(data_path, dataset))\n",
    "        X = mat['X']\n",
    "        y = mat['y'].ravel()\n",
    "        \n",
    "        # 计算统计数据\n",
    "        mean_vals = np.mean(X, axis=0)\n",
    "        std_devs = np.std(X, axis=0)\n",
    "        min_vals = np.min(X, axis=0)\n",
    "        max_vals = np.max(X, axis=0)\n",
    "        \n",
    "        # 计算整体描述性统计\n",
    "        overall_stats = {\n",
    "            'mean': np.mean(mean_vals),\n",
    "            'std_dev': np.mean(std_devs),\n",
    "            'min': np.min(min_vals),\n",
    "            'max': np.max(max_vals)\n",
    "        }\n",
    "        stats.append(overall_stats)\n",
    "    return stats\n",
    "\n",
    "\n",
    "data_path = 'data'\n",
    "stats = calculate_descriptive_statistics(data_path, mat_file_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Dataset            Domain     Data Type  Number of Instances  \\\n",
      "0  arrhythmia           Medical  Multivariate                  452   \n",
      "1       glass  Forensic Science  Multivariate                  214   \n",
      "2  ionosphere         Astronomy  Multivariate                  351   \n",
      "3      lympho           Medical  Multivariate                  148   \n",
      "\n",
      "   Number of Attributes Missing Values                     Area       Mean  \\\n",
      "0                   279            Yes               Cardiology  10.125108   \n",
      "1                     9             No  Material Identification  11.265852   \n",
      "2                    34             No                    Space   0.255203   \n",
      "3                    18             No                 Oncology   2.074700   \n",
      "\n",
      "    Std Dev    Min     Max  \n",
      "0  6.546009 -242.4  780.00  \n",
      "1  0.687928    0.0   75.41  \n",
      "2  0.525138   -1.0    1.00  \n",
      "3  0.699778    1.0    8.00  \n"
     ]
    }
   ],
   "source": [
    "df = pd.DataFrame(data_info)\n",
    "\n",
    "# 将统计数据加入 DataFrame\n",
    "for i, stat in enumerate(stats):\n",
    "    df.loc[i, 'Mean'] = stat['mean']\n",
    "    df.loc[i, 'Std Dev'] = stat['std_dev']\n",
    "    df.loc[i, 'Min'] = stat['min']\n",
    "    df.loc[i, 'Max'] = stat['max']\n",
    "\n",
    "print(df)\n",
    "df.to_csv('updated_dataset_information.csv', index=False)\n",
    "\n",
    "# 对照试验？提供哪些信息准确率更高\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model信息1：code details\n",
    "\n",
    "code_summaries = {\n",
    "    'MO-GAAL': \"\"\"\n",
    "1. MO-GAAL (Multiple Objective Generative Adversarial Active Learning) is an outlier detection algorithm based on Generative Adversarial Networks (GANs). It uses multiple sub-generators, each with different objectives, to generate outliers, aiding in separating outliers from normal data. This also helps avoid mode collapse, where the generator produces limited sample variety. The model uses a discriminator to distinguish between real and generated outliers and a generator to produce potential outliers.\n",
    "\n",
    "2. Advantages include its ability to discover complex outlier structures and improve detection performance, overcoming mode collapse. Disadvantages include the computational expense of training multiple GANs and the need for careful hyperparameter tuning. It may lack interpretability, as deep learning models often act as black boxes.\n",
    "\n",
    "3. MO-GAAL performs well on high-dimensional data with complex patterns. However, it may be excessive for simpler datasets where more efficient methods could suffice, and it may not be suitable when interpretability is critical.\n",
    "\"\"\",\n",
    "    \n",
    "    'SO-GAAL': \"\"\"\n",
    "1. SO-GAAL (Single-Objective Generative Adversarial Active Learning) is an outlier detection model using a GAN setup with one generator and one discriminator. The generator produces synthetic data, while the discriminator distinguishes between real and generated data. The model uses generated examples as potential outliers to learn boundaries between normal data and outliers.\n",
    "\n",
    "2. Its advantages include dynamic learning and adaptability, especially when outliers are rare. However, the model may suffer from mode collapse, generating overly similar or 'good' examples, which could limit its effectiveness.\n",
    "\n",
    "3. SO-GAAL works well on datasets with rare outliers or complex feature structures but may struggle when outliers cannot be well approximated by the generator or when there are only minor distinctions between normal and outlier data.\n",
    "\"\"\",\n",
    "    \n",
    "    'AutoEncoder': \"\"\"\n",
    "1. This model is based on an AutoEncoder, a neural network used for unsupervised data representation learning. It compresses input data into a low-dimensional code via an encoder and reconstructs it through a decoder. Outliers are detected based on their reconstruction errors, as they typically deviate from normal instances. The model uses ReLU activation, dropout, and batch normalization to prevent overfitting.\n",
    "\n",
    "2. AutoEncoders are unsupervised and adaptable, making them versatile across various datasets. However, they are sensitive to hyperparameter selection and may struggle to preserve global data structures.\n",
    "\n",
    "3. AutoEncoders perform well on structured data like images or sequences but may struggle on noisy or scalar data with no inherent structure, where simpler methods could be more efficient.\n",
    "\"\"\",\n",
    "    \n",
    "    'AnoGAN': \"\"\"\n",
    "1. AnoGAN uses GANs for outlier detection, with a generator and discriminator. It uses standard GAN training followed by training a separate query model to find the closest latent space point for each data instance. Outliers are detected based on their reconstruction error in the latent space.\n",
    "\n",
    "2. AnoGAN is effective for modeling complex, high-dimensional data and handles both numerical and categorical data. However, it is computationally expensive, and GAN training is known to be unstable.\n",
    "\n",
    "3. AnoGAN excels on complex datasets like images or medical scans but may struggle with simpler or imbalanced datasets, where traditional outlier detection methods might be more appropriate.\n",
    "\"\"\",\n",
    "    \n",
    "    'Deep SVDD': \"\"\"\n",
    "1. Deep SVDD aims to minimize the volume of a hypersphere enclosing the network representations of data during training. It detects outliers by measuring the distance from the center. The architecture is customizable, allowing users to define the network layers and activation functions. It can also operate in autoencoder mode, where the encoder-decoder structure mirrors itself.\n",
    "\n",
    "2. Advantages include unsupervised learning, flexibility in network architecture, and regularization options like dropout and L2. Disadvantages involve the need for trial-and-error hyperparameter tuning and the requirement of large datasets for effective training.\n",
    "\n",
    "3. Deep SVDD performs well on datasets with identifiable patterns but struggles with noisy, imbalanced, or complex datasets where outliers are not easily separable from normal data.\n",
    "\"\"\",\n",
    "    \n",
    "    'ALAD': \"\"\"\n",
    "1. ALAD uses a GAN architecture with an encoder, a generator, and three discriminators to distinguish real from generated data. The model can also incorporate reconstruction loss for improved performance.\n",
    "\n",
    "2. ALAD excels at detecting complex patterns and works well on high-dimensional data. However, it requires substantial computational resources and may perform poorly when the data distribution is difficult to learn or when the dataset is small.\n",
    "\n",
    "3. ALAD is effective for complex, high-dimensional datasets but may struggle with small or simple datasets, where traditional methods might be more efficient.\n",
    "\"\"\",\n",
    "\n",
    "    'AE1SVM' : \"\"\"\n",
    "\n",
    "1. This model combines an Autoencoder (AE) with a One-Class Support Vector Machine (SVM) to detect outliers. The Autoencoder learns a compressed representation of the data through encoding and decoding layers, while the One-Class SVM works on the encoded data's random Fourier features to separate normal data from outliers. The architecture uses hidden layers with customizable neurons, ReLU activations, batch normalization, and dropout for regularization. By utilizing random Fourier features in the SVM, it approximates a kernel function, allowing for non-linear decision boundaries to better distinguish outliers.\n",
    "\n",
    "2. Advantages: The model can capture complex data patterns through the Autoencoder's deep structure and the SVM’s non-linear decision boundaries, providing enhanced outlier detection in non-linearly separable data. Batch normalization and dropout improve training stability and prevent overfitting. Disadvantages: It is computationally expensive, especially with a large number of random Fourier features. Training this model may be time-consuming due to the Autoencoder and SVM combination, which could also make it less effective on small datasets or real-time applications.\n",
    "\n",
    "3. Good performance: This model is ideal for large datasets with high dimensionality and complex, non-linear patterns, where normal and anomalous data have distinguishable structures. Poor performance: It may perform poorly on small datasets, highly noisy datasets, or data with simple, linear separations between normal and anomalous points, as the model's complexity could lead to overfitting or unnecessary computation.\n",
    "\"\"\",\n",
    "\n",
    "    'DevNet' : \"\"\"\n",
    "\n",
    "1. DevNet's architecture varies in depth with options for shallow or deep networks, which include three specific models: DevNetD (3 hidden layers), DevNetS (1 hidden layer), and DevNetLinear (no hidden layer). These configurations allow flexible model complexity based on data needs. Each hidden layer uses ReLU activations, which helps capture non-linear patterns in the data. The model uses a specialized deviation loss, which applies Z-score deviation based on the assumption that inliers and outliers deviate from a reference distribution differently, optimizing the model to distinguish between them effectively.\n",
    "\n",
    "2. Advantages: The flexibility of choosing the network depth makes it adaptable to various data complexities. The deviation loss function is tailored for outlier detection, providing direct optimization for distinguishing anomalies from normal instances. Disadvantages: Deep models, such as DevNetD, could overfit on small datasets with limited diversity, potentially reducing generalizability. The model may struggle with datasets containing subtle or high-dimensional anomalies that are hard to capture with simple linear layers. Training a deep network can be computationally expensive and requires considerable tuning, especially on larger datasets.\n",
    "\n",
    "3. Good Performance: DevNet will likely perform well on datasets where the outliers exhibit distinct characteristics from the inliers, particularly if the data is moderately complex with features that can be captured by shallow or deep neural networks (e.g., low-dimensional structured data or data with clear, distinguishable outlier patterns). Poor Performance: The model might struggle on high-dimensional datasets where anomalies are subtle and require more sophisticated feature extraction than linear layers can provide. Additionally, if the outliers do not significantly deviate from the inliers, the deviation-based loss function may not effectively identify them.\n",
    "\"\"\",\n",
    "\n",
    "    'RGraph' : \"\"\"\n",
    "\n",
    "1. The RGraph model uses an elastic net subspace clustering technique with a graph-based transition matrix to represent data self-representation and outlier scoring. It combines elements of sparse representation (via the Lasso and linear regression) and an active support strategy to optimize computations, especially for large datasets. It detects outliers by constructing a transition matrix normalized by L1, followed by transition steps that propagate a probability vector through this matrix. Lower scores from this transition process signify outliers.\n",
    "\n",
    "2. Advantages: It handles high-dimensional data well due to its reliance on sparse representations. The active support algorithm can optimize the process, making it scalable for large datasets. Disadvantages: The model may be computationally intensive, especially if the active support is not correctly tuned, as it iteratively solves optimization problems. Sensitivity to hyperparameters (like tau, gamma) can make the model difficult to tune, potentially impacting performance on noisy data.\n",
    "\n",
    "3. Good performance: This model should perform well on high-dimensional, sparse datasets where data points reside in low-dimensional subspaces (e.g., image or signal data with natural clusters). Poor performance: It may struggle on dense, low-dimensional datasets with strong non-linear relationships, as its linear clustering technique might not capture complex patterns, potentially leading to poor outlier identification.\n",
    "\"\"\",\n",
    "\n",
    "    'LUNAR' : \"\"\"\n",
    "\n",
    "1. The LUNAR model uses graph neural networks to unify local outlier detection methods by leveraging nearest neighbors. Its architecture consists of two neural networks, SCORE_MODEL and WEIGHT_MODEL, each with three hidden layers of 256 units. The activation functions differ: SCORE_MODEL uses Tanh activations and a Sigmoid output, while WEIGHT_MODEL uses ReLU activations with a final layer normalizing weights via LayerNorm and BatchNorm. LUNAR generates anomaly scores by evaluating the distance between data points and their nearest neighbors and employs a unique negative sampling approach, using random uniform and subspace perturbations to simulate outliers.\n",
    "\n",
    "2. Advantages: Flexibility: LUNAR's dual model approach allows for adaptability in scoring based on different types of outliers. Local Context Awareness: By focusing on k-nearest neighbors, it effectively captures local data structures, which can improve the detection of local outliers. Robust Sampling: The negative sampling technique enhances training by simulating diverse outlier types, potentially improving detection accuracy. Disadvantages: Computationally Intensive: The model’s reliance on neural networks and nearest neighbor searches could lead to high computational costs, particularly on large datasets. Hyperparameter Sensitivity: Its performance is likely sensitive to parameters like n_neighbors, sampling proportion, and model type, which may require fine-tuning for optimal results.\n",
    "\n",
    "3. Good Performance: The model will likely excel on datasets with well-defined clusters or local structures where outliers are distinct from the majority class. Examples include structured datasets like social network data, sensor data, and geospatial data. Poor Performance: LUNAR may struggle on high-dimensional or noisy datasets where local neighborhood relationships are less meaningful or when the data is too sparse, making it difficult to discern local outliers effectively.\n",
    "\"\"\"\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model信息2：paper summarize\n",
    "\n",
    "#model信息2：paper summarize\n",
    "\n",
    "paper_summaries = {\n",
    "    'MO-GAAL': \"MO-GAAL addresses the limitations of SO-GAAL by using multiple generators, each tasked with generating different types of outliers. This approach mitigates the mode collapse problem by creating a mixture of reference distributions, enabling more robust and accurate outlier detection across datasets with various data types and dimensions\",\n",
    "    \n",
    "    'SO-GAAL': \"SO-GAAL generates potential outliers using a single generator in a Generative Adversarial Network (GAN) framework, which plays a mini-max game with a discriminator. The generator synthesizes informative outliers that help the discriminator distinguish between normal data and anomalies. However, SO-GAAL can suffer from mode collapse, where the generator fails to provide diverse enough outliers, limiting its detection ability\",\n",
    "    \n",
    "    'AutoEncoder': \"AutoEncoder is a neural network model primarily used for unsupervised anomaly detection. It works by encoding input data into a lower-dimensional latent space and then reconstructing it back into the original space. Anomalies are detected by measuring the reconstruction error: normal data is reconstructed with minimal error, while anomalies yield higher reconstruction errors. AutoEncoder is particularly suited for structured and tabular data, and its performance can be tuned by adjusting the network’s architecture, including the number of hidden layers and nodes. It is effective for detecting subtle anomalies in complex datasets.\",\n",
    "    \n",
    "    'AnoGAN': \"AnoGAN is an unsupervised learning model that detects anomalies by learning a representation of normal data using a Generative Adversarial Network (GAN). It identifies anomalies by mapping new data to a latent space and calculating how well the new data fits within the learned normal distribution. The model is particularly effective for image-based anomaly detection and was initially applied to medical imaging, where it detects anomalous regions that deviate from the learned healthy patterns.\",\n",
    "    \n",
    "    'Deep SVDD': \"DeepSVDD is a deep learning-based anomaly detection method that extends the classical SVDD (Support Vector Data Description) approach. It learns a compact representation of the data by mapping input samples to a hypersphere of minimum volume in a feature space. The goal is to enclose normal data within the hypersphere, while outliers are mapped outside of it. DeepSVDD avoids the need for explicit feature engineering and works effectively on high-dimensional data, particularly image datasets. It is trained using a one-class objective to ensure that the majority of normal data is close to the hypersphere center, making it suitable for unsupervised anomaly detection.\",\n",
    "    \n",
    "    'ALAD': \"ALAD is a GAN-based anomaly detection method that incorporates an encoder and discriminator to learn a latent representation of normal data. It leverages bi-directional GANs and cycle-consistency to map data samples to and from a latent space, enabling faster and more accurate anomaly detection. ALAD focuses on improving reconstruction error for anomaly detection by utilizing adversarially learned features, ensuring that both the data space and the latent space are well represented. This method enhances performance and stability, particularly in high-dimensional datasets, and is much faster at inference than traditional GAN-based methods\",\n",
    "    \n",
    "    'AE1SVM': \"AE1SVM (Autoencoder-based One-Class SVM) combines an autoencoder with a one-class support vector machine (OC-SVM) for anomaly detection in high-dimensional datasets. The autoencoder is used for dimensionality reduction, while OC-SVM detects anomalies in the reduced space. To handle non-linear data, AE1SVM employs random Fourier features (RFF) to approximate the RBF kernel, enabling efficient training via stochastic gradient descent (SGD). This integration allows for scalable anomaly detection and interpretable results. The autoencoder is optimized to produce representations that help the OC-SVM distinguish between normal and anomalous data. Gradient-based methods provide interpretability by highlighting influential features contributing to the model’s decisions.\",\n",
    "    \n",
    "    \"DevNet\": \"DevNet (Deviation Networks) is an anomaly detection model that combines feature learning with anomaly detection in an end-to-end framework. It introduces a Z-Score-based deviation loss, which enforces significant deviations between the anomaly scores of normal and anomalous data points. DevNet uses a small number of labeled anomalies and assumes a Gaussian prior distribution for anomaly scores, ensuring that anomalies stand out from normal data. This approach improves data efficiency and interpretability, outperforming traditional methods, especially when labeled anomalies are limited. DevNet achieves superior results in metrics like AUC-ROC and AUC-PR.\",\n",
    "    \n",
    "    \"LUNAR\": \"LUNAR (Learnable Unified Neighbourhood-based Anomaly Ranking) is an anomaly detection model that unifies local outlier detection methods (such as LOF, KNN, and DBSCAN) using a graph neural network (GNN) framework. Traditional local outlier methods measure the distance of a sample to its nearest neighbors to detect anomalies, but they lack the ability to learn and adapt to a specific dataset. LUNAR introduces learnability into this framework by leveraging a GNN, which aggregates neighborhood information in a trainable way. This makes LUNAR more flexible and robust compared to traditional methods, allowing it to outperform both classical and deep learning-based anomaly detection techniques, particularly in scenarios with varying neighborhood sizes.\",\n",
    "    \n",
    "    \"RGraph\" : \"R-Graph (Representation Graph) is an anomaly detection method that combines data self-representation with random walks on a directed graph. The method is designed to identify outliers in high-dimensional datasets by leveraging the fact that inliers can be represented as sparse combinations of other inliers, while outliers use both inliers and outliers in their representations. By constructing an asymmetric affinity matrix and defining a Markov Chain on the resulting graph, R-Graph detects outliers based on the behavior of random walks. Outliers are identified as those points for which the random walk probabilities tend to zero. The method has theoretical guarantees for correctness under certain geometric and connectivity assumptions, and experimental results demonstrate its effectiveness compared to state-of-the-art methods for outlier detection in multiple subspaces.\" \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pipeline Design Dimensions</th>\n",
       "      <th>MO-GAAL</th>\n",
       "      <th>SO-GAAL</th>\n",
       "      <th>AutoEncoder</th>\n",
       "      <th>VAE</th>\n",
       "      <th>AnoGAN</th>\n",
       "      <th>Deep SVDD</th>\n",
       "      <th>ALAD</th>\n",
       "      <th>RGraph</th>\n",
       "      <th>DevNet</th>\n",
       "      <th>AE1SVM</th>\n",
       "      <th>LUNAR</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Data Augmentation</td>\n",
       "      <td>SMOTE, GAN-based Oversampling</td>\n",
       "      <td>Oversampling, GAN-based Augmentation</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Graph-based Embedding</td>\n",
       "      <td>Anomaly Injection</td>\n",
       "      <td>Feature Augmentation</td>\n",
       "      <td>Latent Space Manipulation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Data Preprocessing</td>\n",
       "      <td>Normalization, Standardization</td>\n",
       "      <td>MinMax Scaling, Standardization</td>\n",
       "      <td>StandardScaler, Normalization</td>\n",
       "      <td>StandardScaler, MinMax Scaling</td>\n",
       "      <td>StandardScaler, MinMax Scaling</td>\n",
       "      <td>StandardScaler, MinMax Scaling</td>\n",
       "      <td>StandardScaler, MinMax Scaling</td>\n",
       "      <td>Graph Normalization</td>\n",
       "      <td>StandardScaler, Normalization</td>\n",
       "      <td>StandardScaler, MinMax Scaling</td>\n",
       "      <td>Normalization, MinMax Scaling</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Network Architecture</td>\n",
       "      <td>Discriminator, Generator (GAN), MLP, AutoEncoder</td>\n",
       "      <td>Discriminator, Generator (GAN)</td>\n",
       "      <td>AutoEncoder, MLP</td>\n",
       "      <td>VAE, beta-VAE, AutoEncoder</td>\n",
       "      <td>Discriminator, Generator (GAN)</td>\n",
       "      <td>AutoEncoder, One-Class Classifier</td>\n",
       "      <td>Discriminator, Generator (GAN)</td>\n",
       "      <td>Graph Neural Network, R-GCN</td>\n",
       "      <td>MLP, Fully Connected Network</td>\n",
       "      <td>AutoEncoder + SVM</td>\n",
       "      <td>Latent Variable Model, VAE-based</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Hidden Layers</td>\n",
       "      <td>[[32, 16], [64, 32, 16], [128, 64, 32, 16]]</td>\n",
       "      <td>[[64, 32], [128, 64, 32], [256, 128, 64, 32]]</td>\n",
       "      <td>[[32, 16], [64, 32, 16], [128, 64, 32, 16]]</td>\n",
       "      <td>[[64, 32], [128, 64, 32], [256, 128, 64]]</td>\n",
       "      <td>[[64, 32], [128, 64, 32], [256, 128, 64, 32]]</td>\n",
       "      <td>[[64, 32], [128, 64, 32], [256, 128, 64, 32]]</td>\n",
       "      <td>[[64, 32], [128, 64, 32], [256, 128, 64]]</td>\n",
       "      <td>[[64, 32], [128, 64, 32]]</td>\n",
       "      <td>[[32, 16], [64, 32], [128, 64, 32]]</td>\n",
       "      <td>[[64, 32], [128, 64, 32]]</td>\n",
       "      <td>[[32, 16], [64, 32, 16]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Activation</td>\n",
       "      <td>ReLU, LeakyReLU, Tanh</td>\n",
       "      <td>ReLU, LeakyReLU, Tanh</td>\n",
       "      <td>ReLU, Tanh, LeakyReLU</td>\n",
       "      <td>ReLU, Tanh, LeakyReLU</td>\n",
       "      <td>ReLU, LeakyReLU, Tanh</td>\n",
       "      <td>ReLU, Tanh, LeakyReLU</td>\n",
       "      <td>ReLU, LeakyReLU, Tanh</td>\n",
       "      <td>ReLU, Tanh</td>\n",
       "      <td>ReLU, LeakyReLU</td>\n",
       "      <td>ReLU, Tanh</td>\n",
       "      <td>ReLU, LeakyReLU</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Dropout</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Initialization</td>\n",
       "      <td>Xavier Uniform</td>\n",
       "      <td>Xavier Uniform</td>\n",
       "      <td>Xavier Normal</td>\n",
       "      <td>Xavier Normal</td>\n",
       "      <td>Xavier Uniform</td>\n",
       "      <td>Xavier Uniform</td>\n",
       "      <td>Xavier Uniform</td>\n",
       "      <td>Xavier Uniform</td>\n",
       "      <td>He Normal</td>\n",
       "      <td>Xavier Normal</td>\n",
       "      <td>Xavier Uniform</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Loss Function</td>\n",
       "      <td>Cross-Entropy Loss</td>\n",
       "      <td>Cross-Entropy Loss</td>\n",
       "      <td>Reconstruction Loss</td>\n",
       "      <td>Reconstruction Loss + KL Divergence</td>\n",
       "      <td>Cross-Entropy Loss</td>\n",
       "      <td>Binary Cross-Entropy</td>\n",
       "      <td>Cross-Entropy Loss</td>\n",
       "      <td>Cross-Entropy Loss</td>\n",
       "      <td>Binary Cross-Entropy</td>\n",
       "      <td>One-Class SVM Loss</td>\n",
       "      <td>Reconstruction Loss + KL Divergence</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Optimizer</td>\n",
       "      <td>Adam</td>\n",
       "      <td>Adam</td>\n",
       "      <td>Adam</td>\n",
       "      <td>AdamW</td>\n",
       "      <td>Adam</td>\n",
       "      <td>Adam</td>\n",
       "      <td>Adam</td>\n",
       "      <td>Adam</td>\n",
       "      <td>SGD</td>\n",
       "      <td>Adam</td>\n",
       "      <td>AdamW</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Epochs</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>200</td>\n",
       "      <td>120</td>\n",
       "      <td>150</td>\n",
       "      <td>150</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>150</td>\n",
       "      <td>200</td>\n",
       "      <td>120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Batch Size</td>\n",
       "      <td>32</td>\n",
       "      <td>32</td>\n",
       "      <td>16</td>\n",
       "      <td>32</td>\n",
       "      <td>64</td>\n",
       "      <td>64</td>\n",
       "      <td>32</td>\n",
       "      <td>32</td>\n",
       "      <td>64</td>\n",
       "      <td>16</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Learning Rate</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Weight Decay</td>\n",
       "      <td>1e-4</td>\n",
       "      <td>1e-4</td>\n",
       "      <td>1e-5</td>\n",
       "      <td>1e-4</td>\n",
       "      <td>1e-5</td>\n",
       "      <td>1e-5</td>\n",
       "      <td>1e-5</td>\n",
       "      <td>1e-4</td>\n",
       "      <td>5e-4</td>\n",
       "      <td>1e-5</td>\n",
       "      <td>1e-4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Pipeline Design Dimensions  \\\n",
       "0           Data Augmentation   \n",
       "1          Data Preprocessing   \n",
       "2        Network Architecture   \n",
       "3               Hidden Layers   \n",
       "4                  Activation   \n",
       "5                     Dropout   \n",
       "6              Initialization   \n",
       "7               Loss Function   \n",
       "8                   Optimizer   \n",
       "9                      Epochs   \n",
       "10                 Batch Size   \n",
       "11              Learning Rate   \n",
       "12               Weight Decay   \n",
       "\n",
       "                                             MO-GAAL  \\\n",
       "0                      SMOTE, GAN-based Oversampling   \n",
       "1                     Normalization, Standardization   \n",
       "2   Discriminator, Generator (GAN), MLP, AutoEncoder   \n",
       "3        [[32, 16], [64, 32, 16], [128, 64, 32, 16]]   \n",
       "4                              ReLU, LeakyReLU, Tanh   \n",
       "5                                                0.5   \n",
       "6                                     Xavier Uniform   \n",
       "7                                 Cross-Entropy Loss   \n",
       "8                                               Adam   \n",
       "9                                                100   \n",
       "10                                                32   \n",
       "11                                             0.001   \n",
       "12                                              1e-4   \n",
       "\n",
       "                                          SO-GAAL  \\\n",
       "0            Oversampling, GAN-based Augmentation   \n",
       "1                 MinMax Scaling, Standardization   \n",
       "2                  Discriminator, Generator (GAN)   \n",
       "3   [[64, 32], [128, 64, 32], [256, 128, 64, 32]]   \n",
       "4                           ReLU, LeakyReLU, Tanh   \n",
       "5                                             0.5   \n",
       "6                                  Xavier Uniform   \n",
       "7                              Cross-Entropy Loss   \n",
       "8                                            Adam   \n",
       "9                                             100   \n",
       "10                                             32   \n",
       "11                                          0.001   \n",
       "12                                           1e-4   \n",
       "\n",
       "                                    AutoEncoder  \\\n",
       "0                                           NaN   \n",
       "1                 StandardScaler, Normalization   \n",
       "2                              AutoEncoder, MLP   \n",
       "3   [[32, 16], [64, 32, 16], [128, 64, 32, 16]]   \n",
       "4                         ReLU, Tanh, LeakyReLU   \n",
       "5                                           0.2   \n",
       "6                                 Xavier Normal   \n",
       "7                           Reconstruction Loss   \n",
       "8                                          Adam   \n",
       "9                                           200   \n",
       "10                                           16   \n",
       "11                                       0.0005   \n",
       "12                                         1e-5   \n",
       "\n",
       "                                          VAE  \\\n",
       "0                                         NaN   \n",
       "1              StandardScaler, MinMax Scaling   \n",
       "2                  VAE, beta-VAE, AutoEncoder   \n",
       "3   [[64, 32], [128, 64, 32], [256, 128, 64]]   \n",
       "4                       ReLU, Tanh, LeakyReLU   \n",
       "5                                         0.3   \n",
       "6                               Xavier Normal   \n",
       "7         Reconstruction Loss + KL Divergence   \n",
       "8                                       AdamW   \n",
       "9                                         120   \n",
       "10                                         32   \n",
       "11                                      0.001   \n",
       "12                                       1e-4   \n",
       "\n",
       "                                           AnoGAN  \\\n",
       "0                                             NaN   \n",
       "1                  StandardScaler, MinMax Scaling   \n",
       "2                  Discriminator, Generator (GAN)   \n",
       "3   [[64, 32], [128, 64, 32], [256, 128, 64, 32]]   \n",
       "4                           ReLU, LeakyReLU, Tanh   \n",
       "5                                             0.4   \n",
       "6                                  Xavier Uniform   \n",
       "7                              Cross-Entropy Loss   \n",
       "8                                            Adam   \n",
       "9                                             150   \n",
       "10                                             64   \n",
       "11                                         0.0001   \n",
       "12                                           1e-5   \n",
       "\n",
       "                                        Deep SVDD  \\\n",
       "0                                             NaN   \n",
       "1                  StandardScaler, MinMax Scaling   \n",
       "2               AutoEncoder, One-Class Classifier   \n",
       "3   [[64, 32], [128, 64, 32], [256, 128, 64, 32]]   \n",
       "4                           ReLU, Tanh, LeakyReLU   \n",
       "5                                             0.5   \n",
       "6                                  Xavier Uniform   \n",
       "7                            Binary Cross-Entropy   \n",
       "8                                            Adam   \n",
       "9                                             150   \n",
       "10                                             64   \n",
       "11                                          0.001   \n",
       "12                                           1e-5   \n",
       "\n",
       "                                         ALAD                       RGraph  \\\n",
       "0                                         NaN        Graph-based Embedding   \n",
       "1              StandardScaler, MinMax Scaling          Graph Normalization   \n",
       "2              Discriminator, Generator (GAN)  Graph Neural Network, R-GCN   \n",
       "3   [[64, 32], [128, 64, 32], [256, 128, 64]]    [[64, 32], [128, 64, 32]]   \n",
       "4                       ReLU, LeakyReLU, Tanh                   ReLU, Tanh   \n",
       "5                                         0.4                          0.5   \n",
       "6                              Xavier Uniform               Xavier Uniform   \n",
       "7                          Cross-Entropy Loss           Cross-Entropy Loss   \n",
       "8                                        Adam                         Adam   \n",
       "9                                         100                          100   \n",
       "10                                         32                           32   \n",
       "11                                      0.001                        0.001   \n",
       "12                                       1e-5                         1e-4   \n",
       "\n",
       "                                 DevNet                          AE1SVM  \\\n",
       "0                     Anomaly Injection            Feature Augmentation   \n",
       "1         StandardScaler, Normalization  StandardScaler, MinMax Scaling   \n",
       "2          MLP, Fully Connected Network               AutoEncoder + SVM   \n",
       "3   [[32, 16], [64, 32], [128, 64, 32]]       [[64, 32], [128, 64, 32]]   \n",
       "4                       ReLU, LeakyReLU                      ReLU, Tanh   \n",
       "5                                   0.3                             0.2   \n",
       "6                             He Normal                   Xavier Normal   \n",
       "7                  Binary Cross-Entropy              One-Class SVM Loss   \n",
       "8                                   SGD                            Adam   \n",
       "9                                   150                             200   \n",
       "10                                   64                              16   \n",
       "11                                 0.01                          0.0005   \n",
       "12                                 5e-4                            1e-5   \n",
       "\n",
       "                                  LUNAR  \n",
       "0             Latent Space Manipulation  \n",
       "1         Normalization, MinMax Scaling  \n",
       "2      Latent Variable Model, VAE-based  \n",
       "3              [[32, 16], [64, 32, 16]]  \n",
       "4                       ReLU, LeakyReLU  \n",
       "5                                   0.4  \n",
       "6                        Xavier Uniform  \n",
       "7   Reconstruction Loss + KL Divergence  \n",
       "8                                 AdamW  \n",
       "9                                   120  \n",
       "10                                   32  \n",
       "11                                0.001  \n",
       "12                                 1e-4  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#model信息3：hyperparams\n",
    "import pandas as pd\n",
    "\n",
    "model_hyperparams = pd.read_csv('Hyperparameter_Configuration.csv')\n",
    "dataset_hyperparams = pd.read_csv('dataset_hyperparam.csv')\n",
    "model_hyperparams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['The arrhythmia dataset is commonly used in the Medical domain. It is a Multivariate dataset with 452 instances and 279 attributes. Areas of application include Cardiology, and it does contain missing values.', 'The glass dataset is commonly used in the Forensic Science domain. It is a Multivariate dataset with 214 instances and 9 attributes. Areas of application include Material Identification, and it contain missing values.', 'The ionosphere dataset is commonly used in the Astronomy domain. It is a Multivariate dataset with 351 instances and 34 attributes. Areas of application include Space, and it contain missing values.', 'The lympho dataset is commonly used in the Medical domain. It is a Multivariate dataset with 148 instances and 18 attributes. Areas of application include Oncology, and it contain missing values.']\n",
      "[\"Model 'MO-GAAL' hyperparameters include: Data Augmentation: SMOTE, GAN-based Oversampling, Data Preprocessing: Normalization, Standardization, Network Architecture: Discriminator, Generator (GAN), MLP, AutoEncoder, Hidden Layers: [[32, 16], [64, 32, 16], [128, 64, 32, 16]], Activation: ReLU, LeakyReLU, Tanh, Dropout: 0.5, Initialization: Xavier Uniform, Loss Function: Cross-Entropy Loss, Optimizer: Adam, Epochs: 100, Batch Size: 32, Learning Rate: 0.001, Weight Decay: 1e-4\\n\\nPaper summary for MO-GAAL: MO-GAAL addresses the limitations of SO-GAAL by using multiple generators, each tasked with generating different types of outliers. This approach mitigates the mode collapse problem by creating a mixture of reference distributions, enabling more robust and accurate outlier detection across datasets with various data types and dimensions\\n\\nCode summary for MO-GAAL: \\n1. MO-GAAL (Multiple Objective Generative Adversarial Active Learning) is an outlier detection algorithm based on Generative Adversarial Networks (GANs). It uses multiple sub-generators, each with different objectives, to generate outliers, aiding in separating outliers from normal data. This also helps avoid mode collapse, where the generator produces limited sample variety. The model uses a discriminator to distinguish between real and generated outliers and a generator to produce potential outliers.\\n\\n2. Advantages include its ability to discover complex outlier structures and improve detection performance, overcoming mode collapse. Disadvantages include the computational expense of training multiple GANs and the need for careful hyperparameter tuning. It may lack interpretability, as deep learning models often act as black boxes.\\n\\n3. MO-GAAL performs well on high-dimensional data with complex patterns. However, it may be excessive for simpler datasets where more efficient methods could suffice, and it may not be suitable when interpretability is critical.\\n\", \"Model 'SO-GAAL' hyperparameters include: Data Augmentation: Oversampling, GAN-based Augmentation, Data Preprocessing: MinMax Scaling, Standardization, Network Architecture: Discriminator, Generator (GAN), Hidden Layers: [[64, 32], [128, 64, 32], [256, 128, 64, 32]], Activation: ReLU, LeakyReLU, Tanh, Dropout: 0.5, Initialization: Xavier Uniform, Loss Function: Cross-Entropy Loss, Optimizer: Adam, Epochs: 100, Batch Size: 32, Learning Rate: 0.001, Weight Decay: 1e-4\\n\\nPaper summary for SO-GAAL: SO-GAAL generates potential outliers using a single generator in a Generative Adversarial Network (GAN) framework, which plays a mini-max game with a discriminator. The generator synthesizes informative outliers that help the discriminator distinguish between normal data and anomalies. However, SO-GAAL can suffer from mode collapse, where the generator fails to provide diverse enough outliers, limiting its detection ability\\n\\nCode summary for SO-GAAL: \\n1. SO-GAAL (Single-Objective Generative Adversarial Active Learning) is an outlier detection model using a GAN setup with one generator and one discriminator. The generator produces synthetic data, while the discriminator distinguishes between real and generated data. The model uses generated examples as potential outliers to learn boundaries between normal data and outliers.\\n\\n2. Its advantages include dynamic learning and adaptability, especially when outliers are rare. However, the model may suffer from mode collapse, generating overly similar or 'good' examples, which could limit its effectiveness.\\n\\n3. SO-GAAL works well on datasets with rare outliers or complex feature structures but may struggle when outliers cannot be well approximated by the generator or when there are only minor distinctions between normal and outlier data.\\n\", \"Model 'AutoEncoder' hyperparameters include: Data Augmentation: nan, Data Preprocessing: StandardScaler, Normalization, Network Architecture: AutoEncoder, MLP, Hidden Layers: [[32, 16], [64, 32, 16], [128, 64, 32, 16]], Activation: ReLU, Tanh, LeakyReLU, Dropout: 0.2, Initialization: Xavier Normal, Loss Function: Reconstruction Loss, Optimizer: Adam, Epochs: 200, Batch Size: 16, Learning Rate: 0.0005, Weight Decay: 1e-5\\n\\nPaper summary for AutoEncoder: AutoEncoder is a neural network model primarily used for unsupervised anomaly detection. It works by encoding input data into a lower-dimensional latent space and then reconstructing it back into the original space. Anomalies are detected by measuring the reconstruction error: normal data is reconstructed with minimal error, while anomalies yield higher reconstruction errors. AutoEncoder is particularly suited for structured and tabular data, and its performance can be tuned by adjusting the network’s architecture, including the number of hidden layers and nodes. It is effective for detecting subtle anomalies in complex datasets.\\n\\nCode summary for AutoEncoder: \\n1. This model is based on an AutoEncoder, a neural network used for unsupervised data representation learning. It compresses input data into a low-dimensional code via an encoder and reconstructs it through a decoder. Outliers are detected based on their reconstruction errors, as they typically deviate from normal instances. The model uses ReLU activation, dropout, and batch normalization to prevent overfitting.\\n\\n2. AutoEncoders are unsupervised and adaptable, making them versatile across various datasets. However, they are sensitive to hyperparameter selection and may struggle to preserve global data structures.\\n\\n3. AutoEncoders perform well on structured data like images or sequences but may struggle on noisy or scalar data with no inherent structure, where simpler methods could be more efficient.\\n\", \"Model 'AnoGAN' hyperparameters include: Data Augmentation: nan, Data Preprocessing: StandardScaler, MinMax Scaling, Network Architecture: Discriminator, Generator (GAN), Hidden Layers: [[64, 32], [128, 64, 32], [256, 128, 64, 32]], Activation: ReLU, LeakyReLU, Tanh, Dropout: 0.4, Initialization: Xavier Uniform, Loss Function: Cross-Entropy Loss, Optimizer: Adam, Epochs: 150, Batch Size: 64, Learning Rate: 0.0001, Weight Decay: 1e-5\\n\\nPaper summary for AnoGAN: AnoGAN is an unsupervised learning model that detects anomalies by learning a representation of normal data using a Generative Adversarial Network (GAN). It identifies anomalies by mapping new data to a latent space and calculating how well the new data fits within the learned normal distribution. The model is particularly effective for image-based anomaly detection and was initially applied to medical imaging, where it detects anomalous regions that deviate from the learned healthy patterns.\\n\\nCode summary for AnoGAN: \\n1. AnoGAN uses GANs for outlier detection, with a generator and discriminator. It uses standard GAN training followed by training a separate query model to find the closest latent space point for each data instance. Outliers are detected based on their reconstruction error in the latent space.\\n\\n2. AnoGAN is effective for modeling complex, high-dimensional data and handles both numerical and categorical data. However, it is computationally expensive, and GAN training is known to be unstable.\\n\\n3. AnoGAN excels on complex datasets like images or medical scans but may struggle with simpler or imbalanced datasets, where traditional outlier detection methods might be more appropriate.\\n\", \"Model 'Deep SVDD' hyperparameters include: Data Augmentation: nan, Data Preprocessing: StandardScaler, MinMax Scaling, Network Architecture: AutoEncoder, One-Class Classifier, Hidden Layers: [[64, 32], [128, 64, 32], [256, 128, 64, 32]], Activation: ReLU, Tanh, LeakyReLU, Dropout: 0.5, Initialization: Xavier Uniform, Loss Function: Binary Cross-Entropy, Optimizer: Adam, Epochs: 150, Batch Size: 64, Learning Rate: 0.001, Weight Decay: 1e-5\\n\\nPaper summary for Deep SVDD: DeepSVDD is a deep learning-based anomaly detection method that extends the classical SVDD (Support Vector Data Description) approach. It learns a compact representation of the data by mapping input samples to a hypersphere of minimum volume in a feature space. The goal is to enclose normal data within the hypersphere, while outliers are mapped outside of it. DeepSVDD avoids the need for explicit feature engineering and works effectively on high-dimensional data, particularly image datasets. It is trained using a one-class objective to ensure that the majority of normal data is close to the hypersphere center, making it suitable for unsupervised anomaly detection.\\n\\nCode summary for Deep SVDD: \\n1. Deep SVDD aims to minimize the volume of a hypersphere enclosing the network representations of data during training. It detects outliers by measuring the distance from the center. The architecture is customizable, allowing users to define the network layers and activation functions. It can also operate in autoencoder mode, where the encoder-decoder structure mirrors itself.\\n\\n2. Advantages include unsupervised learning, flexibility in network architecture, and regularization options like dropout and L2. Disadvantages involve the need for trial-and-error hyperparameter tuning and the requirement of large datasets for effective training.\\n\\n3. Deep SVDD performs well on datasets with identifiable patterns but struggles with noisy, imbalanced, or complex datasets where outliers are not easily separable from normal data.\\n\", \"Model 'ALAD' hyperparameters include: Data Augmentation: nan, Data Preprocessing: StandardScaler, MinMax Scaling, Network Architecture: Discriminator, Generator (GAN), Hidden Layers: [[64, 32], [128, 64, 32], [256, 128, 64]], Activation: ReLU, LeakyReLU, Tanh, Dropout: 0.4, Initialization: Xavier Uniform, Loss Function: Cross-Entropy Loss, Optimizer: Adam, Epochs: 100, Batch Size: 32, Learning Rate: 0.001, Weight Decay: 1e-5\\n\\nPaper summary for ALAD: ALAD is a GAN-based anomaly detection method that incorporates an encoder and discriminator to learn a latent representation of normal data. It leverages bi-directional GANs and cycle-consistency to map data samples to and from a latent space, enabling faster and more accurate anomaly detection. ALAD focuses on improving reconstruction error for anomaly detection by utilizing adversarially learned features, ensuring that both the data space and the latent space are well represented. This method enhances performance and stability, particularly in high-dimensional datasets, and is much faster at inference than traditional GAN-based methods\\n\\nCode summary for ALAD: \\n1. ALAD uses a GAN architecture with an encoder, a generator, and three discriminators to distinguish real from generated data. The model can also incorporate reconstruction loss for improved performance.\\n\\n2. ALAD excels at detecting complex patterns and works well on high-dimensional data. However, it requires substantial computational resources and may perform poorly when the data distribution is difficult to learn or when the dataset is small.\\n\\n3. ALAD is effective for complex, high-dimensional datasets but may struggle with small or simple datasets, where traditional methods might be more efficient.\\n\", \"Model 'AE1SVM' hyperparameters include: Data Augmentation: Feature Augmentation, Data Preprocessing: StandardScaler, MinMax Scaling, Network Architecture: AutoEncoder + SVM, Hidden Layers: [[64, 32], [128, 64, 32]], Activation: ReLU, Tanh, Dropout: 0.2, Initialization: Xavier Normal, Loss Function: One-Class SVM Loss, Optimizer: Adam, Epochs: 200, Batch Size: 16, Learning Rate: 0.0005, Weight Decay: 1e-5\\n\\nPaper summary for AE1SVM: AE1SVM (Autoencoder-based One-Class SVM) combines an autoencoder with a one-class support vector machine (OC-SVM) for anomaly detection in high-dimensional datasets. The autoencoder is used for dimensionality reduction, while OC-SVM detects anomalies in the reduced space. To handle non-linear data, AE1SVM employs random Fourier features (RFF) to approximate the RBF kernel, enabling efficient training via stochastic gradient descent (SGD). This integration allows for scalable anomaly detection and interpretable results. The autoencoder is optimized to produce representations that help the OC-SVM distinguish between normal and anomalous data. Gradient-based methods provide interpretability by highlighting influential features contributing to the model’s decisions.\\n\\nCode summary for AE1SVM: \\n\\n1. This model combines an Autoencoder (AE) with a One-Class Support Vector Machine (SVM) to detect outliers. The Autoencoder learns a compressed representation of the data through encoding and decoding layers, while the One-Class SVM works on the encoded data's random Fourier features to separate normal data from outliers. The architecture uses hidden layers with customizable neurons, ReLU activations, batch normalization, and dropout for regularization. By utilizing random Fourier features in the SVM, it approximates a kernel function, allowing for non-linear decision boundaries to better distinguish outliers.\\n\\n2. Advantages: The model can capture complex data patterns through the Autoencoder's deep structure and the SVM’s non-linear decision boundaries, providing enhanced outlier detection in non-linearly separable data. Batch normalization and dropout improve training stability and prevent overfitting. Disadvantages: It is computationally expensive, especially with a large number of random Fourier features. Training this model may be time-consuming due to the Autoencoder and SVM combination, which could also make it less effective on small datasets or real-time applications.\\n\\n3. Good performance: This model is ideal for large datasets with high dimensionality and complex, non-linear patterns, where normal and anomalous data have distinguishable structures. Poor performance: It may perform poorly on small datasets, highly noisy datasets, or data with simple, linear separations between normal and anomalous points, as the model's complexity could lead to overfitting or unnecessary computation.\\n\", \"Model 'DevNet' hyperparameters include: Data Augmentation: Anomaly Injection, Data Preprocessing: StandardScaler, Normalization, Network Architecture: MLP, Fully Connected Network, Hidden Layers: [[32, 16], [64, 32], [128, 64, 32]], Activation: ReLU, LeakyReLU, Dropout: 0.3, Initialization: He Normal, Loss Function: Binary Cross-Entropy, Optimizer: SGD, Epochs: 150, Batch Size: 64, Learning Rate: 0.01, Weight Decay: 5e-4\\n\\nPaper summary for DevNet: DevNet (Deviation Networks) is an anomaly detection model that combines feature learning with anomaly detection in an end-to-end framework. It introduces a Z-Score-based deviation loss, which enforces significant deviations between the anomaly scores of normal and anomalous data points. DevNet uses a small number of labeled anomalies and assumes a Gaussian prior distribution for anomaly scores, ensuring that anomalies stand out from normal data. This approach improves data efficiency and interpretability, outperforming traditional methods, especially when labeled anomalies are limited. DevNet achieves superior results in metrics like AUC-ROC and AUC-PR.\\n\\nCode summary for DevNet: \\n\\n1. DevNet's architecture varies in depth with options for shallow or deep networks, which include three specific models: DevNetD (3 hidden layers), DevNetS (1 hidden layer), and DevNetLinear (no hidden layer). These configurations allow flexible model complexity based on data needs. Each hidden layer uses ReLU activations, which helps capture non-linear patterns in the data. The model uses a specialized deviation loss, which applies Z-score deviation based on the assumption that inliers and outliers deviate from a reference distribution differently, optimizing the model to distinguish between them effectively.\\n\\n2. Advantages: The flexibility of choosing the network depth makes it adaptable to various data complexities. The deviation loss function is tailored for outlier detection, providing direct optimization for distinguishing anomalies from normal instances. Disadvantages: Deep models, such as DevNetD, could overfit on small datasets with limited diversity, potentially reducing generalizability. The model may struggle with datasets containing subtle or high-dimensional anomalies that are hard to capture with simple linear layers. Training a deep network can be computationally expensive and requires considerable tuning, especially on larger datasets.\\n\\n3. Good Performance: DevNet will likely perform well on datasets where the outliers exhibit distinct characteristics from the inliers, particularly if the data is moderately complex with features that can be captured by shallow or deep neural networks (e.g., low-dimensional structured data or data with clear, distinguishable outlier patterns). Poor Performance: The model might struggle on high-dimensional datasets where anomalies are subtle and require more sophisticated feature extraction than linear layers can provide. Additionally, if the outliers do not significantly deviate from the inliers, the deviation-based loss function may not effectively identify them.\\n\", \"Model 'LUNAR' hyperparameters include: Data Augmentation: Latent Space Manipulation, Data Preprocessing: Normalization, MinMax Scaling, Network Architecture: Latent Variable Model, VAE-based, Hidden Layers: [[32, 16], [64, 32, 16]], Activation: ReLU, LeakyReLU, Dropout: 0.4, Initialization: Xavier Uniform, Loss Function: Reconstruction Loss + KL Divergence, Optimizer: AdamW, Epochs: 120, Batch Size: 32, Learning Rate: 0.001, Weight Decay: 1e-4\\n\\nPaper summary for LUNAR: LUNAR (Learnable Unified Neighbourhood-based Anomaly Ranking) is an anomaly detection model that unifies local outlier detection methods (such as LOF, KNN, and DBSCAN) using a graph neural network (GNN) framework. Traditional local outlier methods measure the distance of a sample to its nearest neighbors to detect anomalies, but they lack the ability to learn and adapt to a specific dataset. LUNAR introduces learnability into this framework by leveraging a GNN, which aggregates neighborhood information in a trainable way. This makes LUNAR more flexible and robust compared to traditional methods, allowing it to outperform both classical and deep learning-based anomaly detection techniques, particularly in scenarios with varying neighborhood sizes.\\n\\nCode summary for LUNAR: \\n\\n1. The LUNAR model uses graph neural networks to unify local outlier detection methods by leveraging nearest neighbors. Its architecture consists of two neural networks, SCORE_MODEL and WEIGHT_MODEL, each with three hidden layers of 256 units. The activation functions differ: SCORE_MODEL uses Tanh activations and a Sigmoid output, while WEIGHT_MODEL uses ReLU activations with a final layer normalizing weights via LayerNorm and BatchNorm. LUNAR generates anomaly scores by evaluating the distance between data points and their nearest neighbors and employs a unique negative sampling approach, using random uniform and subspace perturbations to simulate outliers.\\n\\n2. Advantages: Flexibility: LUNAR's dual model approach allows for adaptability in scoring based on different types of outliers. Local Context Awareness: By focusing on k-nearest neighbors, it effectively captures local data structures, which can improve the detection of local outliers. Robust Sampling: The negative sampling technique enhances training by simulating diverse outlier types, potentially improving detection accuracy. Disadvantages: Computationally Intensive: The model’s reliance on neural networks and nearest neighbor searches could lead to high computational costs, particularly on large datasets. Hyperparameter Sensitivity: Its performance is likely sensitive to parameters like n_neighbors, sampling proportion, and model type, which may require fine-tuning for optimal results.\\n\\n3. Good Performance: The model will likely excel on datasets with well-defined clusters or local structures where outliers are distinct from the majority class. Examples include structured datasets like social network data, sensor data, and geospatial data. Poor Performance: LUNAR may struggle on high-dimensional or noisy datasets where local neighborhood relationships are less meaningful or when the data is too sparse, making it difficult to discern local outliers effectively.\\n\", \"Model 'RGraph' hyperparameters include: Data Augmentation: Graph-based Embedding, Data Preprocessing: Graph Normalization, Network Architecture: Graph Neural Network, R-GCN, Hidden Layers: [[64, 32], [128, 64, 32]], Activation: ReLU, Tanh, Dropout: 0.5, Initialization: Xavier Uniform, Loss Function: Cross-Entropy Loss, Optimizer: Adam, Epochs: 100, Batch Size: 32, Learning Rate: 0.001, Weight Decay: 1e-4\\n\\nPaper summary for RGraph: R-Graph (Representation Graph) is an anomaly detection method that combines data self-representation with random walks on a directed graph. The method is designed to identify outliers in high-dimensional datasets by leveraging the fact that inliers can be represented as sparse combinations of other inliers, while outliers use both inliers and outliers in their representations. By constructing an asymmetric affinity matrix and defining a Markov Chain on the resulting graph, R-Graph detects outliers based on the behavior of random walks. Outliers are identified as those points for which the random walk probabilities tend to zero. The method has theoretical guarantees for correctness under certain geometric and connectivity assumptions, and experimental results demonstrate its effectiveness compared to state-of-the-art methods for outlier detection in multiple subspaces.\\n\\nCode summary for RGraph: \\n\\n1. The RGraph model uses an elastic net subspace clustering technique with a graph-based transition matrix to represent data self-representation and outlier scoring. It combines elements of sparse representation (via the Lasso and linear regression) and an active support strategy to optimize computations, especially for large datasets. It detects outliers by constructing a transition matrix normalized by L1, followed by transition steps that propagate a probability vector through this matrix. Lower scores from this transition process signify outliers.\\n\\n2. Advantages: It handles high-dimensional data well due to its reliance on sparse representations. The active support algorithm can optimize the process, making it scalable for large datasets. Disadvantages: The model may be computationally intensive, especially if the active support is not correctly tuned, as it iteratively solves optimization problems. Sensitivity to hyperparameters (like tau, gamma) can make the model difficult to tune, potentially impacting performance on noisy data.\\n\\n3. Good performance: This model should perform well on high-dimensional, sparse datasets where data points reside in low-dimensional subspaces (e.g., image or signal data with natural clusters). Poor performance: It may struggle on dense, low-dimensional datasets with strong non-linear relationships, as its linear clustering technique might not capture complex patterns, potentially leading to poor outlier identification.\\n\"]\n"
     ]
    }
   ],
   "source": [
    "# 函数：将数据集信息转换为自然语言描述\n",
    "def dataset_to_natural_language(df):\n",
    "    dataset_prompt_list = []\n",
    "    for index, row in df.iterrows():\n",
    "        description = (\n",
    "            f\"The {row['Dataset']} dataset is commonly used in the {row['Domain']} domain. \"\n",
    "            f\"It is a {row['Data Type']} dataset with {row['Number of Instances']} instances \"\n",
    "            f\"and {row['Number of Attributes']} attributes. \"\n",
    "            f\"Areas of application include {row['Area']}, and it {'' if row['Missing Values'] == 'No' else 'does '}contain missing values.\"\n",
    "        )\n",
    "        dataset_prompt_list.append(description)\n",
    "    return dataset_prompt_list\n",
    "\n",
    "def model_to_natural_language(df, paper_summaries, code_summaries):\n",
    "    model_prompt_list = []\n",
    "    for column in paper_summaries.keys():  \n",
    "        description = f\"Model '{column}' hyperparameters include: \"\n",
    "        \n",
    "        for index, row in df.iterrows():\n",
    "            description += f\"{row['Pipeline Design Dimensions']}: {row[column]}, \"\n",
    "        description = description.strip(\", \")\n",
    "\n",
    "        # 添加 paper_summaries 的描述\n",
    "        if column in paper_summaries:\n",
    "            description += f\"\\n\\nPaper summary for {column}: {paper_summaries[column]}\"\n",
    "\n",
    "        # 添加 code_summaries 的描述\n",
    "        if column in code_summaries:\n",
    "            description += f\"\\n\\nCode summary for {column}: {code_summaries[column]}\"\n",
    "\n",
    "        model_prompt_list.append(description)\n",
    "    \n",
    "    return model_prompt_list\n",
    "\n",
    "\n",
    "\n",
    "dataset_prompt_list = dataset_to_natural_language(dataset_hyperparams)\n",
    "\n",
    "model_prompt_list = model_to_natural_language(model_hyperparams, paper_summaries, code_summaries)\n",
    "\n",
    "# 输出或返回列表\n",
    "print(dataset_prompt_list)\n",
    "print(model_prompt_list)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use GPT to select proper model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "load_dotenv()\n",
    "api_key = os.getenv(\"API_KEY\")\n",
    "\n",
    "client = OpenAI(api_key=api_key)\n",
    "def create_prompt(dataset_description, model_descriptions):\n",
    "    prompt = f\"Given the dataset with the following characteristics:\\n{dataset_description}\\n\\n\"\n",
    "    prompt += \"Here are the available models and their hyperparameters:\\n\"\n",
    "    for model_description in model_descriptions:\n",
    "        prompt += f\"{model_description}\\n\"\n",
    "    prompt += \"\\nGiven this information, which is the BEST ONE would you recommend using for this dataset? Please only choose the best one.\"\n",
    "    return prompt\n",
    "\n",
    "def call_gpt(prompt):\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": 'You are a well-trained data scientist specifically good at machine learning.'},\n",
    "        {\"role\": \"user\", \"content\": prompt}\n",
    "    ]\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gpt-4\",\n",
    "        messages=messages,\n",
    "        max_tokens=1000\n",
    "    ).choices[0].message.content\n",
    "    return response\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running iteration 1/10\n",
      "Running iteration 2/10\n",
      "Running iteration 3/10\n",
      "Running iteration 4/10\n",
      "Running iteration 5/10\n",
      "Running iteration 6/10\n",
      "Running iteration 7/10\n",
      "Running iteration 8/10\n",
      "Running iteration 9/10\n",
      "Running iteration 10/10\n"
     ]
    }
   ],
   "source": [
    "raw_resp_dict = {}\n",
    "results_dict = {}\n",
    "\n",
    "for run in range(10):  # 运行10次\n",
    "    print(f\"Running iteration {run + 1}/10\")\n",
    "    for dataset_description in dataset_prompt_list:\n",
    "        overall_prompt = create_prompt(dataset_description, model_prompt_list)\n",
    "        response_raw = call_gpt(overall_prompt)\n",
    "        processing_prompt = 'Please return me the name (only the top one) of recommended best model (Which is supposed to be one of these models : MO-GAAL,AutoEncoder,SO-GAAL,VAE,AnoGAN,Deep SVDD,ALAD,AE1SVM,DevNet,RGraph, LUNAR) given the paragraph below, in form of python list: \\n' + response_raw\n",
    "        response = call_gpt(processing_prompt)\n",
    "        dataset_name = dataset_description.split(\" \")[1]\n",
    "        if dataset_name not in raw_resp_dict:\n",
    "            raw_resp_dict[dataset_name] = []\n",
    "        if dataset_name not in results_dict:\n",
    "            results_dict[dataset_name] = []\n",
    "        raw_resp_dict[dataset_name].append(response_raw)\n",
    "        results_dict[dataset_name].append(response)\n",
    "\n",
    "# 将结果转换为DataFrame\n",
    "# 对于 raw_resp_dict\n",
    "raw_resp_df = pd.DataFrame(dict([(k, pd.Series(v)) for k, v in raw_resp_dict.items()]))\n",
    "raw_resp_df.index += 1  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "resp_df = pd.DataFrame(dict([(k, pd.Series(v)) for k, v in results_dict.items()]))\n",
    "resp_df.index += 1  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>arrhythmia</th>\n",
       "      <th>glass</th>\n",
       "      <th>ionosphere</th>\n",
       "      <th>lympho</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>['AutoEncoder']</td>\n",
       "      <td>['AutoEncoder']</td>\n",
       "      <td>['AutoEncoder']</td>\n",
       "      <td>[\"AutoEncoder\"]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[\"AutoEncoder\"]</td>\n",
       "      <td>['AutoEncoder']</td>\n",
       "      <td>['AutoEncoder']</td>\n",
       "      <td>['AutoEncoder']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[\"AutoEncoder\"]</td>\n",
       "      <td>['AutoEncoder']</td>\n",
       "      <td>['MO-GAAL']</td>\n",
       "      <td>['AutoEncoder']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>['AutoEncoder']</td>\n",
       "      <td>['AutoEncoder']</td>\n",
       "      <td>['AutoEncoder']</td>\n",
       "      <td>[\"AutoEncoder\"]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>['AutoEncoder']</td>\n",
       "      <td>[\"AutoEncoder\"]</td>\n",
       "      <td>[\"AutoEncoder\"]</td>\n",
       "      <td>['AutoEncoder']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>['AutoEncoder']</td>\n",
       "      <td>['AutoEncoder']</td>\n",
       "      <td>[\"AutoEncoder\"]</td>\n",
       "      <td>['AutoEncoder']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>[\"AutoEncoder\"]</td>\n",
       "      <td>['AutoEncoder']</td>\n",
       "      <td>['AutoEncoder']</td>\n",
       "      <td>['AutoEncoder']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>['AutoEncoder']</td>\n",
       "      <td>[\"AutoEncoder\"]</td>\n",
       "      <td>['AutoEncoder']</td>\n",
       "      <td>['AutoEncoder']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>['AutoEncoder']</td>\n",
       "      <td>['AutoEncoder']</td>\n",
       "      <td>['AutoEncoder']</td>\n",
       "      <td>['AutoEncoder']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>['AutoEncoder']</td>\n",
       "      <td>['AutoEncoder']</td>\n",
       "      <td>['AutoEncoder']</td>\n",
       "      <td>['AutoEncoder']</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         arrhythmia            glass       ionosphere           lympho\n",
       "1   ['AutoEncoder']  ['AutoEncoder']  ['AutoEncoder']  [\"AutoEncoder\"]\n",
       "2   [\"AutoEncoder\"]  ['AutoEncoder']  ['AutoEncoder']  ['AutoEncoder']\n",
       "3   [\"AutoEncoder\"]  ['AutoEncoder']      ['MO-GAAL']  ['AutoEncoder']\n",
       "4   ['AutoEncoder']  ['AutoEncoder']  ['AutoEncoder']  [\"AutoEncoder\"]\n",
       "5   ['AutoEncoder']  [\"AutoEncoder\"]  [\"AutoEncoder\"]  ['AutoEncoder']\n",
       "6   ['AutoEncoder']  ['AutoEncoder']  [\"AutoEncoder\"]  ['AutoEncoder']\n",
       "7   [\"AutoEncoder\"]  ['AutoEncoder']  ['AutoEncoder']  ['AutoEncoder']\n",
       "8   ['AutoEncoder']  [\"AutoEncoder\"]  ['AutoEncoder']  ['AutoEncoder']\n",
       "9   ['AutoEncoder']  ['AutoEncoder']  ['AutoEncoder']  ['AutoEncoder']\n",
       "10  ['AutoEncoder']  ['AutoEncoder']  ['AutoEncoder']  ['AutoEncoder']"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resp_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>arrhythmia</th>\n",
       "      <th>glass</th>\n",
       "      <th>ionosphere</th>\n",
       "      <th>lympho</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I would recommend the 'AutoEncoder' for the gi...</td>\n",
       "      <td>The AutoEncoder model seems to be the most app...</td>\n",
       "      <td>Given the above models and their properties, I...</td>\n",
       "      <td>Considering that the lympho dataset is a medic...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Given the dataset's characteristics (452 insta...</td>\n",
       "      <td>I would recommend using the AutoEncoder model ...</td>\n",
       "      <td>Given the dataset characteristics and the avai...</td>\n",
       "      <td>Given the provided information, the AutoEncode...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Considering the characteristics of the dataset...</td>\n",
       "      <td>While all models presented have their advantag...</td>\n",
       "      <td>Based on the characteristics of the ionosphere...</td>\n",
       "      <td>For the given lympho dataset, I would recommen...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Given the nature of the dataset and the overvi...</td>\n",
       "      <td>Given the characteristics of the dataset you m...</td>\n",
       "      <td>Based on the given dataset, the AutoEncoder mo...</td>\n",
       "      <td>Given that the lympho dataset is medical and m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Given the dataset and the available models, th...</td>\n",
       "      <td>Given the information provided, I would recomm...</td>\n",
       "      <td>Based on the dataset description and the model...</td>\n",
       "      <td>Given the dataset is medical (specifically onc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Given the specific nature of your dataset, whi...</td>\n",
       "      <td>Considering the characteristics of the dataset...</td>\n",
       "      <td>Given the dataset and the information provided...</td>\n",
       "      <td>Given the dataset characteristics and the natu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Considering the description of the dataset - a...</td>\n",
       "      <td>Considering the dataset and model details, I r...</td>\n",
       "      <td>I would recommend using 'AutoEncoder' for the ...</td>\n",
       "      <td>Given the information above and considering th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Looking at the dataset and model summaries, I ...</td>\n",
       "      <td>Given the dataset characteristics and availabl...</td>\n",
       "      <td>Given the characteristics of the ionosphere da...</td>\n",
       "      <td>Based on the characteristics of the lympho dat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Given the dataset characteristics and the mode...</td>\n",
       "      <td>I would recommend using the AutoEncoder model ...</td>\n",
       "      <td>This Ionosphere dataset is a multivariate data...</td>\n",
       "      <td>Based on the information provided, the best mo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Given the dataset is a Multivariate dataset wi...</td>\n",
       "      <td>Based on the dataset description, the glass da...</td>\n",
       "      <td>The dataset in question is the ionosphere data...</td>\n",
       "      <td>Given that the lympho dataset is a medical dat...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           arrhythmia  \\\n",
       "1   I would recommend the 'AutoEncoder' for the gi...   \n",
       "2   Given the dataset's characteristics (452 insta...   \n",
       "3   Considering the characteristics of the dataset...   \n",
       "4   Given the nature of the dataset and the overvi...   \n",
       "5   Given the dataset and the available models, th...   \n",
       "6   Given the specific nature of your dataset, whi...   \n",
       "7   Considering the description of the dataset - a...   \n",
       "8   Looking at the dataset and model summaries, I ...   \n",
       "9   Given the dataset characteristics and the mode...   \n",
       "10  Given the dataset is a Multivariate dataset wi...   \n",
       "\n",
       "                                                glass  \\\n",
       "1   The AutoEncoder model seems to be the most app...   \n",
       "2   I would recommend using the AutoEncoder model ...   \n",
       "3   While all models presented have their advantag...   \n",
       "4   Given the characteristics of the dataset you m...   \n",
       "5   Given the information provided, I would recomm...   \n",
       "6   Considering the characteristics of the dataset...   \n",
       "7   Considering the dataset and model details, I r...   \n",
       "8   Given the dataset characteristics and availabl...   \n",
       "9   I would recommend using the AutoEncoder model ...   \n",
       "10  Based on the dataset description, the glass da...   \n",
       "\n",
       "                                           ionosphere  \\\n",
       "1   Given the above models and their properties, I...   \n",
       "2   Given the dataset characteristics and the avai...   \n",
       "3   Based on the characteristics of the ionosphere...   \n",
       "4   Based on the given dataset, the AutoEncoder mo...   \n",
       "5   Based on the dataset description and the model...   \n",
       "6   Given the dataset and the information provided...   \n",
       "7   I would recommend using 'AutoEncoder' for the ...   \n",
       "8   Given the characteristics of the ionosphere da...   \n",
       "9   This Ionosphere dataset is a multivariate data...   \n",
       "10  The dataset in question is the ionosphere data...   \n",
       "\n",
       "                                               lympho  \n",
       "1   Considering that the lympho dataset is a medic...  \n",
       "2   Given the provided information, the AutoEncode...  \n",
       "3   For the given lympho dataset, I would recommen...  \n",
       "4   Given that the lympho dataset is medical and m...  \n",
       "5   Given the dataset is medical (specifically onc...  \n",
       "6   Given the dataset characteristics and the natu...  \n",
       "7   Given the information above and considering th...  \n",
       "8   Based on the characteristics of the lympho dat...  \n",
       "9   Based on the information provided, the best mo...  \n",
       "10  Given that the lympho dataset is a medical dat...  "
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_resp_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Data</th>\n",
       "      <th>#Samples</th>\n",
       "      <th># Dimensions</th>\n",
       "      <th>Outlier Perc</th>\n",
       "      <th>MO_GAAL</th>\n",
       "      <th>SO_GAAL</th>\n",
       "      <th>AutoEncoder</th>\n",
       "      <th>AnoGAN</th>\n",
       "      <th>DeepSVDD</th>\n",
       "      <th>ALAD</th>\n",
       "      <th>AE1SVM</th>\n",
       "      <th>DevNet</th>\n",
       "      <th>RGraph</th>\n",
       "      <th>LUNAR</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>arrhythmia</td>\n",
       "      <td>452</td>\n",
       "      <td>274</td>\n",
       "      <td>14.6018</td>\n",
       "      <td>0.6153</td>\n",
       "      <td>0.6179</td>\n",
       "      <td>0.8096</td>\n",
       "      <td>0.7726</td>\n",
       "      <td>0.7915</td>\n",
       "      <td>0.5257</td>\n",
       "      <td>0.818</td>\n",
       "      <td>0.4288</td>\n",
       "      <td>0.7241</td>\n",
       "      <td>0.8284</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>glass</td>\n",
       "      <td>214</td>\n",
       "      <td>9</td>\n",
       "      <td>4.2056</td>\n",
       "      <td>0.686</td>\n",
       "      <td>0.4756</td>\n",
       "      <td>0.561</td>\n",
       "      <td>0.628</td>\n",
       "      <td>0.4573</td>\n",
       "      <td>0.5305</td>\n",
       "      <td>0.6189</td>\n",
       "      <td>0.5335</td>\n",
       "      <td>0.5274</td>\n",
       "      <td>0.6707</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ionosphere</td>\n",
       "      <td>351</td>\n",
       "      <td>33</td>\n",
       "      <td>35.8974</td>\n",
       "      <td>0.7789</td>\n",
       "      <td>0.4838</td>\n",
       "      <td>0.8435</td>\n",
       "      <td>0.7895</td>\n",
       "      <td>0.832</td>\n",
       "      <td>0.4579</td>\n",
       "      <td>0.8872</td>\n",
       "      <td>0.7227</td>\n",
       "      <td>0.2331</td>\n",
       "      <td>0.9172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>lympho</td>\n",
       "      <td>148</td>\n",
       "      <td>18</td>\n",
       "      <td>4.0541</td>\n",
       "      <td>0.4971</td>\n",
       "      <td>0.3977</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.9766</td>\n",
       "      <td>0.4503</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0058</td>\n",
       "      <td>0.6316</td>\n",
       "      <td>0.9708</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Data #Samples # Dimensions Outlier Perc MO_GAAL SO_GAAL AutoEncoder  \\\n",
       "0  arrhythmia      452          274      14.6018  0.6153  0.6179      0.8096   \n",
       "0       glass      214            9       4.2056   0.686  0.4756       0.561   \n",
       "0  ionosphere      351           33      35.8974  0.7789  0.4838      0.8435   \n",
       "0      lympho      148           18       4.0541  0.4971  0.3977         1.0   \n",
       "\n",
       "   AnoGAN DeepSVDD    ALAD  AE1SVM  DevNet  RGraph   LUNAR  \n",
       "0  0.7726   0.7915  0.5257   0.818  0.4288  0.7241  0.8284  \n",
       "0   0.628   0.4573  0.5305  0.6189  0.5335  0.5274  0.6707  \n",
       "0  0.7895    0.832  0.4579  0.8872  0.7227  0.2331  0.9172  \n",
       "0     1.0   0.9766  0.4503     1.0  0.0058  0.6316  0.9708  "
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roc_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'arrhythmia': ['LUNAR', 'AE1SVM', 'AutoEncoder', 'DeepSVDD', 'AnoGAN'],\n",
       " 'glass': ['LUNAR', 'AnoGAN', 'AE1SVM', 'AutoEncoder', 'DevNet'],\n",
       " 'ionosphere': ['LUNAR', 'AE1SVM', 'AutoEncoder', 'DeepSVDD', 'AnoGAN'],\n",
       " 'lympho': ['AutoEncoder', 'AnoGAN', 'AE1SVM', 'DeepSVDD', 'LUNAR']}"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Drop unnecessary column if present\n",
    "data = roc_df.drop(columns=['Unnamed: 0'], errors='ignore')\n",
    "\n",
    "# Extract model columns, assuming they start from 'MO_GAAL' till the end\n",
    "model_columns = roc_df.columns[5:]\n",
    "\n",
    "# Initialize a dictionary to store top 5 models for each dataset\n",
    "top5_models_per_dataset = {}\n",
    "\n",
    "# Iterate through each row in the DataFrame\n",
    "for _, row in roc_df.iterrows():\n",
    "    # Extract dataset name\n",
    "    dataset_name = row['Data']\n",
    "    \n",
    "    # Sort models based on their performance scores, keeping only the top 5\n",
    "    top5_models = row[model_columns].sort_values(ascending=False).head(5).index.tolist()\n",
    "    \n",
    "    # Store the result\n",
    "    top5_models_per_dataset[dataset_name] = top5_models\n",
    "\n",
    "top5_models_per_dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA04AAAJgCAYAAAC9cTNzAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8fJSN1AAAACXBIWXMAAA9hAAAPYQGoP6dpAABj1klEQVR4nO3deZxO9f//8ec1u1mMZWzDGDMjzGCsJaRCiJR2oZAtVPaKSrbKUmTJUgmplHy0kTDZIlqshZGsI0tjKWNnZt6/P/zm+naZ4cyMmeuM5nHvNrdb1/t6n3Ne17nmuOZ5nfd5H4cxxggAAAAAcFUedhcAAAAAAHkdwQkAAAAALBCcAAAAAMACwQkAAAAALBCcAAAAAMACwQkAAAAALBCcAAAAAMACwQkAAAAALBCcAAAAAMACwQnIw2bNmiWHw+H88fLyUpkyZfTkk0/q4MGDdpeXbdu3b9fQoUO1b9++dM917NhR5cqVc3tNWXHixAk99thjKl68uBwOh+6///5r9k9NTdWHH36ou+66SyEhIfL29lbx4sXVsmVLLViwQKmpqe4pPActWrRIQ4cOtbuMDDkcDsva9u3bJ4fDoTfffNM9ReVhZ8+e1dChQ7Vy5cpM9U/bd9faz506dXL2yUl33nmn7rzzzmwtW65cOXXs2NGy35kzZzR69GhVq1ZNBQsWVFBQkKKiovToo49q1apV2dp2Zn4nr8frr7+uL7/8Ml37ypUr5XA4Mv3eArg2ghNwA5g5c6bWrVunuLg4de3aVZ988okaNGigM2fO2F1atmzfvl3Dhg3LMDgNHjxYX3zxhfuLyoIRI0boiy++0FtvvaV169ZpzJgxV+17/vx5tWjRQh06dFDx4sU1depULV++XNOmTVNoaKgeeeQRLViwwI3V54xFixZp2LBhdpeBHHD27FkNGzYsy39cBwUFadasWemC/+nTpzVv3jwVLFgwB6t0j5SUFDVt2lSvvfaaHn74Yc2bN0//+9//1LdvX508eVKrV6+2u8QMXS041axZU+vWrVPNmjXdXxTwH+RldwEArFWpUkW1a9eWJDVs2FApKSkaMWKEvvzyS7Vr1y7DZc6ePSt/f393lmnp0qVLlt9AR0VFuama7Nu6dauioqKuuu//rV+/flqyZIk++OADtW/f3uW5Bx98UM8995zOnTt33TWlpKQoOTlZvr6+6Z7Li78LuLarvWfGGJ0/f14FChSwoSpXrVu31vTp07Vs2TI1adLE2T537lylpKTo/vvv10cffWRjhVn3/fffa+3atZoxY4aefPJJZ3uzZs30zDPP3HBnhwsWLKhbb73V7jKA/wzOOAE3oLQPwv3790u6PLwtMDBQv/32m5o2baqgoCA1btxY0uVhZT179lTp0qXl4+OjyMhIvfTSS7pw4YLLOh0Oh5555hm98847qlChgnx9fRUTE6NPP/003fa3bt2qVq1aqXDhwvLz81P16tX1wQcfuPRJGyLy4Ycfqn///ipdurR8fX01ffp0PfLII5Iuh8C04TyzZs1yvpYrh+qdP39egwYNUkREhHx8fFS6dGk9/fTT+ueff1z6lStXTi1bttTixYtVs2ZNFShQQJUqVdKMGTMytV+t9lXaEKXvvvtO8fHxztqv9k39kSNHNH36dDVr1ixdaEpz0003KTY21vk4ISFBjz/+uIoXLy5fX19FR0dr7NixLn+wpdUxZswYvfrqq4qIiJCvr69WrFihoUOHyuFwaOPGjXr44YdVuHBhZxg1xmjKlCmqXr26ChQooMKFC+vhhx/Wnj170tW1ePFiNW7cWMHBwfL391d0dLRGjhwp6fJ7NHnyZElyGUqa0RnENHFxcWrVqpXKlCkjPz8/lS9fXk899ZSOHTvm0i+t/m3btqlNmzYKDg5WiRIl1KlTJ508edKlb1JSkrp27aqiRYsqMDBQd999t3bu3HnVGqykDY1dsWKFevTooZCQEBUtWlQPPvigDh06lK7/nDlzVLduXQUGBiowMFDVq1fX+++/79JnxowZqlatmvz8/FSkSBE98MADio+Pd+lzreM37bicNm2aoqOj5evr6zzW/vjjD7Vt29bldyXtffm3f/75R/3791dkZKR8fX1VvHhxtWjRQjt27NC+fftUrFgxSdKwYcOc72VmhrRVrFhR9erVS3d8zZgxQw8++KCCg4PTLZOamqoxY8aoUqVKzlrat2+vP//806WfMUZjxoxReHi4/Pz8VLNmTX377bcZ1pGUlKQBAwa4/PvQp0+fbJ2RP378uCSpVKlSGT7v4eH6Z9ORI0f01FNPqUyZMvLx8VFERISGDRum5ORky21ldtkLFy5o+PDhio6Olp+fn4oWLaqGDRtq7dq1ki7/jpw5c0YffPCB8/1LG854taF6X3/9terWrSt/f38FBQWpSZMmWrdunUufrByL8+bNU506dZz/XkRGRqpTp06W+wC44RgAedbMmTONJPPLL7+4tE+YMMFIMu+++64xxpgOHToYb29vU65cOTNy5EizbNkys2TJEnPu3DkTGxtrAgICzJtvvmmWLl1qBg8ebLy8vEyLFi1c1inJhIWFmZiYGPPJJ5+Yr7/+2tx9991Gkpk3b56z344dO0xQUJCJiooys2fPNt98841p06aNkWRGjx7t7LdixQojyZQuXdo8/PDD5uuvvzYLFy40R44cMa+//rqRZCZPnmzWrVtn1q1bZxITE52vJTw83Lme1NRU06xZM+Pl5WUGDx5sli5dat58800TEBBgatSoYc6fP+/sGx4ebsqUKWNiYmLM7NmzzZIlS8wjjzxiJJlVq1Zdc19nZl+dP3/erFu3ztSoUcNERkY6az958mSG65wzZ46RZKZOnXrNbadJTEw0pUuXNsWKFTPTpk0zixcvNs8884yRZHr06OHst3fvXue+bdiwofnf//5nli5davbu3WuGDBliJJnw8HDzwgsvmLi4OPPll18aY4zp2rWr8fb2Nv379zeLFy82c+bMMZUqVTIlSpQwR44cca5/+vTpxuFwmDvvvNPMmTPHfPfdd2bKlCmmZ8+exhhjdu3aZR5++GEjybkP1q1b5/JeXGnq1Klm5MiR5uuvvzarVq0yH3zwgalWrZqpWLGiuXjxorNfWv0VK1Y0r7zyiomLizPjxo0zvr6+5sknn3T2S01NNQ0bNjS+vr7mtddeM0uXLjVDhgwxkZGRRpIZMmTINfd12j584403nG1px1tkZKR59tlnzZIlS8z06dNN4cKFTcOGDV2WHzx4sJFkHnzwQTNv3jyzdOlSM27cODN48GBnn7Tf8zZt2phvvvnGzJ4920RGRprg4GCzc+dOZ7+rHb/GGOf7HBsba+bMmWOWL19utm7darZt22aCg4NN1apVzezZs83SpUtN//79jYeHhxk6dKhz3UlJSaZy5comICDADB8+3CxZssTMnz/f9O7d2yxfvtycP3/eLF682EgynTt3dr6Xu3btytS+e//9942fn585ceKEMebyvw+SzPLly83TTz9trvwzo1u3bkaSeeaZZ8zixYvNtGnTTLFixUxYWJg5evRout+Dzp07m2+//da8++67pnTp0qZkyZLmjjvucPY7c+aMqV69ugkJCTHjxo0z3333nZkwYYIJDg42jRo1Mqmpqc6+4eHhpkOHDtf6tTB79+413t7epkKFCuajjz4yhw4dumrfw4cPm7CwMBMeHm7eeecd891335kRI0YYX19f07FjR5e+V/5OZnbZS5cumYYNGxovLy8zYMAAs2jRIvP111+bF1980XzyySfGGGPWrVtnChQoYFq0aOF8/7Zt22aM+b9/h1esWOFc58cff2wkmaZNm5ovv/zSzJ0719SqVcv4+PiY1atXp3sPrI7FtWvXGofDYR577DGzaNEis3z5cjNz5kzzxBNPXHNfAzcighOQh6X9Iffjjz+aS5cumVOnTpmFCxeaYsWKmaCgIOcfux06dDCSzIwZM1yWnzZtmpFkPvvsM5f20aNHG0lm6dKlzjZJpkCBAi5/QCcnJ5tKlSqZ8uXLO9see+wx4+vraxISElzW2bx5c+Pv72/++ecfY8z/fWDffvvt6V7XvHnz0n2Yp7kyOKX9UTdmzBiXfnPnznUJj8Zc/sPIz8/P7N+/39l27tw5U6RIEfPUU0+l29a/ZWVf3XHHHaZy5crXXJ8xxowaNcpIMosXL7bsa4wxAwcONJLMTz/95NLeo0cP43A4zO+//26M+b8/XKOiolxChzH/98fOK6+84tK+bt06I8mMHTvWpf3AgQOmQIEC5vnnnzfGGHPq1ClTsGBBc9ttt7n80XmljP4ozqzU1FRz6dIls3//fiPJfPXVV+nqv/L97tmzp/Hz83PW9O233xpJZsKECS79XnvttesOTmkBMc2YMWOMJHP48GFjjDF79uwxnp6epl27dldd/99//+38Y/bfEhISjK+vr2nbtq2z7WrHrzGXj8vg4GBnMEnTrFkzU6ZMmXSh/ZlnnnEJMsOHDzeSTFxc3FVrPXr0aKb2WZp/77tTp06ZwMBA8/bbbxtjjHnuuedMRESESU1NTfc7Eh8fn+H+/emnn4wk8+KLLxpjLu87Pz8/88ADD7j0++GHH4wkl+A0cuRI4+Hhke7Lpf/9739Gklm0aJGzLTPByRhj3n//fRMYGGgkGUmmVKlSpn379ub777936ffUU0+ZwMBAl39vjDHmzTffNJKc4cWY9MEps8vOnj3bSDLvvffeNWsOCAjI8LVdGZxSUlJMaGioqVq1qklJSXH2O3XqlClevLipV6+esy2zx2JazWn/9gP/ZQzVA24At956q7y9vRUUFKSWLVuqZMmS+vbbb1WiRAmXfg899JDL4+XLlysgIEAPP/ywS3vaMJxly5a5tDdu3NhlnZ6enmrdurV27drlHEqzfPlyNW7cWGFhYenWefbs2XTDPa6sKauWL1/uUnOaRx55RAEBAeleQ/Xq1VW2bFnnYz8/P1WoUME5rPFa28nKvsoNy5cvV0xMjG655ZZ0NRhjnPsizX333Sdvb+8M13Xlfl+4cKEcDocef/xxJScnO39KliypatWqOYfyrF27VklJSerZs2eOzoiWmJio7t27KywsTF5eXvL29lZ4eLgkpRu6lvba/i02Nlbnz59XYmKiJGnFihWSlO46s7Zt2153rRltW/q/obFxcXFKSUnR008/fdV1rFu3TufOnUv3exsWFqZGjRpl+Pt0tWOlUaNGKly4sPPx+fPntWzZMj3wwAPy9/d3eT9btGih8+fP68cff5Qkffvtt6pQoYLuuusu6xeeDYGBgXrkkUc0Y8YMJScna/bs2XryyScz/N1Je8+u3Ce33HKLoqOjnftk3bp1On/+fLr3tl69es7fmTQLFy5UlSpVVL16dZf90KxZs2zPJtepUyf9+eefmjNnjnr16qWwsDB99NFHuuOOO/TGG2+4bLthw4YKDQ112Xbz5s0l6Zoz8GV22W+//VZ+fn45Nuzt999/16FDh/TEE0+4DDsMDAzUQw89pB9//FFnz551WcbqWLz55pslSY8++qg+++yzG3rGV8AKk0MAN4DZs2crOjpaXl5eKlGiRIbj7/39/dPNYnX8+HGVLFky3R8xxYsXl5eXl3M8f5qSJUumW29a2/Hjx1WmTBkdP348w+2HhoY6+/3b1a4VyKzjx4/Ly8vLeR1GGofDoZIlS6bbXtGiRdOtw9fX13IChqzuq8xIC3B79+7NVP/jx49nOBV7dvbtlc/99ddfMsakC9tpIiMjJUlHjx6VJJUpUyZTNWdGamqqmjZtqkOHDmnw4MGqWrWqAgIClJqaqltvvTXD9+bK9zFt0ou0vmm/F1f2y+h3OKustp2ZfXSta2VCQ0MVFxfn0pbR8ZvmynUcP35cycnJmjRpkiZNmpThMmnXjh09etTli4Tc0LlzZ91222167bXXdPTo0ateH2W1T9KCaVq/a/17lOavv/7Srl27rvoFwpXX0GVWcHCw2rRpozZt2kiStm3bprvuuksvvfSSunbtqkKFCumvv/7SggULsrXtzC579OhRhYaGpru2Krus3oPU1FT9/fffLhOTWB0Pt99+u7788ktNnDhR7du314ULF1S5cmW99NJLzv0H/FcQnIAbQHR0tHNWvavJ6BveokWL6qeffpIxxuX5xMREJScnKyQkxKX/kSNH0q0jrS3tw7No0aI6fPhwun5pF89fuc7rPWtRtGhRJScn6+jRoy7hyRijI0eOOL/tvF5Z3VeZ0bBhQ3l7e+vLL79U9+7dM1VDTu3bK58LCQmRw+HQ6tWrM5x5L60tbR9febH+9di6dau2bNmiWbNmqUOHDs72Xbt2ZXudab8Xx48fd/nDLqPf4Zz273105ZnXf9cn6arv5/W8l4ULF5anp6eeeOKJq571ioiIcNaak+9lRurXr6+KFStq+PDhatKkSab2yZWh89/7JK3f1f49+veXCyEhISpQoMBVJ4DJznGbkcqVK+uxxx7T+PHjtXPnTt1yyy0KCQlRbGysXnvttQyXSfvC42p1ZWbZYsWKac2aNUpNTc2R8GT1e+nh4eFydjOzWrVqpVatWunChQv68ccfNXLkSLVt21blypVT3bp1r7tuIK9gqB7wH9a4cWOdPn063f09Zs+e7Xz+35YtW6a//vrL+TglJUVz585VVFSU8w+dxo0ba/ny5elmGZs9e7b8/f0zNfXtld9YWr0GSemmNZ4/f77OnDmT7jVkV1b3VWaULFlSXbp00ZIlS5zrudLu3bv166+/Orexfft2bdy4MV0NDodDDRs2zHINaVq2bCljjA4ePKjatWun+6lataqky8OhgoODNW3aNBljrrq+rLyHaX/4XxnY3nnnney+HOe++Pjjj13a58yZk+11ZlbTpk3l6empqVOnXrVP3bp1VaBAgXS/t3/++adzuGt2+fv7q2HDhtq0aZNiY2MzfD/T/kBu3ry5du7cmW6Y579l5b28mpdffln33nuv+vfvf9U+jRo1kpT+WP7ll18UHx/v3Ce33nqr/Pz80r23a9euTTfktmXLltq9e7eKFi2a4X7I6s20jx8/rosXL2b43I4dOyT9X6hp2bKl89YEGW37WsEps8s2b95c58+fd846ejWZOasuXZ4JsXTp0pozZ47L8X3mzBnNnz/fOdNedvn6+uqOO+7Q6NGjJUmbNm3K9rqAvIgzTsB/WPv27TV58mR16NBB+/btU9WqVbVmzRq9/vrratGiRbrrHkJCQtSoUSMNHjxYAQEBmjJlinbs2OEyJfmQIUOc4/NfeeUVFSlSRB9//LG++eYbjRkzJsMpiK9UpUoVSdK7776roKAg+fn5KSIiIsNhdk2aNFGzZs30wgsvKCkpSfXr19evv/6qIUOGqEaNGnriiSeucy9dltV9lVnjxo3Tnj171LFjRy1ZskQPPPCASpQooWPHjikuLk4zZ87Up59+qtjYWPXt21ezZ8/WPffco+HDhys8PFzffPONpkyZoh49eqhChQrZfn3169dXt27d9OSTT2r9+vW6/fbbFRAQoMOHD2vNmjWqWrWqevToocDAQI0dO1ZdunTRXXfdpa5du6pEiRLatWuXtmzZorfffluSnEFr9OjRat68uTw9PRUbGysfH590265UqZKioqI0cOBAGWNUpEgRLViwIN1wtaxo2rSpbr/9dj3//PM6c+aMateurR9++EEffvhhtteZWeXKldOLL76oESNG6Ny5c86pmrdv365jx45p2LBhKlSokAYPHqwXX3xR7du3V5s2bXT8+HENGzZMfn5+GjJkyHXVMGHCBN12221q0KCBevTooXLlyunUqVPatWuXFixY4AxKffr00dy5c9WqVSsNHDhQt9xyi86dO6dVq1apZcuWatiwoYKCghQeHq6vvvpKjRs3VpEiRRQSEpKl0PH444/r8ccfv2afihUrqlu3bpo0aZI8PDzUvHlz7du3T4MHD1ZYWJj69u0r6fIZtQEDBujVV19Vly5d9Mgjj+jAgQMaOnRouqF6ffr00fz583X77berb9++io2NVWpqqhISErR06VL1799fderUyfTrWLFihXr37q127dqpXr16Klq0qBITE/XJJ59o8eLFat++vfNLpOHDhysuLk716tVTr169VLFiRZ0/f1779u3TokWLNG3atKsO58zssm3atNHMmTPVvXt3/f7772rYsKFSU1P1008/KTo6Wo899piky8fjypUrtWDBApUqVUpBQUGqWLFiuu16eHhozJgxateunVq2bKmnnnpKFy5c0BtvvKF//vlHo0aNyvS+SvPKK6/ozz//VOPGjVWmTBn9888/mjBhgry9vXXHHXdkeX1AnmbbtBQALF1tOvIrdejQwQQEBGT43PHjx0337t1NqVKljJeXlwkPDzeDBg1KN3W0JPP000+bKVOmmKioKOPt7W0qVapkPv7443Tr/O2338y9995rgoODjY+Pj6lWrZqZOXOmS5+02Zz+PZX5v40fP95EREQYT09PI8m5/JWz6hlzeWa8F154wYSHhxtvb29TqlQp06NHD/P333+79AsPDzf33HNPum3dcccdLjNxXU1m91VmZ9VLk5ycbD744APTqFEjU6RIEePl5WWKFStmmjdvbubMmeMyu9X+/ftN27ZtTdGiRY23t7epWLGieeONN1z6ZDQjXJq0mbD+PbXzv82YMcPUqVPHBAQEmAIFCpioqCjTvn17s379epd+ixYtMnfccYcJCAgw/v7+JiYmxmW6+QsXLpguXbqYYsWKGYfDYSSZvXv3XnUfbN++3TRp0sQEBQWZwoULm0ceecQkJCSkm23savWnHQv/3sY///xjOnXqZAoVKmT8/f1NkyZNnNNhX8+selcebxlN6WzM5RnPbr75ZuPn52cCAwNNjRo10h0H06dPN7GxscbHx8cEBwebVq1aucy2Zsy1j9+04/Jqr6FTp06mdOnSxtvb2xQrVszUq1fPvPrqqy79/v77b9O7d29TtmxZ4+3tbYoXL27uueces2PHDmef7777ztSoUcP4+voaSdecfe5av3//ltHMiykpKWb06NGmQoUKxtvb24SEhJjHH3/cHDhwwKVfamqqGTlypAkLCzM+Pj4mNjbWLFiwIMNj+fTp0+bll182FStWdO7nqlWrmr59+7rMEpqZWfUOHDhgXn75ZVO/fn1TsmRJ4+XlZYKCgkydOnXMpEmTTHJyskv/o0ePml69epmIiAjj7e1tihQpYmrVqmVeeuklc/r0aWe/jH4nM7vsuXPnzCuvvGJuuukm4+PjY4oWLWoaNWpk1q5d6+yzefNmU79+fePv7+8y8+DVfne//PJLU6dOHePn52cCAgJM48aNzQ8//ODSJ7PH4sKFC03z5s1N6dKljY+PjylevLhp0aKFy9TmwH+Fw5hrjMUAkG84HA49/fTTzjMKAAAA+D9c4wQAAAAAFghOAAAAAGCBySEASNI1Z1ADAADI7zjjBAAAAAAWCE4AAAAAYIHgBAAAAAAW8t01TqmpqTp06JCCgoKcd7MHAAAAkP8YY3Tq1CmFhobKw+Pa55TyXXA6dOiQwsLC7C4DAAAAQB5x4MABlSlT5pp98l1wCgoKknR55xQsWNDmagAAAADYJSkpSWFhYc6McC35LjilDc8rWLAgwQkAAABApi7hYXIIAAAAALBAcAIAAAAACwQnAAAAALCQ765xAgAAAK5HSkqKLl26ZHcZyCQfHx/LqcYzg+AEAAAAZIIxRkeOHNE///xjdynIAg8PD0VERMjHx+e61kNwAgAAADIhLTQVL15c/v7+mZqJDfZKTU3VoUOHdPjwYZUtW/a63jOCEwAAAGAhJSXFGZqKFi1qdznIgmLFiunQoUNKTk6Wt7d3ttfD5BAAAACAhbRrmvz9/W2uBFmVNkQvJSXlutZDcAIAAAAyieF5N56ces8ITgAAAABggeAEAAAAABaYHAIAAAC4Do5h7hu+Z4aYbC135MgRvfbaa/rmm2908OBBFS9eXNWrV1efPn3UuHHjHK7y+syaNUt9+vTJc9O+E5wAAACA/7B9+/apfv36KlSokMaMGaPY2FhdunRJS5Ys0dNPP60dO3ZkeZ2XLl3KcIa6q7X/FzBUDwAAAPgP69mzpxwOh37++Wc9/PDDqlChgipXrqx+/frpxx9/lCQlJCSoVatWCgwMVMGCBfXoo4/qr7/+cq5j6NChql69umbMmKHIyEj5+vrKGCOHw6Fp06apVatWCggI0KuvvipJWrBggWrVqiU/Pz9FRkZq2LBhSk5Odq7vn3/+Ubdu3VSiRAn5+fmpSpUqWrhwoVauXKknn3xSJ0+elMPhkMPh0NChQ926v66GM04AAADAf9SJEye0ePFivfbaawoICEj3fKFChWSM0f3336+AgACtWrVKycnJ6tmzp1q3bq2VK1c6++7atUufffaZ5s+fL09PT2f7kCFDNHLkSL311lvy9PTUkiVL9Pjjj2vixIlq0KCBdu/erW7dujn7pqamqnnz5jp16pQ++ugjRUVFafv27fL09FS9evU0fvx4vfLKK/r9998lSYGBgbm7kzLJ1uD0/fff64033tCGDRt0+PBhffHFF7r//vuvucyqVavUr18/bdu2TaGhoXr++efVvXt39xQMAAAA3EB27dolY4wqVap01T7fffedfv31V+3du1dhYWGSpA8//FCVK1fWL7/8optvvlmSdPHiRX344YcqVqyYy/Jt27ZVp06dnI+feOIJDRw4UB06dJAkRUZGasSIEXr++ec1ZMgQfffdd/r5558VHx+vChUqOPukCQ4OlsPhUMmSJXNmJ+QQW4fqnTlzRtWqVdPbb7+dqf579+5VixYt1KBBA23atEkvvviievXqpfnz5+dypQAAAMCNx5jLk0lc615G8fHxCgsLc4YmSYqJiVGhQoUUHx/vbAsPD08XmiSpdu3aLo83bNig4cOHKzAw0PnTtWtXHT58WGfPntXmzZtVpkwZZ2i6Udh6xql58+Zq3rx5pvtPmzZNZcuW1fjx4yVJ0dHRWr9+vd5880099NBDuVQlAAAAcGO66aab5HA4FB8ff9WRXWnXKlm1ZzTUL6P21NRUDRs2TA8++GC6vn5+fipQoEAWXkHecUNNDrFu3To1bdrUpa1Zs2Zav369Ll26lOEyFy5cUFJSkssPAAAAkB8UKVJEzZo10+TJk3XmzJl0z//zzz+KiYlRQkKCDhw44Gzfvn27Tp48qejo6Cxvs2bNmvr9999Vvnz5dD8eHh6KjY3Vn3/+qZ07d2a4vI+Pj1JSUrK83dx2Q00OceTIEZUoUcKlrUSJEkpOTtaxY8dUqlSpdMuMHDlSw4YNc1eJbuPO+wUgY9m9jwJy0DWGHcANDMeA3fgssB+fBfZz13EQHhCuafWn6UziGVv/gl5/aH2Wl+k+pLs6t+qsqjWrqvuA7iofXV4pKSn66fufNH/2fH228jOVjy6vVo+0Ur9h/ZSSnKLRL45Wzbo1pdDL2zx06pDOXjqbqe2/8soratmypcLCwvTII4/Iw8NDv/76q3777Te9+uqruuOOO3T77bfroYce0rhx41S+fHnt2LFDDodDd999t8qVK6fTp09r2bJlqlatmvz9/eXv75+d3ZWjbqjgJKUfn2k1bnPQoEHq16+f83FSUpLL+E0AAADgevzS9Re7S7im0mVL66PFH2nGxBkaP3y8jiUeU+EihVUptpIGjhwoh8OhN2e8qTdefkPdHuwmDw8P1b2zrga8OiBb22vWrJkWLlyo4cOHa8yYMfL29lalSpXUpUsXZ5/58+drwIABatOmjc6cOaPy5ctr1KhRkqR69eqpe/fuat26tY4fP64hQ4bkiSnJHcbkja8MHQ6H5ax6t99+u2rUqKEJEyY427744gs9+uijOnv2bKZutpWUlKTg4GCdPHlSBQsWzInSbcG3jPbjW8Y8gDNO9sobHx/5Gp8F9uOzwH7uPuMUUjrkBjz1kLtqh9a27mSj8+fPa+/evYqIiJCfn5/Lc1nJBjfUNU5169ZVXFycS9vSpUtVu3bt/+wdigEAAADYz9bgdPr0aW3evFmbN2+WdHm68c2bNyshIUHS5WF27du3d/bv3r279u/fr379+ik+Pl4zZszQ+++/rwEDsncaEQAAAAAyw9YTjevXr1fDhg2dj9OuRerQoYNmzZqlw4cPO0OUJEVERGjRokXq27evJk+erNDQUE2cOJGpyAEAAADkKluD05133qlrXWI1a9asdG133HGHNm7cmItVAQAAAICrG+oaJwAAAACwA8EJAAAAACwQnAAAAADAAsEJAAAAACwQnAAAAADAAsEJAAAAACzYOh05AAAAcKOrXfpmt21r/cFfsrzM0D5DdTrptN6c8WYuVGSvO++8U9WrV9f48eNzfVuccQIAAACQay5evJiuLSUlRampqTZUk30EJwAAACCfeOrhp/Tm4Dc18dWJaly5sZpVb6Z3x77r0ufUyVN67fnX1KxaM9WPrK/WjVprddxq5/PLv1muRxs+qnoR9XRfnfs0duxYl+XLlSunV199VR07dlRwcLC6du2qWbNmqVChQlq4cKFiYmLk6+ur/fv36+LFi3r++edVunRpBQQEqE6dOlq5cqXL+n744Qfdcccd8vf3V+HChdWsWTP9/fff6tixo1atWqUJEybI4XDI4XBo3759ubXrGKoHAAAA5CcL5y1Uu27tNHPBTP224TcN6ztM1W6upjq311Fqaqp6P95bZ86c0fBJw1U6vLT27twrD8/L51vif43XoO6D1LVfVzW5r4l+Xf+rBr80WEWLFlXHjh2d23jjjTc0ePBgvfzyy5KkNWvW6OzZsxo5cqSmT5+uokWLqnjx4nryySe1b98+ffrppwoNDdUXX3yhu+++W7/99ptuuukmbd68WY0bN1anTp00ceJEeXl5acWKFUpJSdGECRO0c+dOValSRcOHD5ckFStWLNf2G8EJAAAAyEduir5JXft1lSSVjSyrz2Z9pp/X/Kw6t9fRz6t/1rbN2/TZys8UHhUuSSoTXsa57Mfvfqybb7tZXfp2kSSFR4Xr3OFzeuONN1yCU6NGjTRgwADn4zVr1ujSpUuaMmWKqlWrJknavXu3PvnkE/35558KDQ2VJA0YMECLFy/WzJkz9frrr2vMmDGqXbu2pkyZ4lxX5cqVnf/v4+Mjf39/lSxZMof3UnoM1QMAAADykfLR5V0ehxQP0d/H/pYk7dy2U8VLFXeGpivt+2Ofqt1czaWtfv36+uOPP5SSkuJsq127drplfXx8FBsb63y8ceNGGWNUoUIFBQYGOn9WrVql3bt3S5LzjFNewBknAAAAIB/x8nKNAA6HwzlRg6+f7zWXNcZIjgzarhAQEJCurUCBAnI4/m/h1NRUeXp6asOGDfL09HTpGxgY6Fwmr+CMEwAAAABJl89GJR5O1P7d+zN8PqJChLb8vMWlbe3atapQoUK68GOlRo0aSklJUWJiosqXL+/ykzb0LjY2VsuWLbvqOnx8fFzOdOUmghMAAAAASVKturVUo04NvdDtBf30/U86mHBQPyz/QWtXrJUkPf7U4/plzS+a/tZ07d+9Xws/W6i3337b5XqmzKpQoYLatWun9u3b6/PPP9fevXv1yy+/aPTo0Vq0aJEkadCgQfrll1/Us2dP/frrr9qxY4emTp2qY8eOSbo8g99PP/2kffv26dixY7k6xTlD9QAAAIDrkJ2b0uZlo98brQkjJuilni/p/LnzKlOujJ4Z9IwkqVLVSho5baSmvTlN7094XyHFQzR8+HCXiSGyYubMmXr11VfVv39/HTx4UEWLFlXdunXVokULSZfD1dKlS/Xiiy/qlltuUYECBVSnTh21adNG0uXJJDp06KCYmBidO3dOe/fuVbly5XJiN6TjMBkNSvwPS0pKUnBwsE6ePKmCBQvaXU62OYY5rDshV5kh+erQyZscHAe2yl8fH3kSnwX247PAfu46DsIDwjWt/jSFlA7h1MMVaoemnwgiLzl//rz27t2riIgI+fn5uTyXlWzAUD0AAAAAsEBwAgAAAAALBCcAAAAAsEBwAgAAAAALBCcAAADAgvn//4n5QG44OTUXHsEJAAAAsHD8wnFdTLkoXbK7EmTVxYsXJSnLN+i9EpMpAgAAABbOJJ/R1/u/VhufNiqkQpK3JO4IIOnydN95VWpqqo4ePSp/f395eV1f9CE4AQAAAJkwc9dMSdJ94ffJx9NHDpKTJGnvmb12l3BNHh4eKlu2rBzXef9HghMAAACQCUZGM3bN0Kd7P1WIXwjB6f/b8cwOu0u4Jh8fH3l4XP8VSgQnAAAAIAvOppxVwpkEu8vIM/z8/OwuwS2YHAIAAAAALBCcAAAAAMACwQkAAAAALBCcAAAAAMACwQkAAAAALBCcAAAAAMACwQkAAAAALBCcAAAAAMACwQkAAAAALBCcAAAAAMACwQkAAAAALBCcAAAAAMACwQkAAAAALBCcAAAAAMACwQkAAAAALBCcAAAAAMACwQkAAAAALBCcAAAAAMACwQkAAAAALBCcAAAAAMACwQkAAAAALBCcAAAAAMACwQkAAAAALBCcAAAAAMACwQkAAAAALBCcAAAAAMACwQkAAAAALBCcAAAAAMACwQkAAAAALBCcAAAAAMACwQkAAAAALBCcAAAAAMACwQkAAAAALBCcAAAAAMACwQkAAAAALBCcAAAAAMACwQkAAAAALBCcAAAAAMACwQkAAAAALBCcAAAAAMACwQkAAAAALBCcAAAAAMACwQkAAAAALBCcAAAAAMACwQkAAAAALBCcAAAAAMACwQkAAAAALBCcAAAAAMACwQkAAAAALBCcAAAAAMCC7cFpypQpioiIkJ+fn2rVqqXVq1dfs//HH3+satWqyd/fX6VKldKTTz6p48ePu6laAAAAAPmRrcFp7ty56tOnj1566SVt2rRJDRo0UPPmzZWQkJBh/zVr1qh9+/bq3Lmztm3bpnnz5umXX35Rly5d3Fw5AAAAgPzE1uA0btw4de7cWV26dFF0dLTGjx+vsLAwTZ06NcP+P/74o8qVK6devXopIiJCt912m5566imtX7/ezZUDAAAAyE9sC04XL17Uhg0b1LRpU5f2pk2bau3atRkuU69ePf35559atGiRjDH666+/9L///U/33HPPVbdz4cIFJSUlufwAAAAAQFbYFpyOHTumlJQUlShRwqW9RIkSOnLkSIbL1KtXTx9//LFat24tHx8flSxZUoUKFdKkSZOuup2RI0cqODjY+RMWFpajrwMAAADAf5/tk0M4HA6Xx8aYdG1ptm/frl69eumVV17Rhg0btHjxYu3du1fdu3e/6voHDRqkkydPOn8OHDiQo/UDAAAA+O/zsmvDISEh8vT0THd2KTExMd1ZqDQjR45U/fr19dxzz0mSYmNjFRAQoAYNGujVV19VqVKl0i3j6+srX1/fnH8BAAAAAPIN2844+fj4qFatWoqLi3Npj4uLU7169TJc5uzZs/LwcC3Z09NT0uUzVQAAAACQG2wdqtevXz9Nnz5dM2bMUHx8vPr27auEhATn0LtBgwapffv2zv733nuvPv/8c02dOlV79uzRDz/8oF69eumWW25RaGioXS8DAAAAwH+cbUP1JKl169Y6fvy4hg8frsOHD6tKlSpatGiRwsPDJUmHDx92uadTx44dderUKb399tvq37+/ChUqpEaNGmn06NF2vQQAAAAA+YDD5LMxbklJSQoODtbJkydVsGBBu8vJNsewjCfQgPuYIfnq0MmbrjKRDNwkf3185El8FtiPzwL7cRzY70Y+DrKSDWyfVQ8AAAAA8jqCEwAAAABYIDgBAAAAgAWCEwAAAABYIDgBAAAAgAWCEwAAAABYIDgBAAAAgAWCEwAAAABYIDgBAAAAgAWCEwAAAABYIDgBAAAAgAWCEwAAAABYIDgBAAAAgAWCEwAAAABYIDgBAAAAgAWCEwAAAABYIDgBAAAAgAWCEwAAAABYIDgBAAAAgAWCEwAAAABYIDgBAAAAgAWCEwAAAABYIDgBAAAAgAWCEwAAAABYIDgBAAAAgAWCEwAAAABYIDgBAAAAgAWCEwAAAABYIDgBAAAAgAWCEwAAAABYIDgBAAAAgAWCEwAAAABYIDgBAAAAgAWCEwAAAABYIDgBAAAAgAWCEwAAAABYIDgBAAAAgAWCEwAAAABYIDgBAAAAgAWCEwAAAABYIDgBAAAAgAWCEwAAAABYIDgBAAAAgAWCEwAAAABYIDgBAAAAgAWCEwAAAABYIDgBAAAAgAWCEwAAAABYIDgBAAAAgAWCEwAAAABYIDgBAAAAgAWCEwAAAABYIDgBAAAAgAWCEwAAAABYIDgBAAAAgAWCEwAAAABYIDgBAAAAgAWCEwAAAABYIDgBAAAAgAWCEwAAAABYIDgBAAAAgAWCEwAAAABYIDgBAAAAgAWCEwAAAABYIDgBAAAAgAWCEwAAAABYIDgBAAAAgAWCEwAAAABYIDgBAAAAgAWCEwAAAABYIDgBAAAAgAWCEwAAAABYIDgBAAAAgAWCEwAAAABYIDgBAAAAgAWCEwAAAABYIDgBAAAAgAXbg9OUKVMUEREhPz8/1apVS6tXr75m/wsXLuill15SeHi4fH19FRUVpRkzZripWgAAAAD5kZedG587d6769OmjKVOmqH79+nrnnXfUvHlzbd++XWXLls1wmUcffVR//fWX3n//fZUvX16JiYlKTk52c+UAAAAA8hNbg9O4cePUuXNndenSRZI0fvx4LVmyRFOnTtXIkSPT9V+8eLFWrVqlPXv2qEiRIpKkcuXKubNkAAAAAPmQbUP1Ll68qA0bNqhp06Yu7U2bNtXatWszXObrr79W7dq1NWbMGJUuXVoVKlTQgAEDdO7cuatu58KFC0pKSnL5AQAAAICssO2M07Fjx5SSkqISJUq4tJcoUUJHjhzJcJk9e/ZozZo18vPz0xdffKFjx46pZ8+eOnHixFWvcxo5cqSGDRuW4/UDAAAAyD+yFZzOnDmjUaNGadmyZUpMTFRqaqrL83v27Mn0uhwOh8tjY0y6tjSpqalyOBz6+OOPFRwcLOnycL+HH35YkydPVoECBdItM2jQIPXr18/5OCkpSWFhYZmuDwAAAACyFZy6dOmiVatW6YknnlCpUqWuGnSuJSQkRJ6enunOLiUmJqY7C5WmVKlSKl26tDM0SVJ0dLSMMfrzzz910003pVvG19dXvr6+Wa4PAAAAANJkKzh9++23+uabb1S/fv1sb9jHx0e1atVSXFycHnjgAWd7XFycWrVqleEy9evX17x583T69GkFBgZKknbu3CkPDw+VKVMm27UAAAAAwLVka3KIwoULO2e1ux79+vXT9OnTNWPGDMXHx6tv375KSEhQ9+7dJV0eZte+fXtn/7Zt26po0aJ68skntX37dn3//fd67rnn1KlTpwyH6QEAAABATshWcBoxYoReeeUVnT179ro23rp1a40fP17Dhw9X9erV9f3332vRokUKDw+XJB0+fFgJCQnO/oGBgYqLi9M///yj2rVrq127drr33ns1ceLE66oDAAAAAK7FYYwxWV2oRo0a2r17t4wxKleunLy9vV2e37hxY44VmNOSkpIUHByskydPqmDBgnaXk22OYVm/rgw5ywzJ8qGDnJaN6yuRg7L+8YEcxmeB/fgssB/Hgf1u5OMgK9kgW9c43X///dlZDAAAAABuSNkKTkOGDMnpOgAAAAAgz7quG+Bu2LBB8fHxcjgciomJUY0aNXKqLgAAAADIM7IVnBITE/XYY49p5cqVKlSokIwxOnnypBo2bKhPP/1UxYoVy+k6AQAAAMA22ZpV79lnn1VSUpK2bdumEydO6O+//9bWrVuVlJSkXr165XSNAAAAAGCrbJ1xWrx4sb777jtFR0c722JiYjR58mQ1bdo0x4oDAAAAgLwgW2ecUlNT001BLkne3t5KTU297qIAAAAAIC/JVnBq1KiRevfurUOHDjnbDh48qL59+6px48Y5VhwAAAAA5AXZCk5vv/22Tp06pXLlyikqKkrly5dXRESETp06pUmTJuV0jQAAAABgq2xd4xQWFqaNGzcqLi5OO3bskDFGMTExuuuuu3K6PgAAAACw3XXdx6lJkyZq0qRJTtUCAAAAAHlSpoPTxIkT1a1bN/n5+WnixInX7MuU5AAAAAD+SzIdnN566y21a9dOfn5+euutt67az+FwEJwAAAAA/KdkOjjt3bs3w/8HAAAAgP+6bM2qN3z4cJ09ezZd+7lz5zR8+PDrLgoAAAAA8pJsBadhw4bp9OnT6drPnj2rYcOGXXdRAAAAAJCXZCs4GWPkcDjStW/ZskVFihS57qIAAAAAIC/J0nTkhQsXlsPhkMPhUIUKFVzCU0pKik6fPq3u3bvneJEAAAAAYKcsBafx48fLGKNOnTpp2LBhCg4Odj7n4+OjcuXKqW7dujleJAAAAADYKUvBqUOHDkpOTpYk3XXXXSpTpkyuFAUAAAAAeUmWr3Hy8vJSz549lZKSkhv1AAAAAECek63JIerUqaNNmzbldC0AAAAAkCdlaahemp49e6p///76888/VatWLQUEBLg8HxsbmyPFAQAAAEBekK3g1Lp1a0lSr169nG0Oh8M5TTnD+AAAAAD8l2QrOO3duzen6wAAAACAPCtbwSk8PDyn6wAAAACAPCtbwUmSdu/erfHjxys+Pl4Oh0PR0dHq3bu3oqKicrI+AAAAALBdtmbVW7JkiWJiYvTzzz8rNjZWVapU0U8//aTKlSsrLi4up2sEAAAAAFtl64zTwIED1bdvX40aNSpd+wsvvKAmTZrkSHEAAAAAkBdk64xTfHy8OnfunK69U6dO2r59+3UXBQAAAAB5SbaCU7FixbR58+Z07Zs3b1bx4sWvtyYAAAAAyFOyNVSva9eu6tatm/bs2aN69erJ4XBozZo1Gj16tPr375/TNQIAAACArbIVnAYPHqygoCCNHTtWgwYNkiSFhoZq6NChLjfFBQAAAID/gmwFJ4fDob59+6pv3746deqUJCkoKChHCwMAAACAvCLb93GSpMTERP3+++9yOByqWLGiihUrllN1AQAAAECeka3JIZKSkvTEE08oNDRUd9xxh26//XaFhobq8ccf18mTJ3O6RgAAAACwVbaCU5cuXfTTTz/pm2++0T///KOTJ09q4cKFWr9+vbp27ZrTNQIAAACArbI1VO+bb77RkiVLdNtttznbmjVrpvfee0933313jhUHAAAAAHlBts44FS1aVMHBwenag4ODVbhw4esuCgAAAADykmwFp5dffln9+vXT4cOHnW1HjhzRc889p8GDB+dYcQAAAACQF2RrqN7UqVO1a9cuhYeHq2zZspKkhIQE+fr66ujRo3rnnXecfTdu3JgzlQIAAACATbIVnO6///4cLgMAAAAA8q5sBachQ4bkdB0AAAAAkGdd1w1wN2zYoPj4eDkcDsXExKhGjRo5VRcAAAAA5BnZCk6JiYl67LHHtHLlShUqVEjGGJ08eVINGzbUp59+qmLFiuV0nQAAAABgm2zNqvfss88qKSlJ27Zt04kTJ/T3339r69atSkpKUq9evXK6RgAAAACwVbbOOC1evFjfffedoqOjnW0xMTGaPHmymjZtmmPFAQAAAEBekK0zTqmpqfL29k7X7u3trdTU1OsuCgAAAADykmwFp0aNGql37946dOiQs+3gwYPq27evGjdunGPFAQAAAEBekK3g9Pbbb+vUqVMqV66coqKiVL58eUVEROjUqVOaNGlSTtcIAAAAALbK1jVOYWFh2rhxo+Li4rRjxw4ZYxQTE6O77rorp+sDAAAAANtlOTglJyfLz89PmzdvVpMmTdSkSZPcqAsAAAAA8owsD9Xz8vJSeHi4UlJScqMeAAAAAMhzsnWN08svv6xBgwbpxIkTOV0PAAAAAOQ52brGaeLEidq1a5dCQ0MVHh6ugIAAl+c3btyYI8UBAAAAQF6QreB0//33y+FwyBiT0/UAAAAAQJ6TpeB09uxZPffcc/ryyy916dIlNW7cWJMmTVJISEhu1QcAAAAAtsvSNU5DhgzRrFmzdM8996hNmzb67rvv1KNHj9yqDQAAAADyhCydcfr888/1/vvv67HHHpMktWvXTvXr11dKSoo8PT1zpUAAAAAAsFuWzjgdOHBADRo0cD6+5ZZb5OXlpUOHDuV4YQAAAACQV2QpOKWkpMjHx8elzcvLS8nJyTlaFAAAAADkJVkaqmeMUceOHeXr6+tsO3/+vLp37+4yJfnnn3+ecxUCAAAAgM2yFJw6dOiQru3xxx/PsWIAAAAAIC/KUnCaOXNmbtUBAAAAAHlWlq5xAgAAAID8iOAEAAAAABYITgAAAABggeAEAAAAABYITgAAAABggeAEAAAAABYITgAAAABggeAEAAAAABYITgAAAABggeAEAAAAABYITgAAAABggeAEAAAAABYITgAAAABgwfbgNGXKFEVERMjPz0+1atXS6tWrM7XcDz/8IC8vL1WvXj13CwQAAACQ79kanObOnas+ffropZde0qZNm9SgQQM1b95cCQkJ11zu5MmTat++vRo3buymSgEAAADkZ7YGp3Hjxqlz587q0qWLoqOjNX78eIWFhWnq1KnXXO6pp55S27ZtVbduXTdVCgAAACA/sy04Xbx4URs2bFDTpk1d2ps2baq1a9dedbmZM2dq9+7dGjJkSKa2c+HCBSUlJbn8AAAAAEBW2Bacjh07ppSUFJUoUcKlvUSJEjpy5EiGy/zxxx8aOHCgPv74Y3l5eWVqOyNHjlRwcLDzJyws7LprBwAAAJC/2D45hMPhcHlsjEnXJkkpKSlq27athg0bpgoVKmR6/YMGDdLJkyedPwcOHLjumgEAAADkL5k7bZMLQkJC5Onpme7sUmJiYrqzUJJ06tQprV+/Xps2bdIzzzwjSUpNTZUxRl5eXlq6dKkaNWqUbjlfX1/5+vrmzosAAAAAkC/YdsbJx8dHtWrVUlxcnEt7XFyc6tWrl65/wYIF9dtvv2nz5s3On+7du6tixYravHmz6tSp467SAQAAAOQztp1xkqR+/frpiSeeUO3atVW3bl29++67SkhIUPfu3SVdHmZ38OBBzZ49Wx4eHqpSpYrL8sWLF5efn1+6dgAAAADISbYGp9atW+v48eMaPny4Dh8+rCpVqmjRokUKDw+XJB0+fNjynk4AAAAAkNscxhhjdxHulJSUpODgYJ08eVIFCxa0u5xscwxLP4EG3MsMyVeHTt6UwUQycKP89fGRJ/FZYD8+C+zHcWC/G/k4yEo2sH1WPQAAAADI6whOAAAAAGCB4AQAAAAAFghOAAAAAGCB4AQAAAAAFghOAAAAAGCB4AQAAAAAFghOAAAAAGCB4AQAAAAAFghOAAAAAGCB4AQAAAAAFghOAAAAAGCB4AQAAAAAFghOAAAAAGCB4AQAAAAAFghOAAAAAGCB4AQAAAAAFghOAAAAAGCB4AQAAAAAFghOAAAAAGCB4AQAAAAAFghOAAAAAGCB4AQAAAAAFghOAAAAAGCB4AQAAAAAFghOAAAAAGCB4AQAAAAAFghOAAAAAGCB4AQAAAAAFghOAAAAAGCB4AQAAAAAFghOAAAAAGCB4AQAAAAAFghOAAAAAGCB4AQAAAAAFghOAAAAAGCB4AQAAAAAFghOAAAAAGCB4AQAAAAAFghOAAAAAGCB4AQAAAAAFghOAAAAAGCB4AQAAAAAFghOAAAAAGCB4AQAAAAAFghOAAAAAGCB4AQAAAAAFghOAAAAAGCB4AQAAAAAFghOAAAAAGCB4AQAAAAAFghOAAAAAGCB4AQAAAAAFghOAAAAAGCB4AQAAAAAFghOAAAAAGCB4AQAAAAAFghOAAAAAGCB4AQAAAAAFghOAAAAAGCB4AQAAAAAFghOAAAAAGCB4AQAAAAAFghOAAAAAGCB4AQAAAAAFghOAAAAAGCB4AQAAAAAFghOAAAAAGCB4AQAAAAAFghOAAAAAGCB4AQAAAAAFghOAAAAAGCB4AQAAAAAFghOAAAAAGCB4AQAAAAAFghOAAAAAGCB4AQAAAAAFmwPTlOmTFFERIT8/PxUq1YtrV69+qp9P//8czVp0kTFihVTwYIFVbduXS1ZssSN1QIAAADIj2wNTnPnzlWfPn300ksvadOmTWrQoIGaN2+uhISEDPt///33atKkiRYtWqQNGzaoYcOGuvfee7Vp0yY3Vw4AAAAgP3EYY4xdG69Tp45q1qypqVOnOtuio6N1//33a+TIkZlaR+XKldW6dWu98sormeqflJSk4OBgnTx5UgULFsxW3XmBY5jD7hLyPTPEtkMHaRwcB7ay7+MD/x+fBfbjs8B+HAf2u5GPg6xkA9vOOF28eFEbNmxQ06ZNXdqbNm2qtWvXZmodqampOnXqlIoUKXLVPhcuXFBSUpLLDwAAAABkhW3B6dixY0pJSVGJEiVc2kuUKKEjR45kah1jx47VmTNn9Oijj161z8iRIxUcHOz8CQsLu666AQAAAOQ/tk8O4bhiqI0xJl1bRj755BMNHTpUc+fOVfHixa/ab9CgQTp58qTz58CBA9ddMwAAAID8xcuuDYeEhMjT0zPd2aXExMR0Z6GuNHfuXHXu3Fnz5s3TXXfddc2+vr6+8vX1ve56AQAAAORftp1x8vHxUa1atRQXF+fSHhcXp3r16l11uU8++UQdO3bUnDlzdM899+R2mQAAAABg3xknSerXr5+eeOIJ1a5dW3Xr1tW7776rhIQEde/eXdLlYXYHDx7U7NmzJV0OTe3bt9eECRN06623Os9WFShQQMHBwba9DgAAAAD/bbYGp9atW+v48eMaPny4Dh8+rCpVqmjRokUKDw+XJB0+fNjlnk7vvPOOkpOT9fTTT+vpp592tnfo0EGzZs1yd/kAAAAA8glbg5Mk9ezZUz179szwuSvD0MqVK3O/IAAAAAC4gu2z6gEAAABAXkdwAgAAAAALBCcAAAAAsEBwAgAAAAALBCcAAAAAsEBwAgAAAAALBCcAAAAAsEBwAgAAAAALBCcAAAAAsEBwAgAAAAALBCcAAAAAsEBwAgAAAAALBCcAAAAAsEBwAgAAAAALBCcAAAAAsEBwAgAAAAALBCcAAAAAsEBwAgAAAAALBCcAAAAAsEBwAgAAAAALBCcAAAAAsEBwAgAAAAALBCcAAAAAsEBwAgAAAAALBCcAAAAAsEBwAgAAAAALBCcAAAAAsEBwAgAAAAALBCcAAAAAsEBwAgAAAAALBCcAAAAAsEBwAgAAAAALBCcAAAAAsEBwAgAAAAALBCcAAAAAsEBwAgAAAAALBCcAAAAAsEBwAgAAAAALBCcAAAAAsEBwAgAAAAALBCcAAAAAsEBwAgAAAAALBCcAAAAAsEBwAgAAAAALBCcAAAAAsEBwAgAAAAALBCcAAAAAsEBwAgAAAAALBCcAAAAAsEBwAgAAAAALBCcAAAAAsEBwAgAAAAALBCcAAAAAsEBwAgAAAAALBCcAAAAAsEBwAgAAAAALBCcAAAAAsEBwAgAAAAALBCcAAAAAsEBwAgAAAAALBCcAAAAAsEBwAgAAAAALBCcAAAAAsEBwAgAAAAALBCcAAAAAsEBwAgAAAAALBCcAAAAAsEBwAgAAAAALBCcAAAAAsEBwAgAAAAALBCcAAAAAsEBwAgAAAAALBCcAAAAAsEBwAgAAAAALBCcAAAAAsEBwAgAAAAALBCcAAAAAsGB7cJoyZYoiIiLk5+enWrVqafXq1dfsv2rVKtWqVUt+fn6KjIzUtGnT3FQpAAAAgPzK1uA0d+5c9enTRy+99JI2bdqkBg0aqHnz5kpISMiw/969e9WiRQs1aNBAmzZt0osvvqhevXpp/vz5bq4cAAAAQH5ia3AaN26cOnfurC5duig6Olrjx49XWFiYpk6dmmH/adOmqWzZsho/fryio6PVpUsXderUSW+++aabKwcAAACQn3jZteGLFy9qw4YNGjhwoEt706ZNtXbt2gyXWbdunZo2berS1qxZM73//vu6dOmSvL290y1z4cIFXbhwwfn45MmTkqSkpKTrfQn2Om93Abjhf4eA68UxYD8+C2zHZ0EewHFguxv5OEir3Rhj2de24HTs2DGlpKSoRIkSLu0lSpTQkSNHMlzmyJEjGfZPTk7WsWPHVKpUqXTLjBw5UsOGDUvXHhYWdh3VA1LwqGC7SwDsFcwxAPBZAPw3joNTp04p2OJzzbbglMbhcLg8Nsaka7Pqn1F7mkGDBqlfv37Ox6mpqTpx4oSKFi16ze0g9yQlJSksLEwHDhxQwYIF7S4HsAXHAcBxAEgcB3YzxujUqVMKDQ217GtbcAoJCZGnp2e6s0uJiYnpziqlKVmyZIb9vby8VLRo0QyX8fX1la+vr0tboUKFsl84ckzBggX5BwL5HscBwHEASBwHdrI605TGtskhfHx8VKtWLcXFxbm0x8XFqV69ehkuU7du3XT9ly5dqtq1a2d4fRMAAAAA5ARbZ9Xr16+fpk+frhkzZig+Pl59+/ZVQkKCunfvLunyMLv27ds7+3fv3l379+9Xv379FB8frxkzZuj999/XgAED7HoJAAAAAPIBW69xat26tY4fP67hw4fr8OHDqlKlihYtWqTw8HBJ0uHDh13u6RQREaFFixapb9++mjx5skJDQzVx4kQ99NBDdr0EZIOvr6+GDBmSbgglkJ9wHAAcB4DEcXAjcZjMzL0HAAAAAPmYrUP1AAAAAOBGQHACAAAAAAsEJwAAAACwQHACAAAAAAsEJwAAAACwQHACAAAAAAu23scJ+cuff/6pr7/+WgkJCbp48aLLc+PGjbOpKsB9PvjgA4WEhOiee+6RJD3//PN69913FRMTo08++cR5DzsgP7h48aL27t2rqKgoeXnx5wiAvI8zTnCLZcuWqWLFipoyZYrGjh2rFStWaObMmZoxY4Y2b95sd3mAW7z++usqUKCAJGndunV6++23NWbMGIWEhKhv3742Vwe4x9mzZ9W5c2f5+/urcuXKzhvd9+rVS6NGjbK5OsB9Vq1apXvvvVfly5fXTTfdpPvuu0+rV6+2uyxcA8EJbjFo0CD1799fW7dulZ+fn+bPn68DBw7ojjvu0COPPGJ3eYBbHDhwQOXLl5ckffnll3r44YfVrVs3jRw5kg9L5BuDBg3Sli1btHLlSvn5+Tnb77rrLs2dO9fGygD3+eijj3TXXXfJ399fvXr10jPPPKMCBQqocePGmjNnjt3l4SocxhhjdxH47wsKCtLmzZsVFRWlwoULa82aNapcubK2bNmiVq1aad++fXaXCOS64sWLa8mSJapRo4Zq1Kihvn37qn379tq9e7eqVaum06dP210ikOvCw8M1d+5c3XrrrQoKCtKWLVsUGRmpXbt2qWbNmkpKSrK7RCDXRUdHq1u3bulGG4wbN07vvfee4uPjbaoM18IZJ7hFQECALly4IEkKDQ3V7t27nc8dO3bMrrIAt2rSpIm6dOmiLl26aOfOnc5rnbZt26Zy5crZWxzgJkePHlXx4sXTtZ85c0YOh8OGigD327Nnj+6999507ffdd5/27t1rQ0XIDIIT3OLWW2/VDz/8IEm655571L9/f7322mvq1KmTbr31VpurA9xj8uTJqlu3ro4ePar58+eraNGikqQNGzaoTZs2NlcHuMfNN9+sb775xvk4LSy99957qlu3rl1lAW4VFhamZcuWpWtftmyZwsLCbKgImcFQPbjFnj17dPr0acXGxurs2bMaMGCA1qxZo/Lly+utt95iNjEAyCfWrl2ru+++W+3atdOsWbP01FNPadu2bVq3bp1WrVqlWrVq2V0ikOumTp2qPn36qFOnTqpXr54cDofWrFmjWbNmacKECXrqqafsLhEZIDgBgJssXrxYgYGBuu222yRdPgP13nvvKSYmRpMnT1bhwoVtrhBwj61bt+qNN97Qhg0blJqaqpo1a+qFF15Q1apV7S4NcJsvvvhCY8eOdV7PFB0dreeee06tWrWyuTJcDcEJANykatWqGj16tFq0aKHffvtNN998s/r166fly5crOjpaM2fOtLtEIFddunRJ3bp10+DBgxUZGWl3OQCQJQQn5JoiRYpo586dCgkJUeHCha950e+JEyfcWBlgj8DAQG3dulXlypXT0KFDtXXrVv3vf//Txo0b1aJFCx05csTuEoFcV6hQIW3cuJHgBOjyjaATExOVmprq0l62bFmbKsK1cKtu5Jq33npLQUFBkqTx48fbWwyQB/j4+Ojs2bOSpO+++07t27eXdPlLBqZgRn7xwAMP6Msvv1S/fv3sLgWwzR9//KFOnTpp7dq1Lu3GGDkcDqWkpNhUGa6F4IRc06FDhwz/H8ivbrvtNvXr10/169fXzz//7LzZ586dO1WmTBmbqwPco3z58hoxYoTWrl2rWrVqKSAgwOX5Xr162VQZ4D4dO3aUl5eXFi5cqFKlSjEV/w2CoXpwq8TExAxPScfGxtpUEeA+CQkJ6tmzpw4cOKBevXqpc+fOkqS+ffsqJSVFEydOtLlCIPdFRERc9TmHw6E9e/a4sRrAHgEBAdqwYYMqVapkdynIAoIT3GLDhg3q0KGD4uPjdeWvHKekAQBAfnLzzTfrrbfecs6yihsDwQluERsbq/Lly+uFF15QiRIl0p2S5j5OyG/OnTunS5cuubQVLFjQpmoA97t48aL27t2rqKgoeXlx5QD++/59Lev69ev18ssv6/XXX1fVqlXl7e3t0pfPg7yJ4AS3CAoK0qZNm1S+fHm7SwFsc+bMGb3wwgv67LPPdPz48XTPc+YV+cHZs2f17LPP6oMPPpB0+Rq/yMhI9erVS6GhoRo4cKDNFQK5w8PDw+WL47SJIP6NySHyNr7igVs0btxYW7ZsITghX3v++ee1YsUKTZkyRe3bt9fkyZN18OBBvfPOOxo1apTd5QFuMWjQIG3ZskUrV67U3Xff7Wy/6667NGTIEIIT/rNWrFhhdwm4TpxxglscO3ZMHTp00C233KIqVaqkOyV933332VQZ4D5ly5bV7Nmzdeedd6pgwYLauHGjypcvrw8//FCffPKJFi1aZHeJQK4LDw/X3LlzdeuttyooKEhbtmxRZGSkdu3apZo1azI1P4A8izNOcIu1a9dqzZo1+vbbb9M9xylp5BcnTpxwzihWsGBB542fb7vtNvXo0cPO0gC3OXr0qIoXL56u/cyZM0zJjHzl77//1vvvv6/4+Hg5HA5FR0frySefVJEiRewuDVfhYXcByB969eqlJ554QocPH1ZqaqrLD6EJ+UVkZKT27dsnSYqJidFnn30mSVqwYIEKFSpkX2GAG91888365ptvnI/TwtJ7772nunXr2lUW4FarVq1SuXLlNHHiRP399986ceKEJk6cqIiICK1atcru8nAVDNWDWwQFBWnz5s2KioqyuxTANm+99ZY8PT3Vq1cvrVixQvfcc49SUlKUnJyscePGqXfv3naXCOS6tWvX6u6771a7du00a9YsPfXUU9q2bZvWrVunVatWqVatWnaXCOS6KlWqqF69epo6dao8PT0lXZ4gqGfPnvrhhx+0detWmytERghOcIsOHTqoQYMG6tKli92lAHlGQkKC1q9fr6ioKFWrVs3ucgC3+e233/Tmm29qw4YNSk1NVc2aNfXCCy+oatWqdpcGuEWBAgW0efNmVaxY0aX9999/V/Xq1XXu3DmbKsO1cI0T3KJChQoaNGiQ1qxZk+H9Cnr16mVTZYB9ypYtq7Jly9pdBuB2VatWdU5HDuRHNWvWVHx8fLrgFB8fr+rVq9tTFCxxxglukXZBfEYcDof27NnjxmoA95k4cWKm+/IFAvKL1NRU7dq1S4mJiUpNTXV57vbbb7epKsB95s6dq+eff17PPvusbr31VknSjz/+qMmTJ2vUqFGKjo529o2NjbWrTFyB4AQAuehaXxr8G18gIL/48ccf1bZtW+3fv19X/gnCLKvILzw8rj0/m8Ph4Ga4eRDBCQAAuE316tVVoUIFDRs2TKVKlUo3BXlwcLBNlQHus3///kz3DQ8Pz8VKkBUEJ7hFSkqKZs2apWXLlmU4NGP58uU2VQa4T79+/TJsdzgc8vPzU/ny5dWqVSvu4YH/tICAAG3ZskXly5e3uxQAyBImh4Bb9O7dW7NmzdI999yjKlWqcJND5EubNm3Sxo0blZKSoooVK8oYoz/++EOenp6qVKmSpkyZov79+2vNmjWKiYmxu1wgV9SpU0e7du0iOCHfO3jwoH744YcMv1Dmmte8iTNOcIuQkBDNnj1bLVq0sLsUwDbjx4/X6tWrNXPmTBUsWFCSlJSUpM6dO+u2225T165d1bZtW507d05LliyxuVog5/z666/O/9+9e7defvllPffccxnOssqF8MgPZs6cqe7du8vHx0dFixZ1+UKZa17zLoIT3CI0NFQrV65UhQoV7C4FsE3p0qUVFxeX7mzStm3b1LRpUx08eFAbN25U06ZNdezYMZuqBHKeh4eH82L3jHAhPPKbsLAwde/eXYMGDbKcKAJ5B0P14Bb9+/fXhAkT9PbbbzNMD/nWyZMnlZiYmC44HT16VElJSZKkQoUK6eLFi3aUB+SavXv32l0CkKecPXtWjz32GKHpBkNwQq558MEHXR4vX75c3377rSpXrpxuaMbnn3/uztIAW7Rq1UqdOnXS2LFjdfPNN8vhcOjnn3/WgAEDdP/990uSfv75Z87M4j+HWcEAV507d9a8efM0cOBAu0tBFjBUD7nmySefzHTfmTNn5mIlQN5w+vRp9e3bV7Nnz1ZycrIkycvLSx06dNBbb72lgIAAbd68WZK4czz+037//XdNmjRJ8fHxcjgcqlSpkp599llVrFjR7tIAt0hJSVHLli117ty5DK/1GzdunE2V4VoITgDgZqdPn9aePXtkjFFUVJQCAwPtLglwm//9739q06aNateurbp160q6fFPcX375RXPmzNEjjzxic4VA7hsxYoSGDBmiihUrqkSJEukmh+A2LXkTwQlu0ahRI33++ecqVKiQS3tSUpLuv/9+/oEAgHwiMjJSjz/+uIYPH+7SPmTIEH344YfMJoZ8oXDhwnrrrbfUsWNHu0tBFhCc4BYeHh46cuSIihcv7tKemJio0qVL69KlSzZVBgBwJ39/f/3666/p7uP0xx9/qFq1ajp79qxNlQHuU7JkSa1evVo33XST3aUgC5gcArnq3/fu2L59u44cOeJ8nJKSosWLF6t06dJ2lAYAsMGdd96p1atXpwtOa9asUYMGDWyqCnCv3r17a9KkSZo4caLdpSALOOOEXJV27w5JGd6/o0CBApo0aZI6derk7tIAADaYNm2aXnnlFT366KO69dZbJV2+xmnevHkaNmyYQkNDnX3vu+8+u8oEctUDDzyg5cuXq2jRosw2fAMhOCFX7d+/X8YYRUZG6ueff1axYsWcz/n4+Kh48eLy9PS0sUIAgDtl9r413AwX/2VWMw8z23DeRHCCW5w5c0YBAQF2lwEAAABkC7crhluUKFFCnTp10po1a+wuBQCQx/zzzz92lwC41dChQ7V//367y0AWEZzgFp988olOnjypxo0bq0KFCho1apQOHTpkd1kAADcbPXq05s6d63z8yCOPqEiRIipdurS2bNliY2WA+yxYsEBRUVFq3Lix5syZo/Pnz9tdEjKB4AS3uPfeezV//nwdOnRIPXr00CeffKLw8HC1bNlSn3/+uZKTk+0uEQDgBu+8847CwsIkSXFxcfruu++0ePFiNW/eXM8995zN1QHusWHDBm3cuFGxsbHq27evSpUqpR49euiXX36xuzRcA9c4wTaTJk3Sc889p4sXLyokJETdu3fXwIED5e/vb3dpAIBcUqBAAe3cuVNhYWHq3bu3zp8/r3feeUc7d+5UnTp19Pfff9tdIuBWycnJWrBggWbOnKnFixerYsWK6tKlizp27Kjg4GC7y8O/cMYJbnXkyBGNGTNG0dHRGjhwoB5++GEtW7ZMb731lr744gvdf//9dpcIAMhFhQsX1oEDByRJixcv1l133SXp8i0rmEUP+VFqaqouXryoCxcuyBijIkWKaOrUqQoLC3MZ1gr7cQNcuMXnn3+umTNnasmSJYqJidHTTz+txx9/XIUKFXL2qV69umrUqGFfkQCAXPfggw+qbdu2uummm3T8+HE1b95ckrR58+Z0N8UF/ss2bNigmTNn6pNPPpGvr6/at2+vyZMnO4+DsWPHqlevXmrdurXNlSINQ/XgFsHBwXrsscfUpUsX3XzzzRn2OXfunMaMGaMhQ4a4uToAgLtcunRJEyZM0IEDB9SxY0fnF2bjx49XYGCgunTpYnOFQO6LjY3V9u3b1axZM3Xt2lX33ntvuvtaHj16VCVKlFBqaqpNVeJKBCe4xdmzZ7l2CQAAQNKIESPUqVMnlS5d2u5SkAUEJ7hNamqqdu3apcTExHTfntx+++02VQUAcLfdu3dr/Pjxio+Pl8PhUHR0tPr06aPIyEi7SwNyTb9+/TLdd9y4cblYCbKLa5zgFj/++KPatm2r/fv368qs7nA4uCAYAPKJJUuW6L777lP16tVVv359GWO0du1axcTEaMGCBWrSpIndJQK5YtOmTZnq53A4crkSZBdnnOAW1atXV4UKFTRs2DCVKlUq3T8KTLcJAPlDjRo11KxZM40aNcqlfeDAgVq6dKk2btxoU2UAcG0EJ7hFQECAtmzZwoxJAJDP+fn56bffftNNN93k0r5z507Fxsbq/PnzNlUGANfGfZzgFnXq1NGuXbvsLgMAYLNixYpp8+bN6do3b96s4sWLu78gAMgkrnFCrvn111+d///ss8+qf//+OnLkiKpWrSpvb2+XvrGxse4uDwBgg65du6pbt27as2eP6tWrJ4fDoTVr1mj06NHq37+/3eUBwFUxVA+5xsPDQw6HI91kEGnSnmNyCADIP4wxGj9+vMaOHatDhw5JkkJDQ/Xcc8+pV69eXBgPIM8iOCHX7N+/P9N9w8PDc7ESAEBedOrUKUlSUFCQzZUAgDWCE3LdpUuXVLFiRS1cuFAxMTF2lwMAAABkGZNDINd5e3vrwoULDL8AAOivv/7SE088odDQUHl5ecnT09PlBwDyKs44wS1GjRqlHTt2aPr06fLyYk4SAMivmjdvroSEBD3zzDMZ3tevVatWNlUGANdGcIJbPPDAA1q2bJkCAwNVtWpVBQQEuDz/+eef21QZAMCdgoKCtHr1alWvXt3uUgAgS/jqH25RqFAhPfTQQ3aXAQCwWVhY2FVnWwWAvIwzTsh1ycnJ+vjjj9WsWTOVLFnS7nIAADZaunSpxo4dq3feeUflypWzuxwAyDSCE9zC399f8fHxTDsOAPlc4cKFdfbsWSUnJ8vf3z/dDdFPnDhhU2UAcG0M1YNb1KlTR5s2bSI4AUA+N378eLtLAIBs4YwT3GLevHkaOHCg+vbtq1q1aqWbHCI2NtamygAAAABrBCe4hYfH1W8Z5nA4lJKS4sZqAAB2SklJ0Zdffqn4+Hg5HA7FxMTovvvu4z5OAPI0hurBLfbu3Wt3CQCAPGDXrl1q0aKFDh48qIoVK8oYo507dyosLEzffPONoqKi7C4RADLEGSe41fbt25WQkKCLFy862xwOh+69914bqwIAuEuLFi1kjNHHH3+sIkWKSJKOHz+uxx9/XB4eHvrmm29srhAAMkZwglvs2bNHDzzwgH777Tc5HA7nPTzS7hjPUD0AyB8CAgL0448/qmrVqi7tW7ZsUf369XX69GmbKgOAa7v6hSdADurdu7ciIiL0119/yd/fX1u3btX333+v2rVra+XKlXaXBwBwE19fX506dSpd++nTp+Xj42NDRQCQOQQnuMW6des0fPhwFStWTB4eHvL09NRtt92mkSNHqlevXnaXBwBwk5YtW6pbt2766aefZIyRMUY//vijunfvrvvuu8/u8gDgqghOcIuUlBQFBgZKkkJCQnTo0CFJUnh4uH7//Xc7SwMAuNHEiRMVFRWlunXrys/PT35+fqpXr57Kly/PPZ4A5GnMqge3qFKlin799VdFRkaqTp06GjNmjHx8fPTuu+8qMjLS7vIAAG5SqFAhffXVV9q1a5fi4+NljFFMTIzKly9vd2kAcE1MDgG3WLJkic6cOaMHH3xQe/bsUcuWLbVjxw4VLVpUc+fOVaNGjewuEQCQS/r166cRI0YoICBA/fr1u2bfcePGuakqAMgazjjBLZo1a+b8/8jISG3fvl0nTpxQ4cKFnTPrAQD+mzZt2qRLly45//9q+DwAkJdxxgkAAAAALDA5BAAAAABYIDgBAAAAgAWCEwAAAABYIDgBAAAAgAWCEwAgz+nYsaMcDoccDoe8vb1VokQJNWnSRDNmzFBqamqm1zNr1iwVKlQo9wq9io4dO+r+++93+3YBALmH4AQAyJPuvvtuHT58WPv27dO3336rhg0bqnfv3mrZsqWSk5PtLg8AkM8QnAAAeZKvr69Kliyp0qVLq2bNmnrxxRf11Vdf6dtvv9WsWbMkXb5ZatWqVRUQEKCwsDD17NlTp0+fliStXLlSTz75pE6ePOk8ezV06FBJ0kcffaTatWsrKChIJUuWVNu2bZWYmOjc9t9//6127dqpWLFiKlCggG666SbNnDnT+fzBgwfVunVrFS5cWEWLFlWrVq20b98+SdLQoUP1wQcf6KuvvnJud+XKle7YZQCAXERwAgDcMBo1aqRq1arp888/lyR5eHho4sSJ2rp1qz744AMtX75czz//vCSpXr16Gj9+vAoWLKjDhw/r8OHDGjBggCTp4sWLGjFihLZs2aIvv/xSe/fuVceOHZ3bGTx4sLZv365vv/1W8fHxmjp1qkJCQiRJZ8+eVcOGDRUYGKjvv/9ea9asUWBgoO6++25dvHhRAwYM0KOPPuo8Y3b48GHVq1fPvTsKAJDjvOwuAACArKhUqZJ+/fVXSVKfPn2c7RERERoxYoR69OihKVOmyMfHR8HBwXI4HCpZsqTLOjp16uT8/8jISE2cOFG33HKLTp8+rcDAQCUkJKhGjRqqXbu2JKlcuXLO/p9++qk8PDw0ffp0ORwOSdLMmTNVqFAhrVy5Uk2bNlWBAgV04cKFdNsFANy4OOMEALihGGOcgWXFihVq0qSJSpcuraCgILVv317Hjx/XmTNnrrmOTZs2qVWrVgoPD1dQUJDuvPNOSVJCQoIkqUePHvr0009VvXp1Pf/881q7dq1z2Q0bNmjXrl0KCgpSYGCgAgMDVaRIEZ0/f167d+/OnRcNALAdwQkAcEOJj49XRESE9u/frxYtWqhKlSqaP3++NmzYoMmTJ0uSLl26dNXlz5w5o6ZNmyowMFAfffSRfvnlF33xxReSLg/hk6TmzZtr//796tOnjw4dOqTGjRs7h/mlpqaqVq1a2rx5s8vPzp071bZt21x+9QAAuzBUDwBww1i+fLl+++039e3bV+vXr1dycrLGjh0rD4/L3wN+9tlnLv19fHyUkpLi0rZjxw4dO3ZMo0aNUlhYmCRp/fr16bZVrFgxdezYUR07dlSDBg303HPP6c0331TNmjU1d+5cFS9eXAULFsywzoy2CwC4sXHGCQCQJ124cEFHjhzRwYMHtXHjRr3++utq1aqVWrZsqfbt2ysqKkrJycmaNGmS9uzZow8//FDTpk1zWUe5cuV0+vRpLVu2TMeOHdPZs2dVtmxZ+fj4OJf7+uuvNWLECJflXnnlFX311VfatWuXtm3bpoULFyo6OlqS1K5dO4WEhKhVq1ZavXq19u7dq1WrVql37976888/ndv99ddf9fvvv+vYsWPXPAMGALgxEJwAAHnS4sWLVapUKZUrV0533323VqxYoYkTJ+qrr76Sp6enqlevrnHjxmn06NGqUqWKPv74Y40cOdJlHfXq1VP37t3VunVrFStWTGPGjFGxYsU0a9YszZs3TzExMRo1apTefPNNl+V8fHw0aNAgxcbG6vbbb5enp6c+/fRTSZK/v7++//57lS1bVg8++KCio6PVqVMnnTt3znkGqmvXrqpYsaJq166tYsWK6YcffnDPTgMA5BqHMcbYXQQAAAAA5GWccQIAAAAACwQnAAAAALBAcAIAAAAACwQnAAAAALBAcAIAAAAACwQnAAAAALBAcAIAAAAACwQnAAAAALBAcAIAAAAACwQnAAAAALBAcAIAAAAACwQnAAAAALDw/wD+Ffk9FpVl6wAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "# Top 1 模型\n",
    "top1_models = {\n",
    "    'arrhythmia': 'LUNAR',\n",
    "    'glass': 'MO-GAAL',\n",
    "    'ionosphere': 'AutoEncoder',\n",
    "    'lympho': 'AnoGAN'\n",
    "}\n",
    "\n",
    "correctness_matrix = resp_df.apply(lambda col: [top1_models[col.name] in top5_models_per_dataset[col.name] for model in col])\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.heatmap(correctness_matrix, annot=True, cmap='coolwarm', cbar=False)\n",
    "plt.title('Correctness of Model Selection in 10 Experiments')\n",
    "plt.xlabel('Dataset')\n",
    "plt.ylabel('Experiment Number')\n",
    "plt.show()\n",
    "\n",
    "correct_counts = correctness_matrix.sum()\n",
    "total_counts = correctness_matrix.count()\n",
    "correct_ratios = correct_counts / total_counts\n",
    "correctness_df = pd.DataFrame({\n",
    "    'Correct': correct_ratios,\n",
    "    'Incorrect': 1 - correct_ratios\n",
    "})\n",
    "\n",
    "correctness_df.plot(kind='bar', stacked=True, figsize=(10, 6), color=['green', 'red'])\n",
    "plt.title('Proportion of Correct and Incorrect Model Selections')\n",
    "plt.ylabel('Proportion')\n",
    "plt.xlabel('Dataset')\n",
    "plt.legend(['Correct', 'Incorrect'])\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test: LLAMA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gpt",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
